---
title: "Main Analysis Pipeline"
author: "Zachary Stanfield"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: united
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```

# Description

Analyze non-targeted analysis dataset of household consumer products. We
have 5 categories of products that include multiple dilutions, duplicate
samples, and repeated products. The main goal is to develop a chemical
ingredient signature at multiple levels (broad category down to specific
grouping levels like brand and socks within the clothing category). Also
want to assess within-product similarity of samples.

# Load Packages and Data Objects

```{r setEnv}
rm(list=ls())
library(readxl)
library(tsne)
library(reshape2)
#install_github("https://github.com/aberHRML/classyfireR")
library(classyfireR)
library(treecompareR)
library(caret)
library(ggplot2)
library(ComplexHeatmap)
library(ggthemes)
library(tidyr)
library(tidytext)
library(dplyr)
library(factoextra)
library(cluster)
library(vegan)
library(UpSetR)
# install_github("https://github.com/HumanExposure/qsur/")
library(QSUR)
library(RColorBrewer)
library(jsonlite)
library(data.table)
#library(ggtree)
library(circlize)
library(proxy)
library(stringr)
library(colorRamp2)
library(rcartocolor)
library(ggtree)
library(httk)
library(ggpubr)
#myPath <- "/ccte/home1/zstanfie/HouseholdProdSSA"
#myPath <- "C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsNTA/HouseholdProdSSA"
myPath <- "C:/Users/jwambaug/git/CompTox-ExpoCast-HouseholdProductSignatures"
prodGroups <- c("Cotton Clothing", "Shampoo", "Baby Soap", "Fabric Upholstery", "Silicone Kitchen Tools")
myFiles <- c("Sequence1 Clothing.xlsx", "Sequence2 Shampoo.xlsx", "Sequence1 Personal Care Products.xlsx",
             "Sequence3 Fabric.xlsx", "Sequence2 Kitchen.xlsx")
data_files <- paste(myPath, "raw_data", myFiles, sep = "/")
upc_file <- "EPA task 10 items_26Feb18.xlsx"
```

# Process the Raw Data

This function parses the raw data into multiple formats for downstream
analysis and saves them to the data directory

```{r processRaw, eval=FALSE}
source(paste(myPath, "R/processRawData.R", sep = "/"))

### Before running this, check the save_names assignment at the start of this function to make sure
### files are saved in the right locations
processSSAfiles(data_files, myPath, prodGroups)

### This is for organizing the UPCs across raw data files intended for the use of querying 
### ChemExpo programmatically in downstream analyses. Don't need to run this if products 
### don't have UPCs provided in the raw data.
cleanForUPCs(upc_file, myPath, prodGroups)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


# Summarize Data

Examine how many unique chemicals are in our data, how many are confirmed or tentatively
confirmed, and what percentage of our data those make up.  Also want to generate a full
feature table that has all the raw data from all samples and includes curated chemical
identifiers that we add from the EPA's CompTox Chemicals Dashboard (CCD). Have some chemicals
that were individually curated after not having a match in CCD, so need to combine these.
Want to process the dashboard query output files for later use in chemical annotation
and use DTXSIDs across all of our data.

```{r dataSummary}
load(file = paste(myPath, "data", "fullSetOfSamplesWithAllChems.RData", sep = "/"))

# unique chemicals
allChems <- unique(fullSampChemInfo$Name)
length(unique(fullSampChemInfo$Spectrum))
length(unique(fullSampChemInfo$CAS))
length(unique(fullSampChemInfo$CAS[!is.na(fullSampChemInfo$CAS)]))

# Hit flag distribution
as.data.frame(table(fullSampChemInfo$Group))

# Counts of spectra and chemicals by flag
indXC <- fullSampChemInfo$Group == "xc"
indXT <- fullSampChemInfo$Group == "xt"
indBlanks <- regexpr("SOLBLK",fullSampChemInfo$`Customer ID`)!=-1

# Unique spectra and chemical names with these flags
length(unique(fullSampChemInfo$Spectrum[indXC]))
length(unique(fullSampChemInfo$Spectrum[indXT]))
length(unique(fullSampChemInfo$Spectrum[indXC | indXT]))
length(unique(fullSampChemInfo$Spectrum[!(indXC | indXT)]))
length(unique(fullSampChemInfo$Name[indXC]))
length(unique(fullSampChemInfo$Name[indXT]))
length(unique(fullSampChemInfo$Name[indXC | indXT]))
length(unique(fullSampChemInfo$CAS[indXC | indXT]))
# Look at non-matches
indOther <- fullSampChemInfo$Group %in% c("ns", "xt;ui", "xt;ui;PCB", "xu")
length(unique(fullSampChemInfo$Spectrum[indOther]))
length(unique(fullSampChemInfo$Name[indOther]))

# Write a file to use the raw chemical name for querying the EPA's CompTox Chemicals Dashboard
xcxt_name <- unique(fullSampChemInfo$Name[indXC | indXT])
write.table(xcxt_name, file = paste(myPath, "data", "uniqueChems_xcxt_allSamples_Name.txt", sep = "/"), 
            quote = FALSE, row.names = FALSE, col.names = FALSE)

cat(paste(length(unique(fullSampChemInfo$Spectrum[!indBlanks])),
          "features (excluding blanks).\n"))
cat(paste(length(unique(fullSampChemInfo$Spectrum[!indBlanks &
                                                    (indXC | 
                                                        indXT)])),
          "matched NIST.\n"))
cat(paste(length(unique(fullSampChemInfo$Spectrum[!indBlanks &
                                                    indXC])),
          "Features with Confirmed Identity,\n"))
cat(paste(length(unique(fullSampChemInfo$Spectrum[!indBlanks &
                                                    indXT])),
          "Tentative Matches.\n"))
cat(paste(length(unique(fullSampChemInfo$Spectrum[!indBlanks &
                                                    !(indXC | 
                                                        indXT)])),
          "unidentified features.\n"))

prodOnt <- as.data.frame(read_xlsx(path = paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", 
                                                sep = "/")))
# Get rid of blanks:
prodOnt <- subset(prodOnt,!(Type %in% "Solvent Blank"))

cat(paste(length(unique(prodOnt$'Anon Sample')),
    "unique samples analyzed.\n"))
for (this.cat in unique(prodOnt$Group2))
{
  this.subset <- subset(prodOnt, Group2==this.cat)
  unique.samples <- unique(this.subset$'Anon Sample')
  num.replicates <- sum(regexpr("_rep",unique.samples)!=-1)
  num.duplicates <- sum(regexpr("_dup",unique.samples)!=-1)
  cat(paste(length(unique.samples)-num.replicates-num.duplicates,
  "unique items with",
  num.duplicates, "duplicate extraction and",
  num.replicates, "repeat purchases for", 
  this.cat,"\n"))
  
}

```

```{r read_dashboard_query_by_name}
# Read in the result of querying the dashboard by name
tps <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_2024-05-03.xlsx", sep = "/"), sheet = 2)
# Process this data in case some chemicals returned multiple rows
todrop <- c("Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
tps <- tps[!tps$FOUND_BY %in% todrop,]
# Add harmonized chemical identifiers to fullSampChemInfo object 
ind <- match(fullSampChemInfo$Name, tps$INPUT)
temp <- tps[ind, colnames(tps) %in% c("DTXSID", "PREFERRED_NAME", "CASRN")]
colnames(fullSampChemInfo)[7:9] <- paste("Raw_", colnames(fullSampChemInfo)[7:9], sep = "")
fullSampChemInfo <- cbind(fullSampChemInfo[,1:9], temp, fullSampChemInfo[,-c(1:9)])

# Find the xc and xt chemicals without a match by name and send them to Tony Williams for curation
xcxtChemsWithoutCCDmatch <- fullSampChemInfo[indXC | indXT,]
# How much of our xc-xt data is this
sum(is.na(xcxtChemsWithoutCCDmatch$DTXSID))  # rows of feature data without a matching chemical
sum(!is.na(xcxtChemsWithoutCCDmatch$DTXSID))
# 364/5835  # 6.24%
# Set up file for saving these rows of the data
xcxtChemsWithoutCCDmatch <- xcxtChemsWithoutCCDmatch[is.na(xcxtChemsWithoutCCDmatch$DTXSID),] 
# how many unique chemicals is this?
length(unique(xcxtChemsWithoutCCDmatch$Raw_Name))
# Remove the all-NA columns
xcxtChemsWithoutCCDmatch[,c("DTXSID", "PREFERRED_NAME", "CASRN")] <- NULL
# Number of features (rows) for each product category that didn't have a dashboard match (mostly shampoo and baby soap) 
as.data.frame(table(xcxtChemsWithoutCCDmatch$Category))
# Save these chemicals
write.table(xcxtChemsWithoutCCDmatch, file = paste(myPath, "data", "xcxtChemsWithoutCCDmatch.txt", sep= "/"), 
              sep = "\t", row.names = FALSE)
```
```{r read_curated_chemicals}
# Read in file of curated chemicals (generated by Tony Williams) that now has 
# DTXSIDs that can be used to query the dashboard for other metadata
curated_in <- read_xlsx(paste(myPath, "data", "xcxtChemsWithoutCCDmatch_TonyCurated.xlsx", sep = "/"))
# Pull the unique, curated DTXSIDs to perform a second query of the dashboard
curatedDTXSIDs <- unique(curated_in$DTXSID)
# Save these DTXSIDs to get ToxPrints, InChIKeys, etc
write.table(curatedDTXSIDs, file = paste(myPath, "data", "houseProdSSA_curatedChems_DTXSIDs.txt", sep = "/"), 
            quote = FALSE, row.names = FALSE, col.names = FALSE)
```

```{r read_from_dashboard}
# Read in dashboard query file and add the chemical identifiers to our full feature data object
curated_out <- read_xlsx(paste(myPath, "data", "houseProdSSA_curatedChems_CCDquery_byDTXSID.xlsx", sep = "/"), sheet = 2)
# Add dashboard data to curated_in
ind <- match(curated_in$DTXSID, curated_out$DTXSID)
ind2 <- which(!is.na(ind))
curated_in <- cbind(curated_in, "CASRN" = NA) 
curated_in[ind2, c("DTXSID", "PREFERRED_NAME", "CASRN")] <- curated_out[ind[ind2], c("DTXSID", "PREFERRED_NAME", "CASRN")]
# Now add to fullSampChemInfo
ind <- match(fullSampChemInfo$Raw_Name, curated_in$Raw_Name)
ind2 <- which(!is.na(ind))
fullSampChemInfo[ind2,c("DTXSID", "PREFERRED_NAME", "CASRN")] <- curated_in[ind[ind2], c("DTXSID", "PREFERRED_NAME", "CASRN")]
# Some entries are "-".  Replace with NA.
ind <- fullSampChemInfo == "-"
fullSampChemInfo[ind] <- NA


# Fill in the missing data in the main dashboard output table that was returned by searching for raw chemical name
# so that we have a quick reference with the raw and curated chemical identifiers
# Information is in curated_out, so add raw name in the input column to that object from curated_in for consistency
ind <- match(curated_out$DTXSID, curated_in$DTXSID)
ind2 <- which(!is.na(ind))
curated_out$INPUT[ind2] <- curated_in$Raw_Name[ind[ind2]]
# Now add these rows to the tps object
ind <- match(tps$INPUT, curated_out$INPUT)
ind2 <- which(!is.na(ind))
tps[ind2,] <- curated_out[ind[ind2],]
# Clean up
colnames(tps)[1] <- "Raw_Name"
tps$FOUND_BY <- NULL

# Insert a placeholder DTXSID for the chemicals that still don't have a match
# Will carry these through all the other data objects so all data uses DTXSID identifiers
ind <- which(is.na(tps$DTXSID))
placeholders <- paste(rep("DTXSID_unk_", length(ind)), as.character(1:length(ind)), sep = "")
# Add these to the tps object and the fullSampChemInfo object
tps$DTXSID[ind] <- placeholders
temp <- tps[ind,]
ind2 <- match(fullSampChemInfo$Raw_Name, temp$Raw_Name)
ind3 <- which(!is.na(ind2))
fullSampChemInfo$DTXSID[ind3] <- temp$DTXSID[ind2[ind3]]

# Save tps as master toxprints file
save(tps, file = paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# Save fullSampChemInfo for supplement
write.table(fullSampChemInfo, file = paste(myPath, "data", "fullSetOfSamplesWithAllChems.txt", sep= "/"), 
              sep = "\t", row.names = FALSE)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))

```


# Examine Dilution Effect

Most of our samples were run at 2 dilutions because some chemicals are more easily
extracted/detected at a different dilution. For example, in fabric upholstery and
cotton clothing samples, the more concentrated assays tended to be best for identifying 
lighter compounds and aromatics whereas hydrocarbons, long-chain alcohols, etc. were 
better observed in the more dilute assay. Use dimensionality reduction on chemical
occurrence to see if different dilutions of different products clearly separate.

```{r dilutionEffect}
### Start with the confirmed/tentative chemicals
# Read in the data object that has our full chemical by sample matrices
load(paste(myPath, "data", "chemXsamp_matrices_xcxt_full.RData", sep = "/"))

sampCats <- chemXsamp_matrices_xcxt$category
binmat <- chemXsamp_matrices_xcxt$binary

# Remove blanks 
ind <- grep("SB", colnames(binmat))
binmat[,ind] <- NULL
sampCats <- sampCats[-ind]

##### Chemical Pre-Filtering #####
chemcounts <- unlist(apply(binmat, 1, function(x) sum(!x == 0)))

# Get rid of chemicals only in 1 sample
ind <- chemcounts < 2
binmat <- binmat[!ind,]
chemcounts <- chemcounts[!ind]

# Now extract dilutions, which are included in the sample names
dilus <- strsplit(colnames(binmat), "_(?!.*_)", perl = TRUE)
dilus <- do.call("rbind", dilus)
dilus <- dilus[,2]

# Add names and transpose
#colnames(binmat) <- sampCats
binmat <- t(binmat)

# Use TSNE
set.seed(115)
my.tsne <- tsne(binmat, initial_dims = 2)
my.tsne <- data.frame(my.tsne)
pdb <- cbind(my.tsne, "Dilution" = dilus, "Category" = sampCats)

#library(plotly)
#plot_ly(data = pdb, x = ~X1, y = ~X2, type = 'scatter', mode = 'markers',  color = sampCats, symbol = dilus)

# Use ggplot
pdb$Dilution <- factor(pdb$Dilution, levels = c("1", "4", "5", "10", "20", "25", "50", "100", "125"), ordered = TRUE)
pdb$Category <- factor(pdb$Category)
# Save plot
pdf(file = paste(myPath, "plots", "TSNE_byDilution_allCatSamples_xcxt.pdf", sep = "/"), 
    width = 8, height = 6)
  ggplot(data = pdb, aes(x = X1, y = X2, shape = Category, color = Dilution)) +
    geom_point() +
    ggthemes::scale_color_gdocs(length(levels(pdb$Dilution))) +
    guides(color = guide_legend(title = "Dilution"))
dev.off()
```
```{r examine_removed_chemicals}
### Now look at the chemicals we don't retain for downstream analyses
# Read in the data object that has the full chemical by sample matrices
load(paste(myPath, "data", "chemXsamp_matrices_ns-xtui-xtuiPCB-xu_full.RData", sep = "/"))

sampCats <- chemXsamp_matrices_other$category
binmat <- chemXsamp_matrices_other$binary

# Remove blanks 
ind <- grep("SB", colnames(binmat))
binmat[,ind] <- NULL
sampCats <- sampCats[-ind]

##### Chemical Pre-Filtering #####
chemcounts <- unlist(apply(binmat, 1, function(x) sum(!x == 0)))

# Get rid of chemicals only in 1 sample
ind <- chemcounts < 2
binmat <- binmat[!ind,]
chemcounts <- chemcounts[!ind]

# Now extract dilutions, which are included in the sample names
dilus <- strsplit(colnames(binmat), "_(?!.*_)", perl = TRUE)
dilus <- do.call("rbind", dilus)
dilus <- dilus[,2]

# Add names and transpose
#colnames(binmat) <- sampCats
binmat <- t(binmat)

# Use TSNE
set.seed(115)
my.tsne <- tsne(binmat, initial_dims = 2)
my.tsne <- data.frame(my.tsne)
pdb <- cbind(my.tsne, "Dilution" = dilus, "Category" = sampCats)

#library(plotly)
#plot_ly(data = pdb, x = ~X1, y = ~X2, type = 'scatter', mode = 'markers',  color = sampCats, symbol = dilus)

pdb$Dilution <- factor(pdb$Dilution, levels = c("1", "4", "5", "10", "20", "25", "50", "100", "125"), ordered = TRUE)
pdb$Category <- factor(pdb$Category)
# Save plot
pdf(file = paste(myPath, "plots", "TSNE_byDilution_allCatSamples_non-xcxt.pdf", sep = "/"), 
    width = 8, height = 6)
  ggplot(data = pdb, aes(x = X1, y = X2, shape = Category, color = Dilution)) +
    geom_point() +
    ggthemes::scale_color_gdocs(length(levels(pdb$Dilution))) +
    guides(color = guide_legend(title = "Dilution"))
dev.off()

rm(list=setdiff(ls(), c("myPath", "prodGroups")))

```


# Final Processing Steps

## Combine Dilutions

Will use the resulting samples, including duplicates and repeats, to
assess within- product variability for occurrence, concentration,
functional use, and ClassyFire.

```{r combineDilutions}
# Load data
load(paste(myPath, "data", "masterSampleList.RData", sep = "/"))
load(paste(myPath, "data", "chemXsamp_matrices_xcxt_full.RData", sep = "/"))

# Replace chemical names with DTXSIDs using the finalized dashboard object from the Summarize Data section
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# The rows are in the same order, so can simply swap them out with the tps DTXSID column
# There are a couple of duplicate DTXSIDs (representing the same chemical) we need to remove first
indD <- which(duplicated(tps$DTXSID))
chemXsamp_matrices_xcxt$binary <- chemXsamp_matrices_xcxt$binary[-indD,]
chemXsamp_matrices_xcxt$group <- chemXsamp_matrices_xcxt$group[-indD,]
chemXsamp_matrices_xcxt$conc <- chemXsamp_matrices_xcxt$conc[-indD,]
# Now use DTXSIDs
row.names(chemXsamp_matrices_xcxt$binary) <- tps$DTXSID[-indD]
row.names(chemXsamp_matrices_xcxt$group) <- tps$DTXSID[-indD]
row.names(chemXsamp_matrices_xcxt$conc) <- tps$DTXSID[-indD]

# Make each matrix its own object
chemXsamp_binary <- chemXsamp_matrices_xcxt$binary
chemXsamp_conc <- chemXsamp_matrices_xcxt$conc
chemXsamp_group <- chemXsamp_matrices_xcxt$group

# Drop Blanks
ind <- grep("SB", colnames(chemXsamp_binary))
chemXsamp_binary[,ind] <- NULL
chemXsamp_conc[,ind] <- NULL
chemXsamp_group[,ind] <- NULL

# Combine Dilutions
# Get list of all sample #s. Duplicate samples have the same sample #, so include _DUP at this stage
# b/c we want to keep duplicates separate for now.
ind <- which(allSamps$Type == "Solvent Blank")
allSamps <- allSamps[-ind,] 
sampNames <- allSamps$`System ID`
ind <- which(allSamps$Type == "Duplicate")
sampNames[ind] <- paste(sampNames[ind], "_DUP", sep = "")
chemXsamp_binary_red <- c()
chemXsamp_conc_red <- c()
chemXsamp_group_red <- c()
for (i in 1:length(sampNames)){

  indS <- grep(sampNames[i], colnames(chemXsamp_binary))
  if (length(grep("DUP", colnames(chemXsamp_binary)[indS])) > 0){
    # This sample is either a duplicate or has a duplicate. Don't want to combine duplicates yet.
    if (length(grep("DUP", sampNames[i])) > 0){
      # All good, sample is a duplicate and will only return samples of the form #####_DUP_##
    } else if (length(grep("DUP", sampNames[i])) == 0) {
      # Sample is not a duplicate but grep pulled the DUP samples as well. Drop the DUP ones b/c 
      # we just want the sample
      ind <- grep("DUP", colnames(chemXsamp_binary)[indS])
      indS <- indS[-ind]
    }
  }
  
  # if only 1 dilution factor was used, we don't have to worry about combining the samples
  # if more than 1 dilution, take union of binary, mean of conc, and xc over xt for group
  if (length(indS) == 1){
    chemXsamp_binary_red <- cbind(chemXsamp_binary_red, chemXsamp_binary[,indS])
    chemXsamp_conc_red <- cbind(chemXsamp_conc_red, chemXsamp_conc[,indS])
    chemXsamp_group_red <- cbind(chemXsamp_group_red, chemXsamp_group[,indS])
  } else {
    chemXsamp_binary_red <- cbind(chemXsamp_binary_red, as.numeric(do.call("|", chemXsamp_binary[,indS])))
    chemXsamp_conc_red <- cbind(chemXsamp_conc_red, unlist(apply(chemXsamp_conc[,indS], 1, 
                                                                 function(x) mean(x, na.rm = TRUE))))
    chemXsamp_group_red <- cbind(chemXsamp_group_red, 
                                 unlist(apply(chemXsamp_group[,indS], 1, 
                                              function(x) ifelse(sum(is.na(x)) == 2, NA, 
                                                                 ifelse(sum(is.na(x)) == 1, x[!is.na(x)],
                                                                        ifelse("xc" %in% x, "xc","xt"))))))
  }
}
colnames(chemXsamp_binary_red) <- sampNames
colnames(chemXsamp_conc_red) <- sampNames
colnames(chemXsamp_group_red) <- sampNames
row.names(chemXsamp_binary_red) <- row.names(chemXsamp_binary)
row.names(chemXsamp_conc_red) <- row.names(chemXsamp_binary)
row.names(chemXsamp_group_red) <- row.names(chemXsamp_binary)

# Extract Product-specific matrices
# The order of samples in allSamps matches that in our matrices
prodList <- list()
for (i in 1:length(prodGroups)){
  ind <- allSamps$Product == prodGroups[i]
  prodList[[i]] <- list("binary" = chemXsamp_binary_red[,ind], 
                        "conc" = chemXsamp_conc_red[,ind], 
                      "group" = chemXsamp_group_red[,ind], 
                      "prod_names" = allSamps$`Customer ID`[ind])
}
names(prodList) <- prodGroups
# Save this object for downstream analysis
save(prodList, file = paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

rm(list=setdiff(ls(), c("myPath", "prodGroups")))  
```


## Combine Duplicates and Repeats

Will use the resulting set of samples for clustering, upset plots, and
machine learning model to classify samples into their product
categories.

```{r combineDupsReps}
# Get curated table of group levels and brands
prodOnt <- as.data.frame(read_xlsx(path = paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", 
                                                sep = "/")))
# Remove blanks
prodOnt <- prodOnt[!prodOnt$Group3 == "blank",]
# Change NA brand to "unknown"
prodOnt$`Anon Brand` <- as.character(prodOnt$`Anon Brand`)
indNA <- prodOnt$`Anon Brand` == "NA"
prodOnt$`Anon Brand`[indNA] <- "unknown"
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Step through each product category, combine duplicates and repeats, then concatenate
# all into 1 big matrix.  All matrices in prodList have the same number of rows (chemicals),
# so this makes concatenating them easier.

# First combine duplicates
binary <- list()
conc <- list()
for (i in 1:length(prodGroups)){
  # Use the master sample table to rename the sample names to our anonymized names
  ind <- match(colnames(prodList[[i]]$binary), prodOnt$MySysID)
  temp_binary <- prodList[[i]]$binary
  colnames(temp_binary) <- prodOnt$`Anon Sample 2`[ind]
  temp_conc <- prodList[[i]]$conc
  colnames(temp_conc) <- prodOnt$`Anon Sample 2`[ind]
  
  # Combine
  temp_binary_comb <- c()
  temp_conc_comb <- c()
  DUPs <- colnames(temp_binary)[grep("dup", colnames(temp_binary))]
  drop <- c()
  for (j in 1:length(DUPs)){
    indS <- which(substr(DUPs[j], 1, nchar(DUPs[j])-4) == colnames(temp_binary))
    indDup <- which(colnames(temp_binary) == DUPs[j])
    temp_binary_comb <- cbind(temp_binary_comb, unlist(apply(temp_binary[,c(indS, indDup)], 1, max)))
    temp_conc_comb <- cbind(temp_conc_comb, unlist(apply(temp_conc[,c(indS, indDup)], 1, 
                                                                   function(x) mean(x, na.rm = TRUE))))
    colnames(temp_binary_comb)[dim(temp_binary_comb)[2]] <- substr(DUPs[j], 1, nchar(DUPs[j])-4)
    colnames(temp_conc_comb)[dim(temp_conc_comb)[2]] <- substr(DUPs[j], 1, nchar(DUPs[j])-4)
    drop <- c(drop, indS, indDup)
  }
  binary[[i]] <- cbind(temp_binary[,-drop], temp_binary_comb)
  conc[[i]] <- cbind(temp_conc[,-drop], temp_conc_comb)
}
  
# Now combine repeats
for (i in 1:length(binary)){
  drop <- c()
  REPs <- colnames(binary[[i]])[grep("rep", colnames(binary[[i]]))]
  temp_binary_comb <- c()
  temp_conc_comb <- c()
  for (j in 1:length(REPs)){
    indS <- which(substr(REPs[j], 1, nchar(REPs[j])-4) == colnames(binary[[i]]))
    indRep <- which(colnames(binary[[i]]) == REPs[j])
    temp_binary_comb <- cbind(temp_binary_comb, unlist(apply(binary[[i]][,c(indS, indRep)], 1, max)))
    temp_conc_comb <- cbind(temp_conc_comb, unlist(apply(conc[[i]][,c(indS, indRep)], 1, 
                                                                   function(x) mean(x, na.rm = TRUE))))
    colnames(temp_binary_comb)[dim(temp_binary_comb)[2]] <- substr(REPs[j], 1, nchar(REPs[j])-4)
    colnames(temp_conc_comb)[dim(temp_conc_comb)[2]] <- substr(REPs[j], 1, nchar(REPs[j])-4)
    drop <- c(drop, indS, indRep)
  }
  binary[[i]] <- cbind(binary[[i]][,-drop], temp_binary_comb)
  conc[[i]] <- cbind(conc[[i]][,-drop], temp_conc_comb)
  # Re-order columns
  ind <- as.numeric(substr(colnames(binary[[i]]), 8, nchar(colnames(binary[[i]]))))
  ind <- order(ind)
  binary[[i]] <- binary[[i]][,ind]
  conc[[i]] <- conc[[i]][,ind]
}

# Save these two matrices 
names(binary) <- prodGroups
names(conc) <- prodGroups
allComb_BinAndConc <- list("binary" = binary, "conc" = conc)
save(allComb_BinAndConc, file = paste(myPath, "data", "allCombDilDupRep_BinAndConcMats.RData", sep = "/"))

# Now concatenate them into a single matrix with all samples and have a corresponding
# vector designating which samples are which category
binaryMat <- do.call(cbind, binary)
concMat <- do.call(cbind, conc)
prodType <- rep(prodGroups, as.numeric(unlist(lapply(binary, function(x) dim(x)[2]))))
allComb_BinAndConc_concat <- list("binary" = binaryMat, "conc" = concMat, "prodType" = prodType)
save(allComb_BinAndConc_concat, file = paste(myPath, "data", "allCombDilDupRep_BinAndConcMats_concat.RData", sep = "/"))

rm(list=setdiff(ls(), c("myPath", "prodGroups")))

```



# Make Upset plot

```{r upset}
# Get sample list
load(paste(myPath, "data", "masterSampleList.RData", sep = "/"))

# Load matrices for chemical occurrence
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Combine into 1 occurrence matrix
chemXsamp_binary_red <- c()
prodind <- c()
for (i in 1:length(prodGroups)){
  chemXsamp_binary_red <- cbind(chemXsamp_binary_red, prodList[[i]][[1]]) 
  prodind <- c(prodind, rep(prodGroups[i], dim(prodList[[i]][[1]])[2]))
}

# Aggregate by product
upset_list <- vector("list", length(prodGroups))
for (i in 1:length(prodGroups)){
  upset_list[[i]] <- which(unlist(apply(chemXsamp_binary_red[,prodind == prodGroups[i]], 1, sum))  > 0)
}
names(upset_list) <- prodGroups

# Chemical counts per product group
lengths(upset_list)

pdf(file = paste(myPath, 
                 "plots", 
                 "Fig2-ProductGroup_chemOccurrence_upsetPlot.pdf", sep = "/"), 
    width = 6, height = 3.7, onefile=FALSE)
u <- upset(fromList(upset_list), order.by = "freq", point.size = 3, line.size = 1.5, 
      mainbar.y.label = "Chemical Intersections", sets.x.label = "Total Chemicals", 
      text.scale = c(1.5, 1.3, 1.3, 1.1, 1.4, 1.2))
print(u)
dev.off()

print(u)
```

# Get the set of chemicals that are present in all 5 categories and save for the paper supplement
```{r ubiquitous_chemicals}
chems <- lapply(upset_list, names)
sharedChems <- Reduce(intersect, chems)

# Add CAS and name
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))
ind <- match(sharedChems, tps$DTXSID)
sharedChems <- data.frame("DTXSID" = sharedChems, "PREFERRED_NAME" = tps$PREFERRED_NAME[ind], 
                          "CAS" = tps$CASRN[ind], "Cotton Clothing" = NA, "Shampoo" = NA,
                          "Baby Soap" = NA, "Fabric Upholstery" = NA, "Silicone Kitchen Tools" = NA)
# Step through the data to get the number of samples each chemical occurs in
for (i in 1:dim(sharedChems)[1]){
  for (j in 1:length(prodGroups)){
    ind <- which(row.names(prodList[[j]][[1]]) == sharedChems$DTXSID[i])
    sharedChems[i,(j+3)] <- sum(prodList[[j]][[1]][ind,])  #/dim(prodList[[j]][[1]])[2]
  }
}
# Save
write.table(sharedChems, file = paste(myPath, "results", "All25sharedChems_withProdCatCounts.txt", sep = "/"), row.names = FALSE)


rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```



# Annotate Chemicals

The unique set of chemicals identified (confirmed or tentative; xc or
xt) across all samples was saved as a text file during the
processRawData function. This was run through the CompTox Dashboard to
obtain chemical identifiers (DTXSID, CAS, InChIKey) for ClassyFire and
the ToxPrints for functional uses. Perform annotations first to be able
to add them to certain plots in the downstream analysis if desired.


## Functional Uses

For all chemicals, run Phillips et. al. 2017 functional use QSUR model.
Only keep those in the applicability domain and with a probability \>=
0.8. Then, if a chemical has a reported use in FUse DB, assign it to
that chemical as well with a probability of 1.

```{r funcUse}
# Load combined duplicates data
load(file = paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Read in dashboard query file that has the toxprints and process.  Input for function 
# to predict uses is a tab-separated file with ID and the toxprints
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# Remove duplicate DTXSIDs
tps <- tps[!duplicated(tps$DTXSID),]

# Reduce to chemical identifiers and ToxPrints
# Keep up to QSAR SMILES and then just tps (starts at 46th column)
colnames(tps)[1:50]
tps <- tps[,c(1:6,46:dim(tps)[2])]

# Drop chemicals without ToxPrint data
ind <- which(is.na(tps$`atom:element_main_group`))
curatedTPs <- tps[-ind,]  


##### Reported and Predicted Uses from ChemExpo ########
# Find which chemicals already have predicted functional uses in ChemExpo
fuseDB <- read.csv(file = paste(myPath, "data/ChemExpo_functional_uses_20230817_HhldProdChems.csv", sep = "/"))
# Reduce this big matrix to just our chemicals
ind <- (fuseDB$DTXSID %in% curatedTPs$DTXSID) 
temp <- fuseDB[ind, c("DTXSID", "Harmonized.Functional.Use")]  # "Reported.Functional.Use", 
# Reduce to unique rows (different documents can report the same use for the same chemical)
temp <- unique(temp)
# There are also rows with a blank harmonized use (remove these)
temp <- temp[!temp$Harmonized.Functional.Use == "",]

# Turn this into a matrix of chemical by use
repUseMat <- as.data.frame(matrix(data = NA, nrow = length(curatedTPs$DTXSID), 
                                  ncol = length(unique(temp$Harmonized.Functional.Use)),
                                        dimnames = list(curatedTPs$DTXSID, unique(temp$Harmonized.Functional.Use))))
# Populate the data frame
for (i in 1:dim(repUseMat)[1]){
  ind <- (temp$DTXSID == row.names(repUseMat)[i])
  repUseMat[i, colnames(repUseMat) %in% temp$Harmonized.Functional.Use[ind]] <- 1
}
# Set NAs to 0
repUseMat[is.na(repUseMat)] <- 0
# How many chemicals are reported for each use?
a <- apply(repUseMat, 2, sum)
as.data.frame(a[order(a, decreasing = TRUE)])
```
##### Predict Uses for Remaining Chemicals Using the QSURs ######
```{r qsur_prep}
chems4qsurs <- curatedTPs[, !colnames(curatedTPs) %in% 
                           c("Raw_Name", "PREFERRED_NAME", "CASRN", "INCHIKEY", "QSAR_READY_SMILES")]
colnames(chems4qsurs)[1] <- "M_NAME"
# Need to save this b/c the input for the prediction function is a file location
write.table(chems4qsurs, file = paste(myPath, "data/chems2predFUfor_TPs.tsv", sep = "/"), sep = "\t", row.names = FALSE)
```

```{r make_qsur_predictions, eval=FALSE}
# Following Suggested Code in the QSUR R Package ReadMe 
TPfile <- paste(myPath, "data", "chems2predFUfor_TPs.tsv", sep = "/")
chems <- read_toxprints(io = TPfile, source = "chemotyper")

# Load the QSUR models
qsurs <- qsur_models()

# Predict with all QSUR models
preds <- predict_all_QSUR(models = qsurs, df = chems, chemical_id ="M_NAME")

# Get predictions that are within the AD
valids <- in_domain(df = chems, models = qsurs, chemical_id ="M_NAME")

# 2 of the models are missing in the valids object.  These are columns 31 and 32.
setdiff(colnames(preds), colnames(valids))
# They have 3 and 0 chemicals with a prediction prob >= 0.8 so just drop them for this analysis
#preds <- preds[,-c(31,32)]
# Set the probability to 0 for those out of the AD
indOutAD <- (valids == FALSE) 
preds[indOutAD] <- 0
# Still use the 0.8 cutoff, but keep the numeric value to assign 1 use to each chemical later on
preds[,-1] <- apply(preds[,-1], 2, function(x) ifelse(x >= 0.8, x, 0))

# Some chemicals didn't have ToxPrints/predictions were not available. Want to keep identical
# rows between this and the reported use matrix, so fill NAs with 0s
preds[is.na(preds)] <- 0

# Put chemical column as row names and remove it
preds <- as.data.frame(preds)
# How many chemicals are predicted for each use
a <- apply(preds, 2, function(x) sum(x > 0.5))
as.data.frame(a[order(a, decreasing = TRUE)])

names.qsurs <- names(qsurs) 
save(names.qsurs, preds, 
     file = paste(myPath, "results",
                         "QSURPreds.RData", sep = "/"))
```

```{r make_use_plot}
load(file = paste(myPath, "results", 
                         "QSURPreds.RData", sep = "/"))

### For the higher-level plot, want to have both predicted and reported uses in 1 matrix
### Keep repUseMat as-is until the plotting stage as I want to use that for category-specific plots
# But need to make column names lowercase and replace spaces with "_"
colnames(repUseMat) <- gsub(" ", "_", tolower(colnames(repUseMat)))
# Remove any uses that don't have a hit for any chemical
todrop <- apply(repUseMat, 2, function(x) sum(x) == 0)
if (any(todrop)){
  repUseMat[,todrop] <- NULL
}
# Save just the reported use matrix here 
save(repUseMat, file = paste(myPath, "results", "RepHarmonizedUses_chemsAcrossAllSamps.RData", sep = "/"))

# Some of the harmonized uses map to multiple qsur models. For the high-level plot, just want to
# look at each row/chemical. If there is a 1, it is reported. If 0.8 < x < 1, it is predicted. If < 0.8, there
# is no associated use. To report the most data in the supplement, only aggregate columns that have
# identical names.

sharedUses <- intersect(names.qsurs, colnames(repUseMat))
# Keep track of which use column belongs to each and allow for data merging
repUseMat2 <- repUseMat
ind <- colnames(repUseMat2) %in% sharedUses
colnames(repUseMat2)[ind] <- paste("shared.", colnames(repUseMat2)[ind], sep = "")  
colnames(repUseMat2)[!ind] <- paste("rep_use.", colnames(repUseMat2)[!ind], sep = "")
# Do the same for the predicted columns
ind <- colnames(preds) %in% sharedUses
colnames(preds)[ind] <- paste("shared.", colnames(preds)[ind], sep = "")  
colnames(preds)[!ind] <- paste("pred_use.", colnames(preds)[!ind], sep = "")

# Merge these two objects. Fastest is rbindlist() where the objects need to be data tables
# with a key column.
colnames(preds)[1] <- "DTXSID"
repUseMat2 <- as.data.table(cbind("DTXSID" = row.names(repUseMat2), repUseMat2), keep.rownames = FALSE)
# First obtain the max value of each row for all the shared columns
test <- bind_rows(preds, repUseMat2) %>% 
                  group_by(DTXSID) %>% 
                  summarise(across(starts_with("shared"), list(max = max)))
# Drop appended column name text
colnames(test) <- gsub("_max", "", colnames(test))
# Do a simple merge to get all the other columns
test2 <- merge(preds, repUseMat2, by = "DTXSID", all = TRUE)
# Remove the "shared" columns in test2 and replace them with those in test
use.pred.rep <- test2
use.pred.rep <- use.pred.rep[,-grep("shared", colnames(use.pred.rep))]
use.pred.rep <- merge(test, use.pred.rep, by = "DTXSID", all = TRUE)

# Remove any uses that don't have a hit for any chemical
todrop <- which(unlist(apply(use.pred.rep[,-1], 2, function(x) sum(x) < 0.1))) + 1
if (length(todrop) > 0){
  use.pred.rep[,todrop] <- NULL
}

# Save these predictions.  First add chemical names so I can match with other matrices.
ind <- match(use.pred.rep$DTXSID, curatedTPs$DTXSID)
use.pred.rep <- as.data.frame(use.pred.rep)
use.pred.rep <- cbind("DTXSID" = use.pred.rep$DTXSID, "PREFERRED_NAME" = curatedTPs$PREFERRED_NAME[ind],
                      "CASRN" = curatedTPs$CASRN[ind], use.pred.rep[,-1])
save(use.pred.rep, file = paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs.RData", sep = "/"))

# Save .txt version for supplemental data file 
write.table(use.pred.rep, file = paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs_data.txt", 
                                       sep = "/"), sep = "\t", row.names = FALSE)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## Make Functional Use Plots

Have one plot showing all 5 categories and the distribution of predicted
and reported uses. Have one plot for each product category showing the
number of reported uses in each sample.

```{r usePlots}
# Combined reported and predicted use matrix
load(file = paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs.RData", sep = "/"))

# Just reported uses
load(file = paste(myPath, "results", "RepHarmonizedUses_chemsAcrossAllSamps.RData", sep = "/"))

# prodList is a list of all 5 groups with 4 elements each.  Pull the binary matrices and concatenate them.
load(file = paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

allProdsMat <- list()
for (i in 1:length(prodGroups)){
  temp <- prodList[[i]][[1]]
  colnames(temp) <- prodList[[i]][[4]]
  allProdsMat$binary <- cbind(allProdsMat$binary, temp)
  allProdsMat$prodType <- c(allProdsMat$prodType, rep(prodGroups[i], dim(temp)[2]))
}

# The row names are the same, just need to reduce our chemical X sample matrix to those with uses
allProdsMat$binary <- allProdsMat$binary[row.names(allProdsMat$binary) %in% use.pred.rep$DTXSID,]

## Get a summary plot for all categories.  Want a split bar for each category.  One color for all chemicals,
## one for reported use, and one for predicted use (>= 0.8)
# First load master sample list so I can use anonymized sample names in the product-specific figures
refTable <- as.data.frame(read_xlsx(paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", sep = "/")))
# Remove blanks
refTable <- refTable[!refTable$Group3 == "blank",]

# Step through each category, select samples, and aggregate uses over chemicals 
allCatUses <- c()
prodCatUses <- list()
# Build data objects needed for plotting
for (i in 1:length(prodGroups)){
  temp <- allProdsMat$binary[,allProdsMat$prodType == prodGroups[i]]
  catChems <- which(apply(temp, 1, sum) > 0) # all chemicals present in samples of this category
  
  # Show the number of chemicals per category
  print(prodGroups[i])
  print(length(catChems))
  
  # High Level
  # For each row/chemical, if there is a 1 for any use, then it is a reported use -> label it as such
  # if there is no use with a value of 1 but a value between 0.8 and 1, then a use was successfully predicted
  # if the first two cases are not met, then assign that chemical as not having a functional use
  useFlags <- apply(use.pred.rep[catChems,-c(1:3)], 1, function(x) ifelse(any(x > 0.9999), "Reported", 
                                                              ifelse(any(x >= 0.8), "Predicted", NA)))
  allCatUses <- rbind(allCatUses, cbind(prodGroups[i], length(catChems), sum(useFlags == "Reported", na.rm = TRUE),
                                        sum(useFlags == "Predicted", na.rm = TRUE), sum(is.na(useFlags))))
  
  # Per Category
  # Want to count those with a reported use per sample. 
  repUses <- c()
  for (j in 1:dim(temp)[2]){
    sampChems <- which(temp[,j] == 1)
    repUses <- rbind(repUses, apply(repUseMat[sampChems,], 2, sum))
  }
  
  # Get anonymized sample and brand name, subtype. temp and refTable are in the same order, just have to 
  indSamp <- refTable$Group2 == prodGroups[i]
  prodCatUses[[i]] <- cbind(colnames(temp), gsub(" ", "_", refTable$`Anon Sample 2`[indSamp]), 
                            refTable$`Anon Brand`[indSamp], gsub(" ", "_", refTable$Group3[indSamp]), repUses)
  colnames(prodCatUses[[i]]) <- c("CustomerID", "SampleName", "BrandName", "Type", colnames(repUses))
}
colnames(allCatUses) <- c("Category", "Unique Chemicals", "Reported Use", "Predicted Use", "Unknown Use")
allCatUses <- as.data.frame(allCatUses)
names(prodCatUses) <- prodGroups


# Plot high level
df <- allCatUses[,-2]
df <- df %>% gather(Annotation, Count, -Category)
df$Count <- as.numeric(df$Count)
df$Annotation <- factor(df$Annotation, levels = c("Reported Use", "Predicted Use", "Unknown Use"), 
                        ordered = TRUE)
df$Category <- factor(df$Category, level = prodGroups, ordered = TRUE)
Fig3b <- ggplot(df, aes(fill = Annotation, y = Count, x = Category)) +
  geom_bar(position = "stack", stat = "identity") +
  #geom_bar(position = "dodge", stat = "identity") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme(text = element_text(size = 13)) +
  labs(title = "Functional Use Distribution of Product Category Chemicals", 
       x = "Product Category", y = "Unique Chemicals")
pdf(file = paste(myPath, "plots/functionalUse", "funUseAnnoAll5CatsBarPlot_withDupReps.pdf", sep = "/"), width = 8, height = 7)
  print(Fig3b)
dev.off()
save(Fig3b, file = paste(myPath, "plots/functionalUse/Fig3b.RData", sep="/"))
# Save data for figure 
write.table(df, file = paste(myPath, "results", 
                             "funUseAnnoAll5CatsBarPlot_withDupReps_data.txt", sep = "/"), 
            sep = "\t", row.names = FALSE)
```

# Build a heatmap for each product category
# Want to show product subcategory and anonymized brand, so use complex heatmap
```{r make_category_heatmap}
useData <- list()
plot <- FALSE
savedata <- FALSE
for (i in 1:length(prodGroups)){
  
  temp <- prodCatUses[[i]][,-c(1:4)]
  
  # Shorten some of the use names for plotting
  ind <- which(!is.na(match(colnames(temp), c("processing_aids_not_otherwise_specified",
                                              "no_specific_technical_function",
                                              "surfactant_(surface_active_agent)",
                                              "propellants,_non-motive_(blowing_agents)"))))
  colnames(temp)[ind] <- c("processing_aids", "no_specific_function", "surfactant", "propellants,_non-motive")
  
  temp <- as.data.frame(apply(temp, 2, as.numeric))
  row.names(temp) <- prodCatUses[[i]][,2]
  tempAnno <- as.data.frame(prodCatUses[[i]][,1:4])
  
  # The columns I want to use for annotations need to be ordered factors. Subset to the product
  # category so the brand labels don't get mixed up
  tempAnno$BrandName <- as.factor(as.character(tempAnno$BrandName))
  tempAnno$Type <- as.factor(as.character(tempAnno$Type))
  
  palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
  brand_col <- palettes$`Tableau 20`$value[1:length(unique(tempAnno$BrandName))]
  names(brand_col) <- levels(tempAnno$BrandName)
  
  type_col <- rcartocolor::carto_pal(n = (1 + length(unique(tempAnno$Type))), name = "Antique")
  type_col <- type_col[-2]
  names(type_col) <- levels(tempAnno$Type)
  
  # Minimum number of elements for the palette is 3, so it adds a 3rd color. Remove this.
  if(length(unique(tempAnno$Type)) < 3){
    type_col <- type_col[1:length(unique(tempAnno$Type))]
  }
  
  # To visualize the colors that are pulled
  #if (test){
  #  plot(NULL, xlim =c(0, length(brand_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
  #  rect(0:(length(brand_col)-1), 0, 1:length(brand_col), 1, col = brand_col)
  #  plot(NULL, xlim =c(0, length(type_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
  #  rect(0:(length(type_col)-1), 0, 1:length(type_col), 1, col = type_col)
  #}
  
  column_ha <- rowAnnotation(SubCategory = tempAnno$Type, Brand = tempAnno$BrandName,   
                                 col = list("SubCategory" = type_col, "Brand" = brand_col))
  temp[temp == 0] <- NA
  col_fun = colorRamp2(c(1, max(temp, na.rm = TRUE)), c("darkblue", "yellow"))
  
  # Sort uses by most chemicals
  useCounts <- unlist(apply(temp, 2, function(x) sum(x, na.rm = TRUE)))
  ind0 <- useCounts == 0
  temp <- temp[,!ind0]
  temp <- temp[,order(useCounts[!ind0], decreasing = TRUE)]
  
  # For count legend
  mySeq <- round(seq.int(from = 1, to = max(temp, na.rm = TRUE), length.out = 4))
  
  # Make plot
  if (prodGroups[i] == "Fabric Upholstery"){
    ht <- Heatmap(temp, col = col_fun, 
                  heatmap_legend_param = list(title = "Chemical Count", at = mySeq, labels = as.character(mySeq)), 
                  na_col = "white", row_title = "Samples", 
                  column_title = paste("Reported Functional Uses in ", prodGroups[i], " Products", sep = ""),
                  cluster_rows = TRUE, cluster_columns = FALSE, show_row_names = TRUE, show_column_names = TRUE,
                  column_names_rot = 90, rect_gp = gpar(col = "white", lwd = 1.4, cex = 1.1),
                  column_names_gp = grid::gpar(fontsize = 9), row_names_gp = grid::gpar(fontsize = 9))
  } else {
    ht <- Heatmap(temp, col = col_fun, 
                  heatmap_legend_param = list(title = "Chemical Count", at = mySeq, labels = as.character(mySeq)), 
                  na_col = "white", row_title = "Samples", left_annotation = column_ha,
                  column_title = paste("Reported Functional Uses in ", prodGroups[i], " Products", sep = ""),
                  cluster_rows = TRUE, cluster_columns = FALSE, show_row_names = TRUE, show_column_names = TRUE,
                  column_names_rot = 90, rect_gp = gpar(col = "white", lwd = 1.4, cex = 1.1),
                  column_names_gp = grid::gpar(fontsize = 9), row_names_gp = grid::gpar(fontsize = 9))
  }
  
  if (plot){
    pdf(file = paste(myPath, "plots/functionalUse", paste("prodCatHeatmap_ReportedUses_", prodGroups[i], 
                      "_withDupReps.pdf", sep = ""), sep = "/"), width = 10, height = 7.5)
      draw(ht)
    dev.off()
  }
    
  # Save data for each figure 
  useTable <- cbind("Category" = rep(prodGroups[i], dim(temp)[1]), prodCatUses[[i]][,-1])
  if (savedata){
    write.table(useTable, file = paste(myPath, "results", paste("prodCatHeatmap_ReportedUses_", prodGroups[i], 
                "_withDupReps_data.txt", sep = ""), sep = "/"), sep = "\t", row.names = FALSE)
  }
  useData[[i]] <- temp
}
names(useData) <- prodGroups
```
```{r top_uses}
# Assess within-product category top uses
for (i in 1:length(prodGroups)){
  print(prodGroups[i])
  print("Top 5 uses and counts")
  print(apply(useData[[i]], 2, mean)[1:5])
  print("Number of unique uses")
  print(dim(useData[[i]])[2])
}

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## ClassyFire

Use the treeCompareR package written by Paul Kruse to annotate my
chemicals via the ClassyFire API and then make a series fo tree
diagrams.

```{r install_treecomparer, eval=FALSE}
devtools::install_git(url = 'https://bitbucket.epa.gov/scm/~pkruse/treecomparer.git', 
                       ref = "merge_kr_rcpp_kruse", git = "external")
```

```{r curated_output}
# Read in my curated dashboard output object
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# Remove duplicate DTXSIDs
tps <- tps[!duplicated(tps$DTXSID),]
# Drop chemicals without a dashboard match (will be NA after DTXSID column)
#ind <- which(is.na(tps$INCHIKEY))
ind <- which(is.na(tps$QSAR_READY_SMILES))
tps <- tps[-ind,]  
# Write these INCHIKEYs for use in ClassyFire API
#write.table(tps$INCHIKEY, file = paste(myPath, "data", "chemINCHIKEYsForClassyFire.txt", sep = "/"),
#            row.names = FALSE, col.names = FALSE, quote = FALSE)
write.table(tps$QSAR_READY_SMILES, file = paste(myPath, "data", "chemSMILEsForClassyFire.txt", sep = "/"),
            row.names = FALSE, col.names = FALSE, quote = FALSE)
```

```{r classyfireR, eval=FALSE}
########################################################################## 
# Using the Classy Fire R Package 
# Access the API via the R package (installed using install_github function)
library(classyfireR)
InChI_Keys <- tps$INCHIKEY
CFout <- purrr::map(InChI_Keys, get_classification)

# Loop through the output to build a matrix for the supplemental data
CFresult <- as.data.frame(matrix(data = NA, nrow = length(CFout), ncol = 11, 
                                 dimnames = list(InChI_Keys, c("DTXSID", "PREFERRED_NAME", "CASRN", "kingdom", "superclass",
                                                               "class", "subclass", "level 5", "level 6", "level 7", "level 8"))))
for (i in 1:length(CFout)){
  if (!is.null(CFout[[i]])){
    temp <- classification(CFout[[i]])
    CFresult[i,4:(3 + dim(temp)[1])] <- temp$Classification
  }
}
# Add chemical identifiers
ind <- match(InChI_Keys, tps$INCHIKEY)
CFresult[,1:3] <- tps[ind, 2:4]
# Remove any chemicals that were not classified (will be NA for Kingdom)
CFresult <- CFresult[!is.na(CFresult$kingdom),]
# Look at classification distributions
as.data.frame(table(CFresult$kingdom))
as.data.frame(table(CFresult$superclass))
as.data.frame(table(CFresult$class))
# Save table
write.table(CFresult, file = paste(myPath, "results", "ClassyFireAnnotation_allChems_batchAPI_2024-05-28.txt", sep = "/"), 
              sep = "\t", row.names = FALSE)
########################################################################
```

```{r ClassyFire_online_batch, eval=FALSE}
#######################################################################
# Using ClassyFire online batch search
CFresult <-read.csv(file = paste(myPath, 
                                 "data", 
                                 "houseProdNTA_chems_ClassyFire_batchquery_2023-12-07.csv",
                                 sep="/"))
                                                 
#CFresult <- read.csv(file = "C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsSSA/houseProdSSA_chems_ClassyFire_batchquery_2023-12-07.csv")
# Remove any chemicals that couldn't be classified
CFresult <- CFresult[!CFresult$ClassyFy.Status == "Failed",]
# Match with curatedHPssa object to add chemical name, DTXSID, and CAS
ind <- match(CFresult$InChIKey, curatedHPssa$INCHIKEY)
CFresult <- cbind("DTXSID" = curatedHPssa$DTXSID[ind], "PREFERRED_NAME" = curatedHPssa$PREFERRED_NAME[ind], 
                  "CASRN" = curatedHPssa$CASRN[ind], CFresult)
CFresult$ClassyFy.Status <- NULL
# Save object for manuscript supplemental data
write.table(CFresult, file = paste(myPath, "results", "ClassyFireAnnotation_allChems_batchAPI.txt", sep = "/"), 
              sep = "\t", row.names = FALSE)
#########################################################################
```

# Skip above 2 blocks and continue here to use treeCompareR
# Classify my chemicals
```{r run_classifire,eval=FALSE}
curatedHPssa<- data.table(tps)
myClassified <- classify_inchikeys(curatedHPssa$INCHIKEY, 
                                   tax_level_labels = chemont_tax_levels, 
                                   wait_min = 0.5)
# Run again for chemicals that didn't work from this first step
#myClassified <- classify_by_smiles(myClassified)
save(myClassified,
     curatedHPssa,
     file = paste(myPath, "results", 
                  "classyfire-output.RData", sep = "/"))
```

```{r run_treeCompareR, eval=FALSE}
load(file = paste(myPath, "results", 
                  "classyfire-output.RData", sep = "/"))
# Examine classifications
head(myClassified)
as.data.frame(table(myClassified$report))

# Set up the chemOnt tree
tax_nodes <- jsonlite::read_json('http://classyfire.wishartlab.com/tax_nodes.json')
length(tax_nodes)
tax_nodes[[1]]
str(tax_nodes[[1]])
# Organize nodes and ontology info
tax_nodes[[1]]$parent_chemont_id <- NA
chemont_taxnodes <- data.frame(
  'Name' = sapply(tax_nodes, function(t) {t[[1]]}),
  'ID' = sapply(tax_nodes, function(t) {t[[2]]}),
  'Parent_ID' = sapply(tax_nodes, function(t) {t[[3]]}))
head(chemont_taxnodes)
# Build the ontology
chemont_taxonomy <- generate_taxonomy_tree(tax_nodes = chemont_taxnodes)
str(chemont_taxonomy)
save(chemont_taxonomy,
     file = paste(myPath, "results", 
                  "classyfire-taxonomy-tree.RData", sep = "/"))
```

```{r display_taxonomy_tree}
load(file = paste(myPath, "results", 
                  "classyfire-output.RData", sep = "/"))
load(file = paste(myPath, "results", 
                  "classyfire-taxonomy-tree.RData", sep = "/"))
# Finalize tree and test view
chemont_tree <- chemont_taxonomy
ggtree(chemont_tree) + layout_circular()

# Remove NAs and convert my data to wide form
myData <- myClassified[!is.na(myClassified$level),]
myData <- pivot_wider(myData[,c(1:3,5:6)], 
                      names_from = "level", 
                      values_from = "name")
myData <- myData[,c(1:9,11,10)]
myData <- cbind(myData, "level9" = NA, "level10" = NA, "level11" = NA)

# add Chemical names and product type to this data
ind <- match(myData$identifier, curatedHPssa$INCHIKEY)
myData <- cbind("Chemical" = curatedHPssa$PREFERRED_NAME[ind], myData)

# Look at how our SSA chemicals span the full ontology
pdf(file = paste(myPath, "plots", "chemsInFullTree_AllChems.pdf", sep = "/"))
display_subtree(data_1 = myData, name_1 = 'HouseProdSSA', show_tips=FALSE, clade_level=2, clade_opts = list(fontsize=4, wrap=10))
dev.off()
display_subtree(data_1 = myData, name_1 = 'HouseProdSSA', show_tips=FALSE, clade_level=2, clade_opts = list(fontsize=4, wrap=10))
```
# Visualize the tree spanned by just our chemicals
```{r subtree_visualizaton}
    pruned_tree <- prune_tree(tree = chemont_tree,
                              adjust_branch_length = FALSE,
                              tax_level_labels = chemont_tax_levels,
                              keep_descendants = NULL, 
                              prune_to = myData) 

   Fig3a <- display_subtree(base_tree = pruned_tree, 
                  show_tips=FALSE,
                #  layout="rectangular",
                  base_opts=list(size=0.25),
                  clade_level=2, 
                  clade_opts = list(fontsize=5, wrap=25))
   Fig3a <- Fig3a+ theme(plot.margin = unit(c(2.5,2.5,2.5,2.5), "in"))
   ggsave( Fig3a, width = 8, height = 8,file = paste(myPath, 
                   "plots", "AllMyChems_subtree.png", sep = "/")) 
  

# Make this subtree a tree object we can plot subtrees on
myFullTree <- prune_tree(tree = chemont_tree, prune_to = myData)
# Check it is correct by plotting
ggtree(myFullTree) + layout_circular()
#prune_and_display_subtree(myData, show_tips = FALSE)

# Now do for each product group individually.  Load needed data
# Need to go to the clustering section , which is where 
load(paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))
myProds <- unique(allProdTypesMat$prodType)
for (i in 1:length(myProds)){
  # Samples of type i
  prodSamps <- allProdTypesMat$prodType == myProds[i]
  # Chems measured in samples of type i
  prodChems <- row.names(allProdTypesMat$binary)[which(unlist(apply(allProdTypesMat$binary[, prodSamps], 
                                                                    1, sum)) > 0)]
  # Now reduce full tree to tree for product type i. Note that not all chemicals had dashboard entries, 
  # so a couple of chemicals from each product type will be missing
  ind <- match(prodChems, myData$Chemical)
  temp <- myData[ind,]
  temp <- temp[!is.na(temp$Chemical),]
  
  # Plot subtree
  pdf(file = paste(myPath, "plots", paste("AllMyChems_subtree_with", myProds[i], "Chems.pdf", sep = ""), sep = "/"))
  print(display_subtree(base_tree = myFullTree, 
                        base_name = "All Product Chemicals", 
                        data_1 = temp, 
                  clade_opts = list(fontsize=4, wrap=30),
                  name_1 = paste(myProds[i], "Chems", sep = " ")))
  dev.off()
}
```
# Can visualize a numerical value overlaid on this tree.  Start with just the
# number of samples each chemical occurs in. Need to add a column to the object
# myClassified that has the sample count (just sum rows of chemXsamp_binary_full.RData).
```{r Make_Fig3}
load(file = paste(myPath, "plots/functionalUse/Fig3b.RData", sep="/"))
Fig3a <- display_subtree(base_tree = pruned_tree, 
                  show_tips=FALSE,
                #  layout="rectangular",
                  base_opts=list(size=0.25),
                  clade_level=2, 
                  clade_opts = list(fontsize=2, wrap=25)) + 
  theme(plot.margin = unit(c(1,0,0.25,0), "in"))
Fig3b <- Fig3b + theme(axis.text.x = element_text(size=7),
                       plot.title= element_text(size=10),
                       legend.text=element_text(size=7),
                       legend.title=element_blank())+
  ggtitle("Functional Use of Chemicals") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 8))
ggarrange(Fig3a,Fig3b)
pdf(paste(myPath, "plots", 
                  "Fig3-ChemicalClassandUse.pdf", sep = "/"),
    height=3,
    width=8)
ggarrange(Fig3a,Fig3b,
    labels=c("A","B"))
dev.off()
```

```{r visualize tree, eval=FALSE}
load(file = paste(myPath, "results", 
                  "classyfire-output.RData", sep = "/"))
myClassified <- subset(myClassified, !is.na(level))
classifyerlevels <- unique(myClassified$level)
myClassified <- reshape(myClassified, idvar=c("identifier","smiles","classification_version","inchikey","report"), timevar="level", direction="wide")
colnames(myClassified) <- gsub("name.","",colnames(myClassified))

myClassified_terminal <- add_terminal_label(myClassified,
                                            tax_level_labels = classifyerlevels)
#circ_tree_boxplot(myClassified_terminal, col = 'Sample Count')
circ_tree_boxplot(myClassified_terminal, col = 'terminal_level')

# Look at the number of unique labels for each taxonomic level
label_bars(myClassified_terminal)

# If I want to compare tress from 2 product types, I can subset myClassified
data_list <- list(myClassified_terminal_1, myClassified_terminal_2)
names(data_list) <- c('Clothing', 'Fabric')
label_bars(data_list)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


# Within-product Category Similarity

## By Chemical Occurrence

```{r prodSimOccur}
# Get curated table of group levels and brands
prodOnt <- as.data.frame(read_xlsx(path = paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", 
                                                sep = "/")))
# Remove blanks
prodOnt <- prodOnt[!prodOnt$Group3 == "blank",]
# Change NA brand to "unknown"
prodOnt$`Anon Brand` <- as.character(prodOnt$`Anon Brand`)
indNA <- prodOnt$`Anon Brand` == "NA"
prodOnt$`Anon Brand`[indNA] <- "unknown"
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

distances <- list()
plot <- TRUE
for (i in 1:length(prodList)){
  if (names(prodList)[i] == "Fabric Upholstery"){
    # Doesn't have sub groups for product or brand names 
    # Get the anonymized sample names using master table
    ind <- match(colnames(prodList[[i]]$binary), prodOnt$MySysID)
    
    distances[[i]] <- as.matrix(dist(t(prodList[[i]]$binary), method = "binary"))
    colnames(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
    row.names(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
  
    # Build annotation for chemical count in each sample
    right_ha <- rowAnnotation("Chemical Count" = anno_barplot(unlist(apply(prodList[[i]]$binary, 
                                                                           2, function(x) sum(x!=0)))),
                                                                           annotation_name_rot = 90)
    
    # Set colors and range
    col_fun <- colorRamp2(c(0, 0.5, 1), c("blue", "white", "red"))
    
    a <- Heatmap(distances[[i]], name = "Distance", col = col_fun, right_annotation = right_ha, 
                 column_names_gp = grid::gpar(fontsize = 8), show_row_names = FALSE,
                 column_title = paste(names(prodList)[i], "Products", sep = " "))
    if (plot){
      pdf(file = paste(myPath, "plots/singleProdCatSimilarityHeatmaps", 
                       paste("withinProdSimilarityHeatmap_", names(prodList)[i], 
                             "_anonSampBrand.pdf", sep = ""), sep = "/"))
      print(a)
      dev.off()
    }
    
  } else {
  
    # Get brand, product sub-category, and curated sample names using master table
    ind <- match(colnames(prodList[[i]]$binary), prodOnt$MySysID)
    
    distances[[i]] <- as.matrix(dist(t(prodList[[i]]$binary), method = "binary"))
    colnames(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
    row.names(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
    
    # The columns I want to use for annotations need to be ordered factors. Subset to the product
    # category so the brand labels don't get mixed up
    temp <- prodOnt[ind,]
    temp$`Anon Brand` <- as.factor(as.character(temp$`Anon Brand`))
    temp$Group3 <- as.factor(temp$Group3)
    
    # Build annotations for these
    palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
    brand_col <- palettes$`Tableau 20`$value[1:length(unique(temp$`Anon Brand`))]
    names(brand_col) <- levels(temp$`Anon Brand`)
    type_col <- rcartocolor::carto_pal(n = (1 + length(unique(temp$Group3))), name = "Antique")
    type_col <- type_col[-2]
    names(type_col) <- levels(temp$Group3)
    
    # Minimum number of elements for the palette is 3, so it adds a 3rd color. Remove this.
    if(length(unique(temp$Group3)) < 3){
      type_col <- type_col[1:length(unique(temp$Group3))]
    }
    
    # To visualize the colors that are pulled
    #if (test){
    #  plot(NULL, xlim =c(0, length(brand_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
    #  rect(0:(length(brand_col)-1), 0, 1:length(brand_col), 1, col = brand_col)
    #  plot(NULL, xlim =c(0, length(type_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
    #  rect(0:(length(type_col)-1), 0, 1:length(type_col), 1, col = type_col)
    #}
    
    column_ha <- HeatmapAnnotation(SubCategory = temp$Group3, Brand = temp$`Anon Brand`,   
                                   col = list("SubCategory" = type_col, "Brand" = brand_col))
    
    # Build annotation for chemical count in each sample
    right_ha <- rowAnnotation("Chemical Count" = anno_barplot(unlist(apply(prodList[[i]]$binary, 
                                                                           2, function(x) sum(x!=0)))),
                                                                           annotation_name_rot = 90)
    # Set colors and range
    col_fun <- colorRamp2(c(0, 0.5, 1), c("blue", "white", "red"))
    
    # Our categories either have ~20 samples or ~40 samples. 
    # Use 2 different font sized for the sample names in the figures.
    if(names(prodList)[i] %in% c("Cotton Clothing", "Silicone Kitchen Tools")){
      myFontSize <- 9.5
    } else {
      myFontSize <- 7.7
    }
    
    a <- Heatmap(distances[[i]], name = "Distance", col = col_fun, top_annotation = column_ha, 
                 right_annotation = right_ha, 
                 column_names_gp = grid::gpar(fontsize = myFontSize), show_row_names = FALSE,
                 column_title = paste(names(prodList)[i], "Products", sep = " "))
    if (plot){
      pdf(file = paste(myPath, "plots/singleProdCatSimilarityHeatmaps", 
                       paste("withinProdSimilarityHeatmap_", names(prodList)[i], 
                             "_anonSampBrand.pdf", sep = ""), sep = "/"))
        print(a)
      dev.off()
    }
    if (names(prodList)[i] == "Cotton Clothing"){
      pdf(file = paste(myPath, "plots", 
                       "Fig4-CottonClothingSampleSimilarity.pdf", 
                       sep = "/"))
        print(a)
      dev.off()
    }
  }
}
save(prodOnt, file = paste(myPath, "data", "allCombinedAnnotated.RData", sep = "/"))
```
# Examine within-product category sample variability
```{r examine_within_product_category_variability}
names(distances) <- prodGroups
simTable <- c()
for (i in 1:length(prodGroups)){
  # First find where our dups and reps are
  indDups <- grep("dup", colnames(distances[[i]]))
  indReps <- grep("rep", colnames(distances[[i]]))
  # All samples without the diagonal
  indTri <- upper.tri(distances[[i]])
  avgTot <-  mean(distances[[i]][indTri])
  sdTot <- sd(distances[[i]][indTri])
  # Non dups and reps
  temp <- distances[[i]][-c(indDups, indReps), -c(indDups, indReps)]
  indTri <- upper.tri(temp)
  avgRed <-  mean(temp[indTri])
  sdRed <- sd(temp[indTri])
  # Dups
  tempDup <- c()
  tempDupCount <- c()
  for (j in 1:length(indDups)){
    indreg <- which(colnames(distances[[i]]) == gsub("_dup", "", colnames(distances[[i]])[indDups[j]]))
    tempDup <- c(tempDup, distances[[i]][indDups[j], indreg])
    tempDupCount <- c(tempDupCount, sum(abs(prodList[[i]]$binary[,indreg] - prodList[[i]]$binary[,indDups[j]])))
  }
  avgDup <- mean(tempDup)
  sdDup <- sd(tempDup)
  avgDupCount <- mean(tempDupCount)
  sdDupCount <- sd(tempDupCount)
  # Reps
  tempRep <- c()
  tempRepCount <- c()
  for (j in 1:length(indReps)){
    indreg <- colnames(distances[[i]]) == gsub("_rep", "", colnames(distances[[i]])[indReps[j]])
    tempRep <- c(tempRep, distances[[i]][indReps[j], indreg])
    tempRepCount <- c(tempRepCount, sum(abs(prodList[[i]]$binary[,indreg] - prodList[[i]]$binary[,indReps[j]])))
  }
  avgRep <- mean(tempRep)
  sdRep <- sd(tempRep)
  avgRepCount <- mean(tempRepCount)
  sdRepCount <- sd(tempRepCount)
  # Build up data frame
  simTable <- rbind(simTable, c(avgTot, sdTot, avgRed, sdRed, length(indDups), avgDup, sdDup, length(indReps), avgRep, sdRep, avgDupCount, sdDupCount, avgRepCount, sdRepCount))
}
simTable <- data.frame(simTable)
colnames(simTable) <- c("avgTot", "sdTot", "avgRed", "sdRed", "NumDups", "avgDup", "sdDup", "NumReps", "avgRep", "sdRep",
                        "avgDupCount", "sdDupCount", "avgRepCount", "sdRepCount")
simTable <- cbind("ProductCategory" = prodGroups, simTable)
write.table(simTable, file = paste(myPath, "results", "similarityMeansForSampBySampHeatmaps.txt", sep = "/"), 
            quote = FALSE, sep = "\t", row.names = FALSE)
```

```{r create_product_category_heatmap}
# Get a binary vector for each product category
prodCatVects <- c()
for (i in 1:length(prodGroups)){
  temp <- unlist(apply(prodList[[i]]$binary, 1, max))
  prodCatVects <- rbind(prodCatVects, temp)
}
row.names(prodCatVects) <- prodGroups
# Get the distances
catDistances <- as.matrix(dist(prodCatVects, method = "binary"))
# Fill in the diagonal
diag(catDistances) <- simTable$avgTot

# Make the plot
# Set colors and range
col_fun <- colorRamp2(c(0.4, 0.7, 1), c("blue", "white", "red"))

a <- Heatmap(catDistances, name = "Distance", col = col_fun, 
             rect_gp = gpar(col = "white", lwd = 2),
             cell_fun = function(j, i, x, y, width, height, fill){
               grid.text(sprintf("%.3f", catDistances[i, j]), x, y, gp = gpar(fontsize = 10))
             },
             column_names_gp = grid::gpar(fontsize = 11), show_row_names = FALSE,
             column_title = "Product Category Similarity by Chemical Occurrence")

pdf(file = paste(myPath, "plots", "allProdCatSimilarityHeatmap_1vect.pdf", sep = "/"))
  print(a)
dev.off()

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## By Chemical Concentration

```{r prodSimConc}
# Load our list of product group matrices
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Get curated table of group levels and brands
prodOnt <- as.data.frame(read_xlsx(path = paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", 
                                                sep = "/")))
# Remove blanks
prodOnt <- prodOnt[!prodOnt$Group3 == "blank",]

plot <- TRUE
myClust <- "SampCount"
concTable <- c()
allDup <- c()
allRep <- c()
myOutliers <- list()
for (i in 1:length(prodList))
{
  print(i)
  temp <- prodList[[i]]$conc
  
  # Remove chemicals not in any of the samples
  indRem <- unlist(apply(temp, 1, function(x) sum(is.na(x)) == dim(temp)[2])) 
  temp <- temp[!indRem,]  
  
  # Perform clustering of rows
  temp2 <- temp
  temp2[is.na(temp2)] <- 0
  temp2[is.nan(temp2)] <- 0
  if (myClust == "Distance"){
    ####### By Distance ######## 
    set.seed(788)
    temp2 <- scale(temp2)
    dist_mat <- dist(temp2, method = 'euclidean')
    hclust_avg <- hclust(dist_mat, method = 'complete')
    temp <- temp[hclust_avg$order,]
  } else if (myClust == "TotalAbund"){
    ##### By Total Abundance #####
    abund <- unlist(apply(temp2, 1, sum))
    temp <- temp[order(abund, decreasing = TRUE),]
  } else if (myClust == "SampCount"){
    ####### By Sample Count ######
    counts <- unlist(apply(temp2, 1, function(x) sum(x != 0)))
    temp <- temp[order(counts, decreasing = TRUE),]
  }    
  
  # Put in ug/g rather than ng/g
  temp <- temp/1000
  
  # Use anonymized sample names from prodOnt
  # Get brand, product sub-category, and curated sample names using master table
  ind <- match(colnames(temp), prodOnt$MySysID)
  colnames(temp) <- prodOnt$`Anon Sample 2`[ind]
  
  # Max concentration
  mymax <- quantile(temp, probs = 0.99, na.rm = TRUE)
  
  # Ensure same colors for the continuous mapping
  total_chem <- circlize::colorRamp2(c(0,
                                       max(unlist(apply(temp, 
                                                        1, 
                                                        function(x) 
                                                          sum(x, na.rm = TRUE))))), c("white", "darkorange3"))
  total_samp <- circlize::colorRamp2(c(0,
                                       max(unlist(apply(temp, 
                                                        2, 
                                                        function(x) 
                                                          sum(x, na.rm = TRUE))))), c("white", "cadetblue4"))
  
  if (names(prodList)[i] != "Fabric Upholstery"){
    # The columns I want to use for annotations need to be ordered factors. Subset to the product
    # category so the brand labels don't get mixed up
    annos <- prodOnt[ind,]
    annos$`Anon Brand` <- as.factor(as.character(annos$`Anon Brand`))
    annos$Group3 <- as.factor(annos$Group3)
    
    # Build annotations for these
    palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
    brand_col <- palettes$`Tableau 20`$value[1:length(unique(annos$`Anon Brand`))]
    names(brand_col) <- levels(annos$`Anon Brand`)
    type_col <- rcartocolor::carto_pal(n = (1 + length(unique(annos$Group3))), name = "Antique")
    type_col <- type_col[-2]
    names(type_col) <- levels(annos$Group3)
  
    column_ha <- HeatmapAnnotation(SubCategory = annos$Group3, 
                                   Brand = annos$`Anon Brand`,
                                   Total_Sample_Abund. = unlist(apply(temp, 
                                                                      2, 
                                                                      function(x) 
                                                                        sum(x, 
                                                                            na.rm = TRUE))), 
                                   Chems_in_Sample = anno_barplot(unlist(apply(temp, 
                                                                               2, 
                                                                               function(x) 
                                                                                 sum(!is.na(x))))),
                                   col = list("SubCategory" = type_col, 
                                              "Brand" = brand_col, 
                                              "Total_Sample_Abund." = total_samp))
  } else {
    column_ha <- HeatmapAnnotation(Total_Sample_Abund. = unlist(apply(temp, 
                                                                      2, 
                                                                      function(x) 
                                                                        sum(x, 
                                                                            na.rm = TRUE))), 
                                   Chems_in_Sample = anno_barplot(unlist(apply(temp, 
                                                                               2, 
                                                                               function(x) 
                                                                                 sum(!is.na(x))))),
                                   col = list("Total_Sample_Abund." = total_samp))
  }
  
  row_ha <- rowAnnotation(Total_Chem_Abund. = unlist(apply(temp, 1, 
                                                           function(x) 
                                                             sum(x, na.rm = TRUE))),
                          annotation_name_rot = 90,
                          Samples_with_Chem = anno_barplot(unlist(apply(temp, 
                                                                        1, 
                                                                        function(x) 
                                                                          sum(!is.na(x))))),
                          col = list("Total_Chem_Abund." = total_chem))
  
  # Make plot
  singleProdCatHeatmaps <- list()
  if(plot){
    # Our categories either have ~20 samples or ~40 samples. 
    # Use 2 different font sized for the sample names in the figures.
    if(names(prodList)[i] %in% c("Cotton Clothing", "Silicone Kitchen Tools")){
      myFontSize <- 12.2
    } else {
      myFontSize <- 10.8
    }
  
    print(prodGroups[i])
    singleProdCatHeatmaps <- Heatmap(temp, 
                                          name = "Abundance (ug/g)", 
                                          top_annotation = column_ha, 
                                          right_annotation = row_ha, 
                                          row_title = "Chemicals", 
                                          #left_annotation = left_ha, 
                                          column_title = paste(prodGroups[i], 
                                                               " Samples", 
                                                               sep = ""), 
                                          cluster_rows = FALSE, 
                                          cluster_columns = FALSE, 
                                          show_row_names = FALSE, 
                                          column_names_rot = 90, 
                                          column_names_gp = gpar(fontsize = 
                                                                   myFontSize), 
                                          column_names_max_height = unit(4, "cm"))
    pdf(file = paste(myPath, "plots/singleProdCatConcHeatmaps", 
                     paste("prodSpecificHeatmap_conc_", 
                           prodGroups[i], "_by", 
                           myClust, ".pdf", 
                           sep = ""),
                     sep = "/"), 
        width = 11, 
        height = 13)
    draw(singleProdCatHeatmaps)
    dev.off()
    save(temp, singleProdCatHeatmaps, 
         prodOnt,
         brand_col,
         type_col,
         annos,
         total_chem,
         total_samp,
         i, prodGroups,
         myFontSize,
         file=paste(myPath, "plots/singleProdCatConcHeatmaps", 
                     paste("prodSpecificHeatmaps-",
                     prodGroups[i],
                     ".RData",
                     sep=""),
                     sep = "/"))
  }

  # Save chemical outliers that are not colored in the figure due to skewing the entire heatmap to
  # be blue
  indOutlier <- unique(unlist(apply(temp, 2, function(x) which(x > mymax))))
  myOutliers[[i]] <- temp[indOutlier,]
  
  # Find the largest difference in estimated concentration for a chemical between dups and reps
  # First find where our dups and reps are
  indDups <- grep("dup", colnames(temp))
  indReps <- grep("rep", colnames(temp))
  # Dups
  tempDup <- c()
  tempDup2 <- c()
  for (j in 1:length(indDups)){
    indreg <- which(colnames(temp) == gsub("_dup", "", colnames(temp)[indDups[j]]))
    # Differences
    Cdiff <- abs(temp[,indDups[j]] - temp[,indreg])
    # Maximum difference
    #tempDup <- c(tempDup, max(Cdiff, na.rm = TRUE))
    # Maximum fold change
    tempDup <- c(tempDup, max(Cdiff/temp[,indreg], na.rm = TRUE))
    # Keep track of each chemical in each sample pair
    tempDup2 <- cbind(tempDup2, Cdiff/temp[,indreg])
    colnames(tempDup2)[j] <- colnames(temp)[indDups[j]]
  }
  allDup[[i]] <- tempDup2 
  avgDup <- mean(tempDup)
  sdDup <- sd(tempDup)
  # Reps
  tempRep <- c()
  tempRep2 <- c()
  for (j in 1:length(indReps)){
    indreg <- colnames(temp) == gsub("_rep", "", colnames(temp)[indReps[j]])
    # Differences
    Cdiff <- abs(temp[,indReps[j]] - temp[,indreg])
    # Maximum fold change
    tempRep <- c(tempRep, max(Cdiff/temp[,indreg], na.rm = TRUE))
    # Keep track of each chemical in each sample pair
    tempRep2 <- cbind(tempRep2, Cdiff/temp[,indreg])
    colnames(tempRep2)[j] <- colnames(temp)[indReps[j]]
  }
  allRep[[i]] <- tempRep2
  avgRep <- mean(tempRep)
  sdRep <- sd(tempRep)
  # Build up data frame
  concTable <- rbind(concTable, c(mymax, avgDup, sdDup, avgDup/mymax, avgRep, sdRep, avgRep/mymax))
  
}
```

```{R Make_Fig5}
load(file=paste(myPath, "plots/singleProdCatConcHeatmaps", 
                     "prodSpecificHeatmaps-Cotton Clothing.RData",
                     sep = "/"))
    LEGEND.FONT <- 8
    column_ha <- HeatmapAnnotation(SubCategory = annos$Group3, 
                                   Brand = annos$`Anon Brand`,
                                   "Total Sample Abund." = unlist(apply(temp, 
                                                                      2, 
                                                                      function(x) 
                                                                        sum(x, 
                                                                            na.rm = TRUE))), 
                                   "Chems in Sample" = anno_barplot(unlist(apply(temp, 
                                                                               2, 
                                                                               function(x) 
                                                                                 sum(!is.na(x))))),
                                   col = list("SubCategory" = type_col, 
                                              "Brand" = brand_col, 
                                              "Total_Sample_Abund." = total_samp),
                          annotation_legend_param = list(title_gp = gpar(fontsize = LEGEND.FONT),
                                                         labels_gp = gpar(fontsize = LEGEND.FONT)))

  row_ha <- rowAnnotation("Total Chem Abund." = unlist(apply(temp, 1, 
                                                           function(x) 
                                                             sum(x, na.rm = TRUE))),
                          annotation_name_rot = 90,
                          "Samples with Chem" = anno_barplot(unlist(apply(temp, 
                                                                        1, 
                                                                        function(x) 
                                                                          sum(!is.na(x))))),
                          col = list("Total_Chem_Abund." = total_chem),
                          annotation_legend_param = list(title_gp = gpar(fontsize = LEGEND.FONT),
                                                         labels_gp = gpar(fontsize = LEGEND.FONT)))
  
 singleProdCatHeatmaps <- Heatmap(temp, 
        name = "Abundance (ug/g)", 
        top_annotation = column_ha, 
        right_annotation = row_ha, 
        row_title = "Chemicals", 
        #left_annotation = left_ha, 
        column_title = paste(prodGroups[i], 
                             " Samples", 
                             sep = ""),
        cluster_rows = FALSE,
        cluster_columns = FALSE,
        show_row_names = FALSE,
        column_names_rot = 90,
        column_names_gp = gpar(fontsize = myFontSize), 
        column_names_max_height = unit(4, "cm"),
        heatmap_legend_param = list(title_gp = gpar(fontsize = LEGEND.FONT),
                                    labels_gp = gpar(fontsize = LEGEND.FONT)))
pdf(file = paste(myPath, "plots/Fig5-CottonHeatmap.pdf",
                 sep = "/"),
    width = 8, 
    height = 8)
draw(singleProdCatHeatmaps)
dev.off()
draw(singleProdCatHeatmaps)
```

```{R Outliers}

concTable <- as.data.frame(concTable)
colnames(concTable) <- c("maxAbund", "avgDup", "sdDup", "dupPercMax", "avgRep", "sdRep", "repPercMax")
concTable <- cbind("ProductCategory" = prodGroups, concTable)

# Want to report the outliers, which is currently a list of matrices for each category
# but the rows and columns are all different. Convert to long-form so we can report as 1 table.
outlierDF <- c()
for (i in 1:length(myOutliers)){
  temp <- as.data.frame(myOutliers[[i]])
  temp$DTXSID <- row.names(temp)
  temp <- pivot_longer(temp, cols = starts_with("sample"))
  # Remove NAs
  temp <- temp[!is.na(temp$value),]
  temp <- temp[temp$value > concTable$maxAbund[i],]
  temp$perc99 <- concTable$maxAbund[i]
  temp <- cbind("Category" = prodGroups[i], temp)
  outlierDF <- rbind(outlierDF, temp)
}
colnames(outlierDF)[3:5] <- c("Sample", "Abundance", "99th_perc_Abund") 

# Save table
write.table(outlierDF, file = paste(myPath, "results", "prodCatChems_concOutliers_with99thperc.txt", sep = "/"), sep = "\t", row.names = FALSE)

# Summarize
as.data.frame(table(outlierDF$Category))
outlierChems <- unique(outlierDF$DTXSID)
# Look at chemical class breakdown
CFout <- read.delim(file = paste(myPath, "results", "ClassyFireAnnotation_allChems_batchAPI_2024-05-28.txt", sep = "/"), 
              sep = "\t")
ind <- match(outlierChems, CFout$DTXSID)
outlierChems <- CFout[ind,]
as.data.frame(table(outlierChems$superclass))
as.data.frame(table(outlierChems$class))

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


# Chemical Signatures of Products

## Simple Signature Identification

This is a simple first-pass way of finding a chemical signature for each
product type. Use the concentration matrix to get an idea of the
fraction of mass each chemical makes up.
```{r signature_func}
subset_to_signature <- function(conc.matrix, threshold = 0.8)
{
  rowcounts <- unlist(apply(conc.matrix, 1, function(x) sum(!is.na(x)))) 
  prevChems <- which(rowcounts/dim(conc.matrix)[2] >= threshold)
  return(conc.matrix[prevChems,])
}
```

```{r simpleSig}
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Load processed dashboard output object
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# Build signatures. Keep a corresponding list with the chemical names for use in
# plotting and supplemental table generation
signatures <- vector(mode = "list", length = length(prodList))
chemnames <- vector(mode = "list", length = length(prodList))
for (i in 1:length(prodList))
{
# Calculate signature here:
  signatures[[i]] <- subset_to_signature(prodList[[i]]$conc)
  
  # Add chemical names (use raw data name for chemicals without a DTXSID)
  ind <- match(row.names(signatures[[i]]), tps$DTXSID)
  chemnames[[i]] <- tps$PREFERRED_NAME[ind]
  # If a chemical didn't have a DTXSID, give it the raw name
  indNA <- which(is.na(chemnames[[i]]))
  chemnames[[i]][indNA] <- tps$Raw_Name[ind[indNA]]
  
  # Some entries are NaN.  Change to NA.
  signatures[[i]][is.nan(signatures[[i]])] <- NA
  signatures[[i]] <- cbind(signatures[[i]], "Median_conc" = apply(signatures[[i]], 1, function(x) 
                                                             quantile(x, probs = 0.5, na.rm = TRUE)))
  
  # Convert from ng/g to ug/g
  signatures[[i]] <- signatures[[i]]/1000
}
names(signatures) <- prodGroups
names(chemnames) <- prodGroups
# Save this object for comparison with external data
save(signatures, file = paste(myPath, "results", "prodCatSignatures_gte0.8sampOccurrence_all.RData", sep = "/"))
```

```{r chemical_counts}
count.table <- sapply(signatures, dim)
rownames(count.table) <- c("Unique Chemicals in Signature","Samples Analyzed in Study")
print(count.table)

load(file = paste(myPath, "data", "allCombDilDupRep_BinAndConcMats_concat.RData", sep = "/"))

cat(paste("Unique products:", dim(allComb_BinAndConc_concat$conc)[2],"\n"))

```
```{r investigate_sample_size}
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Load processed dashboard output object
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# Build signatures. Keep a corresponding list with the chemical names for use in
# plotting and supplemental table generation
sample.num <- sort(unique(c(seq(2,43,2),5,23,43)))
sig.matrix <- matrix(NA,nrow=length(prodList),ncol=length(sample.num))
rownames(sig.matrix) <- names(prodList)
colnames(sig.matrix) <- sample.num
sig.matrix.sd <- sig.matrix

NUM.REPS <- 10
set.seed(120512)
for (this.prod in names(prodList))
{
  this.data.subset <- prodList[[this.prod]]$conc
  for (this.sample.num in sample.num)
  {
    if (this.sample.num > dim(this.data.subset)[2])
    {
      num.chems <- NA 
    } else {
      num.chems <- NULL
      for (this.rep in 1:NUM.REPS)
      {
        
        this.rep <- this.data.subset[,
                                     sample(1:dim(this.data.subset)[2],
                                            this.sample.num,
                                            replace=FALSE)]
        this.sig <- subset_to_signature(this.rep)
        num.chems <- c(num.chems, dim(this.sig)[1])
      }
    }
    sig.matrix[this.prod, colnames(sig.matrix)==this.sample.num] <- mean(num.chems)
    sig.matrix.sd[this.prod, colnames(sig.matrix)==this.sample.num] <- sd(num.chems)
  }
}
```

```{r Make_Fig6}
samplenum.df <- melt(sig.matrix)
samplenum.df$SD <- melt(sig.matrix.sd)$value
colnames(samplenum.df)[1:3] <- c("Product","Samples","Chemicals")

samplenum.plot <- ggplot(samplenum.df, aes(x=Samples, y=Chemicals, 
                                  shape=Product, color=Product)) + 
  geom_point(size=3)+
  geom_errorbar(aes(ymin=Chemicals-SD, ymax=Chemicals+SD), width=.2,
                 position=position_dodge(0.2))+
  ylab("Chemicals in Signature")+
  xlab("Number of Samples Used for Signature")+
  theme_bw()
print(samplenum.plot)
pdf(file = paste(myPath, "plots", 
                 "Fig6-SignatureChemicalswithSamples.pdf", sep = "/"), 
    width = 6, height = 3)
  print(samplenum.plot)
dev.off()
```
# Make a Facet Plot
```{r make_facet_plot}
# Build the data frame 
df <- c()
for (i in 1:length(prodList)){
  ind <- dim(signatures[[i]])
  temp <- data.frame("Category" = rep(names(prodList)[i], ind[1]), "Chemical" = chemnames[[i]], 
              signatures[[i]], row.names = NULL)
  temp <- pivot_longer(temp, cols = grep("X", colnames(temp)), cols_vary = "fastest")
  colnames(temp)[4:5] <- c("Sample", "Conc")
  df <- rbind(df, temp)
}

# Remove NA rows (samples for which signature chems are not present)
df <- df[!is.na(df$Conc),]

# Facet from largest category signature to smallest
srtOrder <- unlist(lapply(signatures, function(x) dim(x)[1]))
srtOrder <- order(srtOrder, decreasing = TRUE)
df$Category <- factor(df$Category, levels = names(prodList)[srtOrder], ordered = TRUE)
Fig7PanelA <- ggplot(df, aes(x = reorder_within(Chemical, -Median_conc, Category), y = Conc, fill = Category)) +
  geom_boxplot() +
  scale_y_log10() +
  scale_x_reordered() +
  facet_grid(~Category, scales = "free_x", space = "free", 
             labeller = labeller(Category = label_wrap_gen(5))) +
  theme_bw() +
  ylab("log10(Abundance in ug/g)") +
  ggtitle("Chemical Signatures of Product Categories") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  theme(axis.title.x = element_blank()) +
  theme(text =element_text(size = 13)) +
  theme(legend.text = element_text(size = 10))
pdf(file = paste(myPath, "plots", "mostPrevChemsPerProduct_boxplotConc.pdf", sep = "/"), width = 12, height = 7)
  print(Fig7PanelA)
dev.off()
```

```{r calculate_categorgy_chemical_IQR}
# For supplement, want to get the IQR for each category-chemical pair. Step through the signatures object.
sigChemsConc <- c()
for (i in 1:length(signatures)){
  iqrs <- t(apply(signatures[[i]], 1, function(x) quantile(x, probs = seq(0, 1, 0.25), na.rm = TRUE)))
  # Round the values
  iqrs <- round(iqrs, digits = 4)
  # Rename columns
  colnames(iqrs) <- c("Min_conc", "25%_quantile_conc", "Median_conc", "75%_quantile_conc", "Max_conc")
  # Want to concatenate across all categories. Since some chemicals are signature chems for multiple 
  # categories, we can't use them as row names (duplicates not allowed). So make it a column.
  iqrs <- cbind("Category" = rep(names(signatures)[i], dim(iqrs)[1]), "DTXSID" = row.names(iqrs), 
                "PREFERRED_NAME" = chemnames[[i]], iqrs)
  row.names(iqrs) <- NULL
  sigChemsConc <- rbind(sigChemsConc, iqrs)
}
sigChemsConc <- as.data.frame(sigChemsConc)

# Go to next section to finish filling out the supplemental table (sigChemsConc) 
```


## Characterize Signature Chemicals

To add more context to our results and signatures, bring in various forms of chemical
data, including EPA's ChemExpo Database for product composition, availability of ToxVal
data, EPA's QC level, activity in ToxCast assays, and predicted oral rat LD50s.

```{r annotateSigChems}
### Pull the dashboard metadata for these signature chemicals
# Bring in the curated dashboard data object
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))

# Drop columns we don't need
indTox <- which(colnames(tps) %in% c("ORAL_RAT_LD50_MOL/KG_TEST_PRED",
                                       "BIODEGRADATION_HALF_LIFE_DAYS_DAYS_OPERA_PRED",
                                       "OCTANOL_AIR_PARTITION_COEFF_LOGKOA_OPERA_PRED",
                                       "OCTANOL_WATER_PARTITION_LOGP_OPERA_PRED",
                                       "TOXVAL_DATA", "CPDAT_COUNT", "TOXCAST_NUMBER_OF_ASSAYS/TOTAL",
                                       "TOXCAST_PERCENT_ACTIVE", "EXPOCAST_MEDIAN_EXPOSURE_PREDICTION_MG/KG-BW/DAY"))
tps <- tps[,c(1:6,indTox)]

# Combine with sigChemsConc object from the last section/code block
# Prep first
sigChemsAll <- base::merge(sigChemsConc, tps, by = "DTXSID", all.x = TRUE, sort = FALSE)
# Reorder columns
colnames(sigChemsAll)
sigChemsAll <- sigChemsAll[,c(2,1,3,11,4:8,14:21)]
colnames(sigChemsAll)[3] <- "PREFERRED_NAME"

# Clean up
sigChemsAll$TOXVAL_DATA[is.na(sigChemsAll$TOXVAL_DATA)] <- "N" 
sigChemsAll$`TOXCAST_NUMBER_OF_ASSAYS/TOTAL`[is.na(sigChemsAll$`TOXCAST_NUMBER_OF_ASSAYS/TOTAL`)] <- 0
sigChemsAll$TOXCAST_PERCENT_ACTIVE[is.na(sigChemsAll$TOXCAST_PERCENT_ACTIVE)] <- 0
# Group by category
sigChemsAll <- sigChemsAll[order(match(sigChemsAll$Category, prodGroups)),]

# Read in ChemExpo bulk composition data to get a chemical count
chemexpo <- read.csv(file = paste(myPath, "data", "ChemExpo_composition_chemicals_20230921_HhldProdChems.csv", sep = "/"))

# Function to get unique products
queryCE <- function(dtxsid, chemexpo){
  prodcount <- chemexpo$Product.Name[chemexpo$DTXSID == dtxsid]
  prodcount <- length(unique(prodcount))
  return(prodcount)
}
counts <- sapply(sigChemsAll$DTXSID, function(x) queryCE(x, chemexpo))
sigChemsAll$CPDAT_COUNT <- counts 
# Save data for figure ##
write.table(sigChemsAll, file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"), sep = "\t", row.names = FALSE)
rm(chemexpo)


### Make 2 plots: to add to the signatures one created above. 1 using exposure data
### and 1 using toxicity data

## Set up data
sigChemsAll <- read.delim(file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"))
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))
srtOrder <- c(1,4,5,2,3)
sigChemsAll$Category <- factor(sigChemsAll$Category, levels = names(prodList)[srtOrder], ordered = TRUE)


# Exposure plot
sigChemsAll$EXPOCAST_MEDIAN_EXPOSURE_PREDICTION_MG.KG.BW.DAY <- as.numeric(sigChemsAll$EXPOCAST_MEDIAN_EXPOSURE_PREDICTION_MG.KG.BW.DAY)
sigChemsAll$CPDAT_COUNT <- as.numeric(sigChemsAll$CPDAT_COUNT)

sigChemsAll$CPDat_Product_Count <- cut(sigChemsAll$CPDAT_COUNT, breaks = c(0.5,10,100,1000,max(sigChemsAll$CPDAT_COUNT)),
                                         labels = c("1-10", "11-100", "101-1000", ">1000"))
levels(sigChemsAll$CPDat_Product_Count) <- c(levels(sigChemsAll$CPDat_Product_Count), "0")
sigChemsAll$CPDat_Product_Count[is.na(sigChemsAll$CPDat_Product_Count)] <- 0
sigChemsAll$CPDat_Product_Count <- factor(sigChemsAll$CPDat_Product_Count, 
                                            levels = c("0", "1-10", "11-100", "101-1000", ">1000"), ordered = TRUE)

sigChemsAll$Median_conc <- as.numeric(sigChemsAll$Median_conc)
colnames(sigChemsAll)[3] <- "Chemical"
Fig7PanelB <- ggplot(sigChemsAll, aes(x = reorder_within(Chemical, -Median_conc, Category), 
                           y = sigChemsAll$EXPOCAST_MEDIAN_EXPOSURE_PREDICTION_MG.KG.BW.DAY, 
                           fill = CPDat_Product_Count)) +
  geom_bar(stat = "identity", width = 0.8) +
  scale_y_log10() +
  scale_x_reordered() +
  scale_fill_manual(values = rev(colorspace::heat_hcl(5))) + 
  facet_grid(~Category, scales = "free_x", space = "free",
             labeller = labeller(Category = label_wrap_gen(5))) +
  theme_bw() +
  #guides(fill = guide_legend(title = "Reported in ChemExpo")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylab("Predicted Median Exposure (mg/kg/day)") +
  #ggtitle("Chemical Signatures of Product Categories") +
  theme(axis.title.x = element_blank()) +
  theme(text =element_text(size = 13)) +
  theme(legend.text = element_text(size = 10))
pdf(file = paste(myPath, "plots", "prodCatSignatures_withChemExpoAndSEEM.pdf", sep = "/"), width = 12.3, height = 6.5)
  print(Fig7PanelB)
dev.off()
```
```{r make_toxicity_plot}
# Toxicity plot
sigChemsAll$ORAL_RAT_LD50_MOL.KG_TEST_PRED <- as.numeric(sigChemsAll$ORAL_RAT_LD50_MOL.KG_TEST_PRED)
sigChemsAll$TOXCAST_PERCENT_ACTIVE <- as.numeric(sigChemsAll$TOXCAST_PERCENT_ACTIVE)

Fig7PanelC <- ggplot(sigChemsAll, aes(x = reorder_within(Chemical, -Median_conc, Category), 
                           y = sigChemsAll$ORAL_RAT_LD50_MOL.KG_TEST_PRED, fill = sigChemsAll$TOXCAST_PERCENT_ACTIVE)) +
  geom_bar(stat = "identity", width = 0.8) +
  #scale_y_log10() +
  scale_x_reordered() +
  #scale_fill_manual(values = rev(colorspace::heat_hcl(5))) + 
  facet_grid(~Category, scales = "free_x", space = "free",
             labeller = labeller(Category = label_wrap_gen(5))) +
  theme_bw() +
  guides(fill = guide_legend(title = str_wrap("Toxcast Percent Active", 15))) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylab("Predicted Oral Rat LD50 (mol/kg)") +
  #ggtitle("Chemical Signatures of Product Categories") +
  theme(axis.title.x = element_blank()) +
  theme(text =element_text(size = 12.5)) +
  theme(legend.text = element_text(size = 9.5))
pdf(file = paste(myPath, "plots", "prodCatSignatures_withToxCastPercActiveAndLD50.pdf", sep = "/"), width = 11.6, height = 6.5)
  print(Fig7PanelC)
dev.off()
```

```{R Make_Fig7}
save(Fig7PanelA, Fig7PanelB, Fig7PanelC, 
     file = paste(myPath, "plots", 
                  "Fig7Panels.RData", sep = "/"))
FONT.SIZE <- 7
library(scales)

# Function for log10 formatting tick labels:
scientific_10 <- function(x) {
  out <- gsub("1e", "10^", scientific_format()(x))
  out <- gsub("\\+","",out)
  out <- gsub("10\\^01","10",out)
  out <- parse(text=gsub("10\\^00","1",out))              }  

Fig7PanelA <- Fig7PanelA +
  ylab("Abundance (ug/g)") +
  scale_y_log10(label=scientific_10) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_text(size = FONT.SIZE+2),
                legend.key.width = unit(0.4, "cm"),
                text=element_text(size = FONT.SIZE),
                legend.text=element_text(size=2),
                legend.position="none",
                plot.margin = unit(c(0,2.8,0,0.8), "cm"))
                
Fig7PanelB <- Fig7PanelB  +
  scale_y_log10(label=scientific_10) +
  guides(fill = guide_legend(title = str_wrap("CPDat Product Count", 15))) + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_text(size = FONT.SIZE+2),
        legend.key.width = unit(0.75, "cm"),
        legend.key.height = unit(0.3, "cm"),
        text=element_text(size = FONT.SIZE),
        legend.text=element_text(size=FONT.SIZE),
        plot.margin = unit(c(0,0,0,0.5), "cm")) +
  ylab("Predicted Median\nExposure (mg/kg/day)")

Fig7PanelC <- Fig7PanelC +
  guides(fill = guide_legend(title = str_wrap("Toxcast Percent Active", 15))) + 
  theme(
    axis.text.y = element_text(size = FONT.SIZE+2),
                legend.key.width = unit(1, "cm"),
                legend.key.height = unit(0.5, "cm"),
                text=element_text(size = FONT.SIZE),
                legend.text=element_text(size=FONT.SIZE),
                plot.margin = unit(c(0,0.3,0,0.8), "cm"))

ggarrange(Fig7PanelA,Fig7PanelB,Fig7PanelC,nrow=3,
          labels=c("A","B","C"),heights=c(1,1,2.2),
          common.legend=FALSE)
pdf(file = paste(myPath, "plots", "Fig7-Signatures.pdf", sep = "/"),
    width = 7, height = 7)
ggarrange(Fig7PanelA,Fig7PanelB,Fig7PanelC,nrow=3,
          labels=c("A","B","C"),heights=c(1,1,2.2),
          common.legend=FALSE)
dev.off()
```

```{r examine_classyfire_annotations}
# Look at the ClassyFire annotations of the signature chemicals 
sigchems <- read.delim(file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"))
classyfire <- read.delim(file = paste(myPath, "results/ClassyFireAnnotation_allChems_batchAPI.txt", sep = "/"))
ind <- match(sigchems$DTXSID, classyfire$DTXSID)
sigchems <- cbind(sigchems, classyfire[ind,c("Kingdom", "Superclass", "Class")])
for (i in 1:length(prodGroups)){
  ind <- sigchems$Category == prodGroups[i]
  print(as.data.frame(table(sigchems$Superclass[ind])))
}

# Check overlap with TSCA Active list
tsca <- as.data.frame(read_xlsx(path = paste(myPath, "data",  
  path = "ChemList_TSCA_ACTIVE_NCTI_0222-2024-03-19.xlsx",
  sep="/")))

# Check to make sure all chemicals are unique
length(unique(tsca$DTXSID))

# Overlap with unique signature chemicals
sigchems_unique <- unique(sigChemsAll$DTXSID)
sigind <- which(sigchems_unique %in% tsca$DTXSID)
sigchems_unique[sigind]

# Bring in the curated dashboard data object to look at overall TSCA overlap
load(paste(myPath, "data", "chemicalData_fromDashboard_rawAndCuratedMatches.RData", sep = "/"))
tps <- tps[!duplicated(tps$DTXSID),]
allind <- which(tps$DTXSID %in% tsca$DTXSID)


rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```



## Classify External Data

Do a simple classification of the data from Phillips et. al. 2018 using
the signatures in our data.

```{r simpleClassif}
# Load my data's signatures
load(file = paste(myPath, "results", "prodCatSignatures_gte0.8sampOccurrence_all.RData", sep = "/"))

# Load our signature chemicals data object
myChems <- read.delim(file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"))

# Just need the chemical names if only doing occurrence 
sigList <- list()
for (i in 1:length(signatures)){
  minconc <- apply(signatures[[i]][,-dim(signatures[[i]])[2]], 1, function(x) min(x, na.rm = TRUE))
  maxconc <- apply(signatures[[i]][,-dim(signatures[[i]])[2]], 1, function(x) max(x, na.rm = TRUE))
  sigList[[i]] <- cbind("Mean" = signatures[[i]][,dim(signatures[[i]])[2]], "Min" = minconc, "Max" = maxconc)
  
  # Add columns with identifiers to help use match with the other study
  ind <- match(names(minconc), myChems$DTXSID)
  sigList[[i]] <- cbind(as.data.frame(sigList[[i]]), "DTXSID" = myChems$DTXSID[ind])
}
names(sigList) <- prodGroups

sets <- lapply(sigList, row.names)

# Look at overlaps
for (i in 1:(length(sets)-1)){
  for (j in (i+1):length(sets)){
    print(paste("Intersection between ", names(sets)[i], " and ", names(sets)[j], sep = ""))
    print(length(intersect(sets[[i]], sets[[j]])))
  }
}

# Drop chemicals that occur in more than one category
uniqSigList <- sigList
for (i in 1:length(sets)){
  ind <- setdiff(sets[[i]], unlist(sets[-i]))
  uniqSigList[[i]] <- sigList[[i]][ind,]
}
lapply(uniqSigList, dim)  

# From Phillips et al 2018 supplemental data, 20 product types (5 samples each)
occurMat <- as.data.frame(read_xlsx(path = paste(myPath, "data", "KPhillips_SSofConsumerProds_SuppTables.xlsx", 
                                                 sep = "/"), sheet = 3))

# Remove any NAs in the DTXSID column
occurMat <- occurMat[!is.na(occurMat$dtxsid),]  

# Turn this long-form table into an occurrence matrix of sample X chemical
extChems <- unique(occurMat$dtxsid)  # 1594
extSamps <- unique(occurMat$anonymized_product)  # 100
# Allocate space
extDF <- as.data.frame(matrix(data = NA, nrow = length(extSamps), ncol = length(extChems), 
                              dimnames = list(extSamps, extChems)))
for (i in 1:length(extSamps)){
  indS <- which(occurMat$anonymized_product == extSamps[i])
  indC <- match(occurMat$dtxsid[indS], extChems)
  indDup <- duplicated(indC)  # There are cases when a chemical is reported twice for a sample
  indS <- indS[!indDup]       # This causes issues when populating the matrix, so drop the duplicate
  indC <- indC[!indDup]
  extDF[i,indC] <- occurMat$concentration_microgram_per_gram[indS] 
}
# Replace NAs with zeros
extDF[is.na(extDF)] <- 0

# Build final DF for classification.  Just have the signature chemicals in the final DF
myCols <- sapply(names(uniqSigList), function(x) paste(x, c("Count", "Total", "Fraction"), sep = "_"))
classDF <- as.data.frame(matrix(data = NA, nrow = dim(extDF)[1], ncol = 3*length(uniqSigList),
                                dimnames = list(row.names(extDF), myCols)))
for (j in 1:dim(extDF)[1]){
  place <- 0
  for (i in 1:length(uniqSigList)){
    counts <- length(intersect(colnames(extDF)[which(extDF[j,] != 0)], uniqSigList[[i]][,4]))
    total <- dim(uniqSigList[[i]])[1]
    fraction <- counts/total
    classDF[j, (place + 1):(place + 3)] <- c(counts, total, fraction)
    place <- place + 3
  }
}

# Make the classification call
callCol <- c()
fraction_cols <- grep("Fraction", colnames(classDF))
for (i in 1:dim(classDF)[1]){
  ind <- names(uniqSigList[which(classDF[i, fraction_cols] == max(classDF[i, fraction_cols]))])
  if (length(ind) > 1){
    ind <- paste(ind, collapse = "_and_")
  }
  callCol <- c(callCol, ind)
}
classDF <- cbind("Classfication" = callCol, classDF)


# Get simple signatures for this external data
extDF <- t(extDF)
catNames <- substr(colnames(extDF), 1, nchar(colnames(extDF))-2)
extCats <- unique(catNames)
extSignatures <- vector(mode = "list", length = length(extCats))
for (i in 1:length(extCats)){
  indCat <- catNames == extCats[i]
  rowcounts <- unlist(apply(extDF[,indCat], 1, function(x) sum(x > 0))) 
  prevChems <- which(rowcounts/dim(extDF[,indCat])[2] >= 0.8)
  extSignatures[[i]] <- extDF[prevChems,indCat]
  # Some entries are NaN.  Change to NA.
  extSignatures[[i]][is.nan(extSignatures[[i]])] <- NA
  extSignatures[[i]] <- cbind(extSignatures[[i]], "Mean" = apply(extSignatures[[i]], 1, function(x) mean(x, na.rm = TRUE)))
}
names(extSignatures) <- extCats
# Save this object for comparison with external data
save(extSignatures, file = paste(myPath, "results", "prodCatSignatures_Phillips2018_gte0.8sampOccurrence_all.RData", sep = "/"))


# Look at signature overlap
# Use the CAS column in sigList to check against the row names in extSignatures
ssdf <- as.data.frame(matrix(data = NA, nrow = 5, ncol = 20, dimnames = list(prodGroups, extCats)))
for (i in 1:length(prodGroups)){
  for (j in 1:length(extCats)){
    ssdf[i,j] <- length(intersect(sigList[[i]][,4], row.names(extSignatures[[j]])))
  }
}
ssdf <- t(ssdf)

# Build annotation for the signanture size of both our data and the external data
right_ha <- rowAnnotation("Signature Size" = anno_barplot(unlist(lapply(extSignatures, 
                                                                       function(x) dim(x)[1]))),
                                                                       annotation_name_rot = 90)

column_ha <- HeatmapAnnotation("Signature Size" = anno_barplot(unlist(lapply(sigList, 
                                                                       function(x) dim(x)[1]))))

# Set colors and range
col_fun <- colorRamp2(c(0, max(ssdf)/2, max(ssdf)), c("blue", "white", "red"))

a <- Heatmap(ssdf, name = "Shared Chemicals", col = col_fun, right_annotation = right_ha,
             top_annotation = column_ha, rect_gp = gpar(col = "white", lwd = 2),
             cell_fun = function(j, i, x, y, width, height, fill){
               grid.text(sprintf("%i", ssdf[i, j]), x, y, gp = gpar(fontsize = 10))},
             column_names_gp = grid::gpar(fontsize = 10), show_row_names = TRUE,
             column_title = "Product Categories: This Study",
             row_names_side = "right", row_names_gp = grid::gpar(fontsize = 10),
             column_title_side = "bottom", row_title = "Product Categories: Phillips et al 2018",
             row_title_side = "right")
pdf(file = paste(myPath, "plots", "prodCatSignatureOverlap_Phillips2018_Heatmap_uniqueChems_2024-05-28.pdf", sep = "/"))
  print(a)
dev.off()

```



# Clustering of Chemicals by Abundance

Global look at abundance data (all samples and all chemicals). Look for ubiquitous 
chemicals, chemicals specific to certain subsets of samples, or chemicals with similar signatures.

```{r abund_clust}
# Bring in chemical X sample matrices after combining duplicates and repeat purchases and 
# concatenating across all  product groups
load(file = paste(myPath, "data", "allCombDilDupRep_BinAndConcMats_concat.RData", sep = "/"))

# Want to work with abundance data
concmat <- allComb_BinAndConc_concat$conc

# Some entries are NaN. Replace with NA.
concmat[is.nan(concmat)] <- NA
# Replace these for clustering
indNA <- is.na(concmat)
concmat[indNA] <- 0

# Change from ng/g to ug/g
concmat <- concmat/1000

# Reduce chemical dimension by removing those only in 1 sample
chemcounts <- unlist(apply(concmat, 1, function(x) sum(x > 1e-5)))
hist(chemcounts)
ind <- chemcounts < 2
concmat <- concmat[!ind,]
chemcounts <- chemcounts[!ind]
# reorder chemicals from most to least total concentration
chemconcs <- unlist(apply(concmat, 1, sum))
indord <- order(chemconcs, decreasing = TRUE)
concmat <- concmat[indord,]

## Order clusters within each category by most chemicals as well ###
# This might show more of a pattern in terms of chemical prevalence
colnames(concmat) <- allComb_BinAndConc_concat$prodType
neworder <- c()
for (i in 1:length(prodGroups)){
  temp <- concmat[,colnames(concmat) == prodGroups[i]]
  counts <- apply(temp, 2, function(x) sum(x > 1e-5))
  neworder <- c(neworder, order(counts, decreasing = TRUE) + length(neworder))
}
concmat <- concmat[,neworder]

sampcats_f <- factor(colnames(concmat))
sampcats_f <- factor(sampcats_f, levels = prodGroups[c(2,3,1,4,5)])

# Include an indicator for articles vs formulations
prodtypes <- rep("Consumer Article", length(sampcats_f))
ind <- sampcats_f %in% c("Shampoo", "Baby Soap")
prodtypes[ind] <- "Formulated Product"
prodtypes <- factor(prodtypes)
type_col <- c("darkorange", "darkgreen")
names(type_col) <- levels(prodtypes)
#Type = prodtypes, col = list("Type" = type_col)

column_ha <- HeatmapAnnotation(Chemical_Count = anno_barplot(unlist(apply(concmat, 2, function(x) sum(x > 1e-5)))),
                               Type = prodtypes, col = list("Type" = type_col))

row_ha <- rowAnnotation(Total_Abundance = anno_barplot(unlist(apply(concmat, 1, function(x) sum(x)))),
                        annotation_name_rot = 90)

# Run to add chemical classes to rows
#CFout <- read.delim(file = paste(myPath, "results", "ClassyFireAnnotation_allChems_batchAPI_2024-05-28.txt", sep = "/"), 
#              sep = "\t")
#ind <- match(row.names(concmat), CFout$DTXSID)
#row_ha2 <- rowAnnotation(Chemical_Class = CFout$superclass[ind])


# Set missing chemicals back to NA rather than 0
concmat[concmat == 0] <- NA

pdf(file = paste(myPath, 
                 "plots", 
                 "abundanceHeatmap_allCombined_sortByConcSampsAndChems.pdf", 
                 sep = "/"), 
    width = 11, height = 9)
print(Heatmap(concmat, name = "Reported Abundance (ug/g)", top_annotation = column_ha, right_annotation = row_ha,
              #left_annotation = row_ha2,
        row_title = "Chemicals", column_title = "Product Samples", cluster_rows = FALSE, na_col = "grey",
        cluster_columns = FALSE, show_row_names = FALSE, show_column_names = FALSE, column_split = sampcats_f))
dev.off()
```

```{r create_prevalence_table}
prevalence.table <- NULL
for (this.category in unique(sampcats_f))
{
  # Get only the columns for this category:
  this.subset <- concmat[,sampcats_f==this.category]
  # Remove chemicals that were not detected:
  this.subset <- subset(this.subset, 
                        apply(this.subset,1,function(x) !all(is.na(x))))
  this.subset <- as.data.frame(this.subset)
  # Calculate stats:
  this.mean <- apply(this.subset, 1, function(x) 
    signif(mean(x, na.rm=TRUE), 3)) 
  this.median <- apply(this.subset, 1, function(x) 
    signif(median(x, na.rm=TRUE), 3))
  this.stddev <- apply(this.subset, 1, function(x) 
    signif(sd(x, na.rm=TRUE), 3))
  this.num <- dim(this.subset)[2]
  this.prevalence <- apply(this.subset, 1, function(x)
    signif(sum(!is.na(x))/dim(this.subset)[2],3))
  # Annotate rows:
  this.subset$Category <- this.category
  this.subset$Chemical <- rownames(this.subset)
  this.subset$Num.Products <- this.num
  this.subset$Prevalence <- this.prevalence
  this.subset$Mean.Abundance <- this.mean
  this.subset$Median.Abundance <- this.median
  this.subset$StdDev.Abundance <- this.stddev
  prevalence.table <- rbind(prevalence.table, this.subset[,
                                                          c("Category",
                                                            "Chemical",
                                                            "Num.Products",
                                                            "Prevalence",
                                                            "Mean.Abundance",
                                                            "Median.Abundance",
                                                            "StdDev.Abundance")])
}
write.csv(prevalence.table,file=paste(myPath, 
                 "results", 
                 "SupTable-ChemPrevalenceByCategory.txt",
                 sep = "/"))
```

```{r examine_common_chemicals}
# There are blue horizontal lines across the articles. What are these chemicals
# and do they share any characteristics?
temp <- concmat[,prodtypes == "Consumer Article"]
commonChems <- which(unlist(apply(temp, 1, function(x) sum(!is.na(x)))) >= 0.80*dim(temp)[2])
# What are the chemical classes?
CFout <- read.delim(file = paste(myPath, "results", "ClassyFireAnnotation_allChems_batchAPI_2024-05-28.txt", sep = "/"), 
              sep = "\t")
ind <- match(row.names(temp)[commonChems], CFout$DTXSID)
as.data.frame(table(CFout$superclass[ind]))
# What functional uses?
load(paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs.RData", sep = "/"))
ind <- match(row.names(temp)[commonChems], use.pred.rep$DTXSID)
chemUses <- use.pred.rep[ind,]
usemat <- apply(chemUses, 2, function(x) sum(x >= 0.8))
usemat[which(usemat > 0)]


# Look into the top abundance chemicals
abundances <- unlist(apply(concmat, 1, function(x) sum(x, na.rm = TRUE)))
topChems <- names(abundances)[which(abundances > quantile(abundances, probs = 0.95))]
# What are the chemical classes?
ind <- match(topChems, CFout$DTXSID)
as.data.frame(table(CFout$superclass[ind]))
# What functional uses?
ind <- match(topChems, use.pred.rep$DTXSID)
chemUses <- use.pred.rep[ind,]
# Remove non-match
chemUses <- chemUses[!is.na(chemUses$DTXSID),]
usemat <- apply(chemUses, 2, function(x) sum(x >= 0.8))
usemat[which(usemat > 0)]
# How many of these chemicals were also in our list of outliers?
outlierChems <- read.delim(file = paste(myPath, "results", "prodCatChems_concOutliers_with99thperc.txt", sep = "/"))
outAndTop <- intersect(unique(outlierChems$DTXSID), topChems)
# Are any of these chemicals in the 25 that occur in at least 1 sample in each category?
allShared <- read.delim(file = paste(myPath, "results", "All25sharedChems_withProdCatCounts.txt", sep = "/"), sep = " ")
sharedAndTop <- intersect(allShared$DTXSID, topChems)
```

#########################################################################
# Try performing dimension reduction using chemical occurrence
```{r dimension_reduction}
load(file = paste(myPath, "data", "allCombDilDupRep_BinAndConcMats.RData", sep = "/"))

sampnums <- unlist(lapply(allComb_BinAndConc$conc, function(x) dim(x)[2]))
sampcats <- c()
for (i in 1:length(prodGroups)){
  sampcats <- c(sampcats, rep(prodGroups[i], sampnums[i]))
}
binmat <- do.call("cbind", allComb_BinAndConc$binary)

##### Chemical Pre-Filtering #####
chemcounts <- unlist(apply(binmat, 1, function(x) sum(!x == 0)))

# Drop chemicals only in 1 sample
ind <- chemcounts < 2
binmat <- binmat[!ind,]
chemcounts <- chemcounts[!ind]

# What if we just do the top 100 most common chemicals
ind <- sort(chemcounts, index.return = TRUE, decreasing = TRUE)
ind <- ind$ix[1:100]
binmat <- binmat[ind,]

# Just signature chemicals
load(paste(myPath, "results/prodCatSignatures_gte0.8sampOccurrence_all.RData", sep = "/"))
sigchems <- c()
for (i in 1:length(signatures)){
  sigchems <- c(sigchems, row.names(signatures[[i]]))
}
binmat <- binmat[row.names(binmat) %in% sigchems,]

colnames(binmat) <- sampcats
binmat <- t(binmat)

# TSNE
set.seed(115)
my.tsne <- tsne(binmat, initial_dims = 2)
my.tsne <- data.frame(my.tsne)
pdb <- cbind(my.tsne, row.names(binmat))
#library(plotly)
#plot_ly(data = pdb, x = ~X1, y = ~X2, type = 'scatter', mode = 'markers', split = ~factor(sampcats))

```



# Calculate Bioactivity:Exposure Ratios

[Not complete due to lack of chemical data] Use SEEM predictions and TEST oral rat 
LD50 predictions along with httk to produce BER values as a means to prioritize 
chemicals via risk.

```{r BERs}
# Load our signature chemicals data object
sigChemsAll <- read.delim(file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"))

# Find chemicals that have the data we need
ind1 <- which(!is.na(sigChemsAll$EXPOCAST_MEDIAN_EXPOSURE_PREDICTION_MG.KG.BW.DAY))
ind2 <- which(!is.na(sigChemsAll$ORAL_RAT_LD50_MOL.KG_TEST_PRED))
indBER <- intersect(ind1,ind2)

# Build a data frame
berDF <- sigChemsAll[indBER,c(1:4,11,15)]

# Apply uncertainty factor (Venman and Flaga 1985) for acute rat to chronic human
berDF$ORAL_RAT_LD50_MOL.KG_TEST_PRED <- 0.0001 * berDF$ORAL_RAT_LD50_MOL.KG_TEST_PRED


##### Use HTTK to calculate the human equivalent dose based on the rat LD50
#library(httk)
# For which chemicals does hhtk have all the information we need?
z <- subset(get_cheminfo(info = "all", species = "Human", model = "pbtk"), DTXSID %in% berDF$DTXSID)
# Only returns data for 7 chemicals.  Load the Dawson QSPR models to get predictions for chemicals
# without measured data already in httk
load_dawson2021(overwrite = TRUE)
z <- subset(get_cheminfo(info = "all", species = "Human", model = "pbtk"), DTXSID %in% berDF$DTXSID)

```


# Signatures at Different Category Levels

[Not Updated with Curated Chemicals] Do for multiple different levels, not just the above 5 categories. Any
different set of groupings can be used, so some manual input is needed
at the start of this section

```{r levelSigs}
load(paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))
refTable <- as.data.frame(read_xlsx(paste(myPath, "data", "masterSampleTable_withLevelsAndBrands.xlsx", sep = "/")))

# Reduce sample list to those in matrix
ind <- match(colnames(allProdTypesMat$binary), refTable$`System ID`)
refTable_2 <- refTable[ind,]
colnames(refTable_2)[1:3] <- c("Lvl1", "Lvl2", "Lvl3")

# List of groups to look at
myGroups <- list(c("Clothing", "Fabric"), "Cotton Clothing", "Fabric Upholstery", "baby_onesie", 
                 "shorts_or_pants", "baby_socks", "GERBER", "JOHNSON'S", c("Shampoo", "Baby Soap"), 
                 "Shampoo", "Baby Soap", "baby_wash", "natural", "traditional", 
                 "Silicone Kitchen Tools", "spatula", "cup")
names(myGroups) <- c("Lvl1", "Lvl2", "Lvl2", "Lvl3", "Lvl3", "Lvl3", "Brand", "Brand", "Lvl2", "Lvl2", 
                     "Lvl2", "Lvl3", "Lvl3", "Lvl3", "Lvl2", "Lvl3", "Lvl3")

topSignats <- list()
topConcs <- list()
sampleCount <- c()
for (i in 1:length(myGroups)){
  indS <- which(refTable_2[,colnames(refTable_2) %in% names(myGroups)[i]] %in% myGroups[[i]])
  sampleCount <- c(sampleCount, length(indS))
  rowcounts <- unlist(apply(allProdTypesMat$binary[,indS], 1, function(x) sum(x != 0))) 
  # Get median conc. in ug/g across samples
  rowMeans <- unlist(apply(allProdTypesMat$conc[,indS], 1, function(x) median(x/1000, na.rm = TRUE)))  
  prevChems <- which(rowcounts/length(indS) >= 0.8)
  topSignats[[i]] <- row.names(allProdTypesMat$binary)[prevChems]
  topConcs[[i]] <- rowMeans[prevChems]
  names(topSignats)[i] <- paste(names(myGroups)[i], ": ", paste(myGroups[[i]], collapse = " + "), sep = "")
  names(topConcs)[i] <- paste(names(myGroups)[i], ": ", paste(myGroups[[i]], collapse = " + "), sep = "")
  names(sampleCount)[i] <- paste(names(myGroups)[i], ": ", paste(myGroups[[i]], collapse = " + "), sep = "")
}

# Now build a heatmap for these signatures
# Rows are chemicals occurring in at least 1 signature and columns are the sample groups
# Want to pull the concentration values to get a median concentration
# Also want functional use for chemicals and sample count for each group of samples
sigChems <- unique(unlist(topSignats))
mydf <- as.data.frame(matrix(data = NA, nrow = length(sigChems), ncol = length(topSignats), 
                             dimnames = list(sigChems, names(topSignats))))
for (i in 1:length(topSignats)){
  ind <- match(topSignats[[i]], sigChems)
  mydf[ind, names(topSignats)[i]] <- topConcs[[i]]
}

# Build annotations for these
# Start with functional use
load(paste(myPath, "results", "predFuncUse_chemsAcrossAllSamps_prob.RData", sep = "/"))
preds$chemical_id <- NULL
preds <- as.matrix(preds)
ind <- match(row.names(mydf), row.names(preds))
useInd <- unlist(apply(preds[ind,], 1, function(x) ifelse(sum(is.na(x)) == length(x) | 
                                                          sum(x) == 0, NA, which(x == max(x)))))
uses <- colnames(preds)[useInd]
uses <- as.factor(uses)

palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
use_col <- palettes$`Tableau 20`$value[1:length(levels(uses))]
names(use_col) <- levels(uses)
left_ha <- rowAnnotation("Functional Use" = uses, col = list("Functional Use" = use_col),
                               annotation_name_gp = grid::gpar(fontsize = 8))

column_ha <- HeatmapAnnotation("Sample Count" = anno_barplot(unlist(apply(mydf, 2, function(x) sum(!is.na(x))))),
                               annotation_name_gp = grid::gpar(fontsize = 8))

# Build annotation for chemical count in each sample
right_ha <- rowAnnotation("Chemical Count" = anno_barplot(unlist(apply(mydf, 1, function(x) sum(!is.na(x))))),
                          annotation_name_rot = 90, annotation_name_gp = grid::gpar(fontsize = 8))

a <- Heatmap(as.matrix(mydf), name = "Median Conc. (ug/g)", top_annotation = column_ha, right_annotation = right_ha, 
             column_names_gp = grid::gpar(fontsize = 7), show_row_names = TRUE, cluster_rows = FALSE, 
             cluster_columns = FALSE, column_title = "Chemical Signatures at Different Product Levels", 
             column_split = c(1,1,1,2,2,2,3,3,4,4,4,5,5,5,6,6,6),
             row_names_side = "left", row_names_gp = grid::gpar(fontsize = 6.25), left_annotation = left_ha)
pdf(file = paste(myPath, "plots", "ChemSignatureHeatmap_withConc.pdf", sep = "/"))
  print(a)
dev.off()

```



# Build Model to Predict Product Type 

[Not Updated with Curated Chemicals] Want to build a sparse machine learning model 
based on chemical occurrence. Use all samples with all chemicals to predict the 
product type and identify the most influential chemicals for each class.

```{r sparsemodel}
load(paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))

# Bring in the dashboard result for our chemicals and remove those without a dashboard entry
myChems <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", sep = "/"), sheet = 2)
myChems <- myChems[,1:5]
# Drop chemicals that didn't have a match
todrop <- c("Searched by Synonym: Found 0 results", 
            "Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
myChems <- myChems[!myChems$FOUND_BY %in% todrop,]

# Need the final chemical X sample occurrence matrix, after combining repeats and duplicates
featMat <- allProdTypesMat$binary
# Match to reduced set
featMat <- featMat[row.names(featMat) %in% myChems$INPUT,]
# Drop chemicals occurring in only 1 training sample
oneSamp <- unlist(apply(featMat, 1, sum))
featMat <- featMat[!oneSamp == 1,]

labels <- allProdTypesMat$prodType
set.seed(112)
featMat <- t(featMat)
data <- as.data.frame(featMat)
data <- cbind("Type" = as.factor(labels), data)
cv_3 <- trainControl(method = "cv", number = 3)
def_elnet <- train(Type ~ ., data = data, method = "rf", trControl = cv_3)
varImp(def_elnet, useModel = TRUE, scale = FALSE)

# Compare to a null model
ind <- sample.int(dim(data)[1], dim(data)[1], replace = FALSE)
data_yrand <- data
data_yrand$Type <- data_yrand$Type[ind]
def_elnet_yrand <- train(Type ~ ., data = data_yrand, method = "rf", trControl = cv_3)


##### Now predict the product type of an external set of samples
# From Phillips et al 2017 supplemental data, 20 product types (5 samples each)
occurMat <- as.data.frame(read_xlsx(path = paste(myPath, "data", "KPhillips_SSofConsumerProds_SuppTables.xlsx", 
                                                 sep = "/"), sheet = 3))

# Examine data
length(unique(occurMat$chemical_name))  # 1602
as.data.frame(table(occurMat$product_type))  # 3: article, food, and formulation
as.data.frame(table(occurMat$product_category))  # 20 product categories for 100 total samples
as.data.frame(table(occurMat$hit_flag))

# Check to see if I can use the chemical names or if I need to do DTXSID or CAS instead
length(intersect(myChems$INPUT, unique(occurMat$chemical_name)))  # 0
length(intersect(myChems$DTXSID, unique(occurMat$dtxsid)))  # 222
length(intersect(myChems$CASRN, unique(occurMat$casrn)))  # 222

# Remove any NAs in the CAS column
occurMat <- occurMat[!is.na(occurMat$casrn),]  # Down from 6010 rows to 5982

# Turn this long-form table into an occurrence matrix of sample X chemical
extChems <- unique(occurMat$casrn)  # 1594
extSamps <- unique(occurMat$anonymized_product)
# Allocate space
extDF <- as.data.frame(matrix(data = NA, nrow = length(extSamps), ncol = length(extChems), 
                              dimnames = list(extSamps, extChems)))
for (i in 1:length(extSamps)){
  indS <- occurMat$casrn[occurMat$anonymized_product == extSamps[i]]
  extDF[i,unique(indS)] <- 1
}
# Replace NAs with zeros
extDF[is.na(extDF)] <- 0

# Build final DF for classification
finalDF <- as.data.frame(matrix(data = NA, nrow = dim(extDF)[1], ncol = dim(featMat)[2], 
                              dimnames = list(row.names(extDF), colnames(featMat))))
for (i in 1:dim(finalDF)[2]){
  # Get the index for this chemical so I can pull CAS of our final feature chemicals
  ind1 <- which(myChems$INPUT == colnames(finalDF)[i])  
  if (length(ind1) == 0){  # If there is no match, it is one of the 63 chemicals in my data without a dashboard entry
    finalDF[,i] <- 0    # meaning we can't say anything about occurrence
  } else {     # otherwise we want to match the CAS of our chemical to the external set
    ind2 <- which(extChems == myChems$CASRN[ind1])
    if (length(ind2) == 0){  # If there is no match, the chemical occurred in my data but not the external data
      finalDF[,i] <- 0    # meaning this chemical isn't present in the samples
    } else {
      # If we do find a match, use the external occurrence matrix to fill in the binary column
      finalDF[,i] <- extDF[,ind2]  
    }
  }  
}

# Get a sample - product category reference table
refSamp <- occurMat[,colnames(occurMat) %in% c("anonymized_product", "product_category", "product_type")]
refSamp <- refSamp[!duplicated(refSamp[,1:2]),]

# Use the model to make predictions
predicted <- predict(def_elnet, newdata = finalDF)

# Save the model that gave these predictions
rf_model_3cv <- def_elnet
varImp(rf_model_3cv, useModel = TRUE)
save(rf_model_3cv, file = paste(myPath, "results", "ProdTypeClassifModel_RandForest_3cv_dashChemsAllSamps_binary.RData", sep = "/"))

# Fill out reference table
refSamp$predicted <- predicted
true_names <- read.csv(file = paste(myPath, "data", "anonymized_product_dictionary.csv", sep = "/"), header = TRUE)
# Not in the same order, so have to match up. Drop spaces, points, and go to lowercase
vecRef <- gsub(" ", "", tolower(refSamp$anonymized_product))
vecTrue <- gsub("\\.", "", gsub(" ", "", tolower(true_names$anonymous)))
ind <- match(vecRef, vecTrue)

refSamp <- cbind("product_name" = true_names$product_name[ind], refSamp)
#save(refSamp, file = paste(myPath, "results", "PilotStudyPreds_RandForest_3cv_dashChemsAllSamps_binary.RData", 
#                            sep = "/"))

### AD Assessment
# Need a train and predicted matrix with labels
train <- as.data.frame(featMat)
trainlabels <- as.factor(labels)
train$train_class <- as.numeric(trainlabels)
train <- cbind("DTXSID" = row.names(train), train)

test <- finalDF
test$pred_class <- as.numeric(predicted)
test <- cbind("DTXSID" = row.names(test), test)

source(paste(myPath, "R/assessAD.R", sep = "/"))
indomain_DTXSIDs <- DomainOfApplicability(training=train, predicted=test)

refSamp$InDomain <- "No"
refSamp$InDomain[indomain_DTXSIDs] <- "Yes"

```
