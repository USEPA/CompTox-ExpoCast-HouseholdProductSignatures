---
title: "Main Analysis Pipeline"
author: "Zachary Stanfield"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: united
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Description

Analyze non-targeted analysis dataset of household consumer products. We
have 5 categories of products that include multiple dilutions, duplicate
samples, and repeated products. The main goal is to develop a chemical
ingredient signature at multiple levels (broad category down to specific
grouping levels like brand and socks within the clothing category). Also
want to assess within-product similarity of samples.

# Load Packages and Data Objects

```{r setEnv, include=FALSE}
library(readxl)
library(reshape2)
library(treecompareR)
library(caret)
library(ggplot2)
library(ComplexHeatmap)
library(ggthemes)
library(tidyr)
library(tidytext)
library(dplyr)
library(factoextra)
library(cluster)
library(vegan)
library(UpSetR)
library(QSUR)
library(RColorBrewer)
library(jsonlite)
library(data.table)
library(ggtree)
library(circlize)
library(proxy)
library(stringr)
library(colorRamp2)
library(rcartocolor)
#myPath <- "/ccte/home1/zstanfie/HouseholdProdSSA"
myPath <- "C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsSSA/HouseholdProdSSA"
prodGroups <- c("Cotton Clothing", "Shampoo", "Baby Soap", "Fabric Upholstery", "Silicone Kitchen Tools")
myFiles <- c("Sequence1 Clothing.xlsx", "Sequence2 Shampoo.xlsx", "Sequence1 Personal Care Products.xlsx",
             "Sequence3 Fabric.xlsx", "Sequence2 Kitchen.xlsx")
data_files <- paste(myPath, "raw_data", myFiles, sep = "/")
upc_file <- "EPA task 10 items_26Feb18.xlsx"
```

# Process the Raw Data

This function parses the raw data into multiple formats for downstream
analysis and saves them to the data directory

```{r processRaw}
source(paste(myPath, "R/processRawData.R", sep = "/"))

### Before running this, check the save_names assignment at the start of this function to make sure
### files are save in the right locations
processSSAfiles(data_files, myPath, prodGroups)

### This is for organizing the UPCs across raw data files intended for the use of querying 
### ChemExpo programmatically in downstream analyses. Don't need to run this if that is not part of the pipeline.
cleanForUPCs(upc_file, myPath, prodGroups)
```


# Summarize Data

```{r dataSummary}
load(file = paste(myPath, "data", "fullSetOfSamplesWithAllChems.RData", sep = "/"))

# unique chemicals
allChems <- unique(fullSampChemInfo$Name)
length(unique(fullSampChemInfo$Spectrum))
length(unique(fullSampChemInfo$CAS))
length(unique(fullSampChemInfo$CAS[!is.na(fullSampChemInfo$CAS)]))

# Hit flag distribution
as.data.frame(table(fullSampChemInfo$Group))

# Counts of spectra and chemicals by flag
indXC <- fullSampChemInfo$Group == "xc"
indXT <- fullSampChemInfo$Group == "xt"
# Unique spectra and chemical names with these flags
length(unique(fullSampChemInfo$Spectrum[indXC]))
length(unique(fullSampChemInfo$Spectrum[indXT]))
length(unique(fullSampChemInfo$Spectrum[indXC | indXT]))
length(unique(fullSampChemInfo$Spectrum[!(indXC | indXT)]))
length(unique(fullSampChemInfo$Name[indXC]))
length(unique(fullSampChemInfo$Name[indXT]))
length(unique(fullSampChemInfo$Name[indXC | indXT]))
length(unique(fullSampChemInfo$CAS[indXC | indXT]))
# Look at non-matches
indOther <- fullSampChemInfo$Group %in% c("ns", "xt;ui", "xt;ui;PCB", "xu")
length(unique(fullSampChemInfo$Spectrum[indOther]))
length(unique(fullSampChemInfo$Name[indOther]))
##
length(unique(fullSampChemInfo$Spectrum[indXC | indXT | indOther]))

# Add chemical identifiers where available (batch search EPA CompTox Dashboard by chemical name)
tps <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", sep = "/"), sheet = 2)
ind <- match(fullSampChemInfo$Name, tps$INPUT)
temp <- tps[ind, colnames(tps) %in% c("DTXSID", "PREFERRED_NAME", "CASRN")]
colnames(fullSampChemInfo)[7:9] <- paste("Raw_", colnames(fullSampChemInfo)[7:9], sep = "")
fullSampChemInfo <- cbind(fullSampChemInfo[,1:9], temp, fullSampChemInfo[,-c(1:9)])

#-------------------------------------------------------------------------------
# How many xc and xt chemicals (those we keep for downstream analysis) don't have
# a match on the CompTox Chemicals Dashboard (CCD)?
keepChems <- unique(fullSampChemInfo$Raw_Name[indXC | indXT])
xcxtChemsWithoutCCDmatch <- fullSampChemInfo[indXC | indXT,]
# Get counts
sum(is.na(xcxtChemsWithoutCCDmatch$DTXSID))
sum(!is.na(xcxtChemsWithoutCCDmatch$DTXSID))
xcxtChemsWithoutCCDmatch <- xcxtChemsWithoutCCDmatch[is.na(xcxtChemsWithoutCCDmatch$DTXSID),] 
length(unique(xcxtChemsWithoutCCDmatch$Raw_Name))
# Remove the all-NA columns
xcxtChemsWithoutCCDmatch[,c("DTXSID", "PREFERRED_NAME", "CASRN")] <- NULL
length(unique(xcxtChemsWithoutCCDmatch$Spectrum))
as.data.frame(table(xcxtChemsWithoutCCDmatch$Category))
# Save these as we might be able to register them in DSSTox
write.table(xcxtChemsWithoutCCDmatch, file = paste(myPath, "data", "xcxtChemsWithoutCCDmatch.txt", sep= "/"), 
              sep = "\t", row.names = FALSE)
#-------------------------------------------------------------------------------

# Now add chemical identifiers of those chemicals for which a dashboard match wasn't found (curated by Tony Williams)
curated <- read_xlsx("C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsSSA/xcxtChemsWithoutCCDmatch_TonyCurated.xlsx")
# Chemicals with a value of "Approved Name", "CAS-RN", or "Expert Validated Synonym" in the FOUND_BY column were linked to existing dashboard entries
# So remove rows not fitting this criteria
curated <- curated[curated$FOUND_BY %in% c("Approved Name", "CAS-RN", "Expert Validated Synonym"),]
ind <- match(fullSampChemInfo$Raw_Name, curated$Raw_Name)
ind2 <- which(!is.na(ind))
fullSampChemInfo[ind2,c("DTXSID", "PREFERRED_NAME", "CASRN")] <- curated[ind[ind2], c("DTXSID", "PREFERRED_NAME", "Raw_CAS")]

# Save for supplement
write.table(fullSampChemInfo, file = paste(myPath, "data", "fullSetOfSamplesWithAllChems.txt", sep= "/"), 
              sep = "\t", row.names = FALSE)

```


# Examine Dilution Effect

Most of our samples were run at 2 dilutions because some chemicals are more easily
extracted/detected at a different dilution. For example, in fabric upholstery and
cotton clothing samples, the more concentrated assays tended to be best for identifying 
lighter compounds and aromatics whereas hydrocarbons, long-chain alcohols, etc. were 
better observed in the more dilute assay. Use dimensionality reduction on chemical
occurrence to see if different dilutions of different products clearly separate.

```{r dilutionEffect}
# Read in the data object that has our full chemical by sample matrices
load(paste(myPath, "data", "chemXsamp_matrices_ns-xtui-xtuiPCB-xu_full.RData", sep = "/"))

sampCats <- chemXsamp_matrices_other$category
binmat <- chemXsamp_matrices_other$binary

# Remove blanks 
ind <- grep("SB", colnames(binmat))
binmat[,ind] <- NULL
sampCats <- sampCats[-ind]

##### Chemical Pre-Filtering #####
chemcounts <- unlist(apply(binmat, 1, function(x) sum(!x == 0)))

# Get rid of chemicals only in 1 sample
ind <- chemcounts < 2
binmat <- binmat[!ind,]
chemcounts <- chemcounts[!ind]

# Now extract dilutions, which are included in the sample names
dilus <- strsplit(colnames(binmat), "_(?!.*_)", perl = TRUE)
dilus <- do.call("rbind", dilus)
dilus <- dilus[,2]

# Add names and transpose
#colnames(binmat) <- sampCats
binmat <- t(binmat)

# Use TSNE
library(tsne)
set.seed(115)
my.tsne <- tsne(binmat, initial_dims = 2)
my.tsne <- data.frame(my.tsne)
pdb <- cbind(my.tsne, "Dilution" = dilus, "Category" = sampCats)
library(plotly)
plot_ly(data = pdb, x = ~X1, y = ~X2, type = 'scatter', mode = 'markers',  color = sampCats, symbol = dilus)


```


# Final Processing Steps

## Combine Dilutions

Will use the resulting samples, including duplicates and repeats, to
assess within- product variability for occurrence, concentration,
functional use, and ClassyFire.

```{r combineDilutions}
# Load data
load(paste(myPath, "data", "masterSampleList.RData", sep = "/"))
load(paste(myPath, "data", "chemXsamp_binary_full.RData", sep = "/"))
load(paste(myPath, "data", "chemXsamp_conc_full.RData", sep = "/"))
load(paste(myPath, "data", "chemXsamp_group_full.RData", sep = "/"))

# Drop Blanks
ind <- grep("SB", colnames(chemXsamp_binary))
chemXsamp_binary[,ind] <- NULL
chemXsamp_conc[,ind] <- NULL
chemXsamp_group[,ind] <- NULL

# Combine Dilutions
# Get list of all sample #s. Duplicate samples have the same sample #, so include _DUP at this stage
# b/c we want to keep duplicates separate for now.
ind <- which(allSamps$Type == "Solvent Blank")
allSamps <- allSamps[-ind,] 
sampNames <- allSamps$`System ID`
ind <- which(allSamps$Type == "Duplicate")
sampNames[ind] <- paste(sampNames[ind], "_DUP", sep = "")
chemXsamp_binary_red <- c()
chemXsamp_conc_red <- c()
chemXsamp_group_red <- c()
for (i in 1:length(sampNames)){

  indS <- grep(sampNames[i], colnames(chemXsamp_binary))
  if (length(grep("DUP", colnames(chemXsamp_binary)[indS])) > 0){
    # This sample is either a duplicate or has a duplicate. Don't want to combine duplicates yet.
    if (length(grep("DUP", sampNames[i])) > 0){
      # All good, sample is a duplicate and will only return samples of the form #####_DUP_##
    } else if (length(grep("DUP", sampNames[i])) == 0) {
      # Sample is not a duplicate but grep pulled the DUP samples as well. Drop the DUP ones b/c 
      # we just want the sample
      ind <- grep("DUP", colnames(chemXsamp_binary)[indS])
      indS <- indS[-ind]
    }
  }
  
  # if only 1 dilution factor was used, we don't have to worry about combining the samples
  # if more than 1 dilution, take union of binary, mean of conc, and xc over xt for group
  if (length(indS) == 1){
    chemXsamp_binary_red <- cbind(chemXsamp_binary_red, chemXsamp_binary[,indS])
    chemXsamp_conc_red <- cbind(chemXsamp_conc_red, chemXsamp_conc[,indS])
    chemXsamp_group_red <- cbind(chemXsamp_group_red, chemXsamp_group[,indS])
  } else {
    chemXsamp_binary_red <- cbind(chemXsamp_binary_red, as.numeric(do.call("|", chemXsamp_binary[,indS])))
    chemXsamp_conc_red <- cbind(chemXsamp_conc_red, unlist(apply(chemXsamp_conc[,indS], 1, 
                                                                 function(x) mean(x, na.rm = TRUE))))
    chemXsamp_group_red <- cbind(chemXsamp_group_red, 
                                 unlist(apply(chemXsamp_group[,indS], 1, 
                                              function(x) ifelse(sum(is.na(x)) == 2, NA, 
                                                                 ifelse(sum(is.na(x)) == 1, x[!is.na(x)],
                                                                        ifelse("xc" %in% x, "xc","xt"))))))
  }
}
colnames(chemXsamp_binary_red) <- sampNames
colnames(chemXsamp_conc_red) <- sampNames
colnames(chemXsamp_group_red) <- sampNames
row.names(chemXsamp_binary_red) <- row.names(chemXsamp_binary)
row.names(chemXsamp_conc_red) <- row.names(chemXsamp_binary)
row.names(chemXsamp_group_red) <- row.names(chemXsamp_binary)

# Extract Product-specific matrices
# The order of samples in allSamps matches that in our matrices
rawGroups <- c("Clothing", "Shampoo", "Personal Care Products", "Fabric", "Kitchen")
prodList <- list()
for (i in 1:length(rawGroups)){
  ind <- allSamps$Product == rawGroups[i]
  prodList[[i]] <- list("binary" = chemXsamp_binary_red[,ind], "conc" = chemXsamp_conc_red[,ind], 
                      "group" = chemXsamp_group_red[,ind], "prod_names" = allSamps$`Customer ID`[ind])
}
names(prodList) <- prodGroups
# Save
#save(prodList, file = paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

```


## Combine Duplicates and Repeats

Will use the resulting set of samples for clustering, upset plots, and
machine learning model to classify samples into their product
categories.

```{r combineDupsReps}
load(paste(myPath, "data", "masterSampleList.RData", sep = "/"))
ind <- grep("SOL",allSamps$`Customer ID`)
allSamps <- allSamps[-ind,]

# Combine duplicate samples and those from the same product
chemXsamp_binary_red2 <- c()
chemXsamp_conc_red2 <- c()
chemXsamp_group_red2 <- c()
DUPs <- sampNames[grep("DUP", sampNames)]
for (i in 1:length(DUPs)){
  # Can do easily b/c they share a sample name
  indS <- grep(substr(DUPs[i], 1, nchar(DUPs[i])-4), colnames(chemXsamp_binary_red))
  chemXsamp_binary_red2 <- cbind(chemXsamp_binary_red2, unlist(apply(chemXsamp_binary_red[,indS], 1, max)))
  chemXsamp_conc_red2 <- cbind(chemXsamp_conc_red2, unlist(apply(chemXsamp_conc_red[,indS], 1, 
                                                                 function(x) mean(x, na.rm = TRUE))))
  chemXsamp_group_red2 <- cbind(chemXsamp_group_red2, unlist(apply(chemXsamp_group_red[,indS], 1, 
                                                               function(x) ifelse(sum(is.na(x)) == 2, NA, 
                                                                                  ifelse(sum(is.na(x)) == 1,
                                                                                  x[!is.na(x)],
                                                                                  ifelse("xc" %in% x, "xc", "xt"))))))
}
colnames(chemXsamp_binary_red2) <- substr(DUPs, 1, nchar(DUPs)-4)
colnames(chemXsamp_conc_red2) <- substr(DUPs, 1, nchar(DUPs)-4)
colnames(chemXsamp_group_red2) <- substr(DUPs, 1, nchar(DUPs)-4)
row.names(chemXsamp_binary_red2) <- row.names(chemXsamp_binary_red)
row.names(chemXsamp_conc_red2) <- row.names(chemXsamp_binary_red)
row.names(chemXsamp_group_red2) <- row.names(chemXsamp_binary_red)
allSamps <- allSamps[!allSamps$`System ID` %in% substr(DUPs, 1, nchar(DUPs)-4),]


# Combine samples that are repeats of the same product
REPs <- allSamps$`Customer ID`[duplicated(allSamps$`Customer ID`)]
for (i in 1:length(REPs)){
  # Find sample IDs with this product name and combine
  indR <- allSamps$`System ID`[allSamps$`Customer ID` == REPs[i]]
  indS <- match(indR, sampNames)
  allSamps <- allSamps[!allSamps$`System ID` %in% indR,]
  chemXsamp_binary_red2 <- cbind(chemXsamp_binary_red2, 
                                 unlist(apply(chemXsamp_binary_red[,indS], 1, function(x) max(x, na.rm = TRUE))))
  chemXsamp_conc_red2 <- cbind(chemXsamp_conc_red2, 
                               unlist(apply(chemXsamp_conc_red[,indS], 1, function(x) mean(x, na.rm = TRUE))))
  chemXsamp_group_red2 <- cbind(chemXsamp_group_red2, 
                                unlist(apply(chemXsamp_group_red[,indS], 1, 
                                             function(x) ifelse(sum(is.na(x)) == 2, NA, 
                                              ifelse(sum(is.na(x)) == 1, x[!is.na(x)],
                                               ifelse("xc" %in% x, "xc", "xt"))))))
  
  colnames(chemXsamp_binary_red2)[dim(chemXsamp_binary_red2)[2]] <- sampNames[indS[1]]
  colnames(chemXsamp_conc_red2)[dim(chemXsamp_binary_red2)[2]] <- sampNames[indS[1]]
  colnames(chemXsamp_group_red2)[dim(chemXsamp_binary_red2)[2]] <- sampNames[indS[1]]
}

# Now add in the single sample products
singles <- allSamps$`System ID`
chemXsamp_binary_red2 <- cbind(chemXsamp_binary_red2, 
                               chemXsamp_binary_red[,colnames(chemXsamp_binary_red) %in% singles])
chemXsamp_conc_red2 <- cbind(chemXsamp_conc_red2, 
                             chemXsamp_conc_red[,colnames(chemXsamp_binary_red) %in% singles])
chemXsamp_group_red2 <- cbind(chemXsamp_group_red2, 
                              chemXsamp_group_red[,colnames(chemXsamp_binary_red) %in% singles])

# Put back in order
load(paste(myPath, "data", "masterSampleList.RData", sep = "/"))
ind <- match(colnames(chemXsamp_binary_red2), allSamps$`System ID`)
prodOrd <- allSamps$Product[ind]
prodOrd2 <- order(prodOrd)
chemXsamp_binary_red2 <- chemXsamp_binary_red2[,prodOrd2]
chemXsamp_conc_red2 <- chemXsamp_conc_red2[,prodOrd2]
chemXsamp_group_red2 <- chemXsamp_group_red2[,prodOrd2]

# Save these in case we need them later
allProdTypesMat <- list("binary" = chemXsamp_binary_red2, "conc" = chemXsamp_conc_red2, 
                        "group" = chemXsamp_group_red2, "prodType" = prodOrd[prodOrd2])
#save(allProdTypesMat, file = paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))

```


# Annotate Chemicals

The unique set of chemicals identified (confirmed or tentative; xc or
xt) across all samples was saved as a text file during the
processRawData function. This was run through the CompTox Dashboard to
obtain chemical identifiers (DTXSID, CAS, InChIKey) for ClassyFire and
the ToxPrints for functional uses. Perform annotations first to be able
to add them to certain plots in the downstream analysis if desired.


## Functional Uses

For all chemicals, run Phillips et. al. 2017 functional use QSUR model.
Only keep those in the applicability domain and with a probability \>=
0.8. Then, if a chemical has a reported use in FUse DB, assign it to
that chemical as well with a probability of 1.

```{r funcUse}
# Load combined duplicates data
load(file = paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Read in dashboard query file that has the toxprints and process.  Input for function 
# is a tab-separated file with ID and the toxprints
tps <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", sep = "/"), sheet = 2)
#colnames(tps)[1:50]
tps <- tps[,c(1:7,38:dim(tps)[2])]
# Check for rows that didn't match. Can't get predicted uses without a proper ID.
#as.data.frame(table(tps$FOUND_BY))
todrop <- c("Searched by Synonym: Found 0 results", "Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
curatedTPs <- tps[!tps$FOUND_BY %in% todrop,]  # Down from 495 to 426
# There are a couple of duplicate DTXSIDs which means the TPs for those are the same. Drop duplicates.
curatedTPs <- curatedTPs[!duplicated(curatedTPs$DTXSID),]


# Find which chemicals already have predictions
fuseDB <- read.csv(file = paste(myPath, "data/ChemExpo_bulk_functional_uses_20230817.csv", sep = "/"))
# Reduce this big matrix to just our chemicals
ind <- (fuseDB$DTXSID %in% curatedTPs$DTXSID) 
temp <- fuseDB[ind, c("DTXSID", "Harmonized.Functional.Use")]  # "Reported.Functional.Use", 
# Reduce to unique rows (different documents can report the same use for the same chemical)
temp <- unique(temp)
# There are also rows with a blank harmonized use (remove these)
temp <- temp[!temp$Harmonized.Functional.Use == "",]

# Turn this into a matrix of chemical by use
repUseMat <- as.data.frame(matrix(data = NA, nrow = length(curatedTPs$DTXSID), 
                                  ncol = length(unique(temp$Harmonized.Functional.Use)),
                                        dimnames = list(curatedTPs$DTXSID, unique(temp$Harmonized.Functional.Use))))
# Populate the data frame
for (i in 1:dim(repUseMat)[1]){
  ind <- (temp$DTXSID == row.names(repUseMat)[i])
  repUseMat[i, colnames(repUseMat) %in% temp$Harmonized.Functional.Use[ind]] <- 1
}
# Set NAs to 0
repUseMat[is.na(repUseMat)] <- 0
# How many chemicals are reported for each use?
a <- apply(repUseMat, 2, sum)
as.data.frame(a[order(a, decreasing = TRUE)])


### Switch to predicted uses
# Get predictions for the rest. First line is for only predicting for chemicals not in FUse. Latter is for predicting for all, which is what I used.
#chems4qsurs <- curatedTPs[!curatedTPs$DTXSID %in% temp$DTXSID, !colnames(curatedTPs) %in% 
#                           c("INPUT", "FOUND_BY", "PREFERRED_NAME", "CASRN", "INCHIKEY", "QSAR_READY_SMILES")]
chems4qsurs <- curatedTPs[, !colnames(curatedTPs) %in% 
                           c("INPUT", "FOUND_BY", "PREFERRED_NAME", "CASRN", "INCHIKEY", "QSAR_READY_SMILES")]
colnames(chems4qsurs)[1] <- "M_NAME"
# Need to save this b/c the input is a file location
write.table(chems4qsurs, file = paste(myPath, "data/chems2predFUfor_TPs.tsv", sep = "/"), sep = "\t", row.names = FALSE)

# Following Suggested Code in the QSUR R Package ReadMe 
TPfile <- paste(myPath, "data", "chems2predFUfor_TPs.tsv", sep = "/")
chems <- read_toxprints(io = TPfile, source = "chemotyper")

# Toxprints were not available for 3 chemicals.  Remove these rows.  When using all my chems, this is only 5
#chems <- chems[!is.na(chems$atom.element_main_group),]

# Load the QSUR models
qsurs <- qsur_models()

# Predict with all QSUR models
preds <- predict_all_QSUR(models = qsurs, df = chems)

# Get predictions that are within the AD
valids <- in_domain(df = chems, models = qsurs)

# 2 of the models are missing in the valids object.  These are columns 31 and 32.
setdiff(colnames(preds), colnames(valids))
# They have 3 and 0 chemicals with a prediction prob >= 0.8 so just drop them for this analysis
preds <- preds[,-c(31,32)]
# Set the probability to 0 for those out of the AD
indOutAD <- (valids == FALSE) 
preds[indOutAD] <- 0
# Still use the 0.8 cutoff, but keep the numeric value to assign 1 use to each chemical later on
preds[,-1] <- apply(preds[,-1], 2, function(x) ifelse(x >= 0.8, x, 0))

# Some chemicals didn't have ToxPrints/predictions were not available. Want to keep identical
# rows between this and the reported use matrix, so fill NAs with 0s
preds[is.na(preds)] <- 0

# Put chemical column as row names and remove it
#row.names(preds) <- preds$chemical_id
#preds$chemical_id <- NULL
# How many chemicals are predicted for each use
a <- apply(preds, 2, function(x) sum(x > 0.5))
as.data.frame(a[order(a, decreasing = TRUE)])


### For the higher-level plot, I want to have both predicted and reported uses in 1 matrix
### Keep repUseMat as-is until the plotting stage as I want to use that for category-specific plots
# But need to make column names lowercase and replace spaces with "_"
colnames(repUseMat) <- gsub(" ", "_", tolower(colnames(repUseMat)))
# Remove any uses that don't have a hit for any chemical
todrop <- apply(repUseMat, 2, function(x) sum(x) == 0)
if (any(todrop)){
  repUseMat[,todrop] <- NULL
}
# Save just the reported use matrix here 
save(repUseMat, file = paste(myPath, "results", "RepHarmonizedUses_chemsAcrossAllSamps.RData", sep = "/"))

# Some of the harmonized uses map to multiple qsur models. For the high-level plot, I just want to
# look at each row/chemical. If there is a 1, it is reported. If 0.8 < x < 1, it is predicted. If < 0.8, there
# is no associated use. To report the most data in the supplement, only aggregate columns that have
# identical names.
sharedUses <- intersect(names(qsurs), colnames(repUseMat))
# Keep track of which use column belongs to each and allow for data merging
repUseMat2 <- repUseMat
ind <- colnames(repUseMat2) %in% sharedUses
colnames(repUseMat2)[ind] <- paste("shared.", colnames(repUseMat2)[ind], sep = "")  
colnames(repUseMat2)[!ind] <- paste("rep_use.", colnames(repUseMat2)[!ind], sep = "")
# Do the same for the predicted columns
ind <- colnames(preds) %in% sharedUses
colnames(preds)[ind] <- paste("shared.", colnames(preds)[ind], sep = "")  
colnames(preds)[!ind] <- paste("pred_use.", colnames(preds)[!ind], sep = "")

# Merge these two objects. Fastest is rbindlist() where the objects need to be data tables
# with a key column.
colnames(preds)[1] <- "DTXSID"
repUseMat2 <- as.data.table(cbind("DTXSID" = row.names(repUseMat2), repUseMat2), keep.rownames = FALSE)
# First obtain the max value of each row for all the shared columns
test <- bind_rows(preds, repUseMat2) %>% 
                  group_by(DTXSID) %>% 
                  summarise(across(starts_with("shared"), list(max = max)))
# Drop appended column name text
colnames(test) <- gsub("_max", "", colnames(test))
# Do a simple merge to get all the other columns
test2 <- merge(preds, repUseMat2, by = "DTXSID", all = TRUE)
# Remove the "shared" columns in test2 and replace them with those in test
use.pred.rep <- test2
use.pred.rep <- use.pred.rep[,-grep("shared", colnames(use.pred.rep))]
use.pred.rep <- merge(test, use.pred.rep, by = "DTXSID", all = TRUE)

# Remove any uses that don't have a hit for any chemical
todrop <- which(unlist(apply(use.pred.rep[,-1], 2, function(x) sum(x) < 0.1))) + 1
if (length(todrop) > 0){
  use.pred.rep[,todrop] <- NULL
}

# Save these predictions.  First add chemical names so I can match with other matrices.
ind <- match(use.pred.rep$DTXSID, curatedTPs$DTXSID)
use.pred.rep <- as.data.frame(use.pred.rep)
row.names(use.pred.rep) <- curatedTPs$INPUT[ind]
use.pred.rep <- cbind("DTXSID" = use.pred.rep$DTXSID, "CASRN" = curatedTPs$CASRN[ind], use.pred.rep[,-1])
#save(use.pred.rep, file = paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs_v2.RData", sep = "/"))

# Save .txt version for supplemental data file 
write.table(use.pred.rep, file = paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs_v2_data.txt", 
                                       sep = "/"), sep = "\t", row.names = FALSE)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## Make Functional Use Plots

Have one plot showing all 5 categories and the distribution of predicted
and reported uses. Have one plot for each product category showing the
number of reported uses in each sample.

```{r usePlots}
# Combined reported and predicted use matrix
load(file = paste(myPath, "results", "predAndKnownFuncUse_chemsAcrossAllSamps_probs_v2.RData", sep = "/"))

# Just reported uses
load(file = paste(myPath, "results", "RepHarmonizedUses_chemsAcrossAllSamps.RData", sep = "/"))

# Is a matrix of chemical name by functional use. Want to combine with the matrix I made in the previous section
load(file = paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# prodList is a list of all 5 groups with 4 elements each.  Pull the binary matrices and concatenate them.
allProdsMat <- list()
for (i in 1:length(prodGroups)){
  temp <- prodList[[i]][[1]]
  colnames(temp) <- prodList[[i]][[4]]
  allProdsMat$binary <- cbind(allProdsMat$binary, temp)
  allProdsMat$prodType <- c(allProdsMat$prodType, rep(prodGroups[i], dim(temp)[2]))
}

# The row names are the same, so reduce our chemical X sample matrix to those with uses
allProdsMat$binary <- allProdsMat$binary[row.names(allProdsMat$binary) %in% row.names(use.pred.rep),]

## Get a summary plot for all categories.  Want a split bar for each category.  One color for all chemicals,
## one for reported use, and one for predicted use (>= 0.8)
# First load master sample list so I can use anonymized sample names in the product-specific figures
refTable <- as.data.frame(read_xlsx(paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", sep = "/")))
# Remove blanks
refTable <- refTable[!refTable$Group3 == "blank",]

# Step through each category, select samples, and aggregate uses over chemicals 
allCatUses <- c()
prodCatUses <- list()
# Build data objects needed for plotting
for (i in 1:length(prodGroups)){
  temp <- allProdsMat$binary[,allProdsMat$prodType == prodGroups[i]]
  catChems <- which(apply(temp, 1, sum) > 0) # all chemicals present in samples of this category
  
  # Show the number of chemicals per category
  print(prodGroups[i])
  print(length(catChems))
  
  # High Level
  # For each row/chemical, if there is a 1 for any use, then it is a reported use -> label it as such
  # if there is no use with a value of 1 but a value between 0.8 and 1, then a use was successfully predicted
  # if the first two cases are not met, then assign that chemical as not having a functional use
  useFlags <- apply(use.pred.rep[catChems,-c(1,2)], 1, function(x) ifelse(any(x > 0.9999), "Reported", 
                                                              ifelse(any(x >= 0.8), "Predicted", NA)))
  allCatUses <- rbind(allCatUses, cbind(prodGroups[i], length(catChems), sum(useFlags == "Reported", na.rm = TRUE),
                                        sum(useFlags == "Predicted", na.rm = TRUE), sum(is.na(useFlags))))
  
  # Per Category
  # Want to count those with a reported use per sample. 
  repUses <- c()
  for (j in 1:dim(temp)[2]){
    sampChems <- which(temp[,j] == 1)
    repUses <- rbind(repUses, apply(repUseMat[sampChems,], 2, sum))
  }
  
  # Get anonymized sample and brand name, subtype. temp and refTable are in the same order, just have to 
  indSamp <- refTable$Group2 == prodGroups[i]
  prodCatUses[[i]] <- cbind(colnames(temp), gsub(" ", "_", refTable$`Anon Sample 2`[indSamp]), 
                            refTable$`Anon Brand`[indSamp], gsub(" ", "_", refTable$Group3[indSamp]), repUses)
  colnames(prodCatUses[[i]]) <- c("CustomerID", "SampleName", "BrandName", "Type", colnames(repUses))
}
colnames(allCatUses) <- c("Category", "Unique Chemicals", "Reported Use", "Predicted Use", "Unknown Use")
allCatUses <- as.data.frame(allCatUses)
names(prodCatUses) <- prodGroups


# Plot high level
df <- allCatUses[,-2]
#df <- allCatUses[,-5]
df <- df %>% gather(Annotation, Count, -Category)
df$Count <- as.numeric(df$Count)
df$Annotation <- factor(df$Annotation, levels = c("Reported Use", "Predicted Use", "Unknown Use"), 
                        ordered = TRUE)
#df$Annotation <- factor(df$Annotation, levels = c("Unique Chemicals", "Reported Use", "Predicted Use"), 
 #                       ordered = TRUE)
df$Category <- factor(df$Category, level = prodGroups, ordered = TRUE)
g <- ggplot(df, aes(fill = Annotation, y = Count, x = Category)) +
  geom_bar(position = "stack", stat = "identity") +
  #geom_bar(position = "dodge", stat = "identity") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
  theme(text = element_text(size = 13)) +
  labs(title = "Functional Use Distribution of Product Category Chemicals", 
       x = "Product Category", y = "Unique Chemicals")
pdf(file = paste(myPath, "plots", "funUseAnnoAll5CatsBarPlot_withDupReps_v2.pdf", sep = "/"), width = 8, height = 7)
  print(g)
dev.off()

# Save data for figure 
write.table(df, file = paste(myPath, "results", 
                             "funUseAnnoAll5CatsBarPlot_withDupReps_v2_data.txt", sep = "/"), 
            sep = "\t", row.names = FALSE)


# Build a heatmap for each product category
# Want to show product subcategory and anonymized brand, so use complex heatmap
for (i in 1:length(prodGroups)){
  
  temp <- prodCatUses[[i]][,-c(1:4)]
  
  # Want to shorten some of the use names for plotting
  ind <- which(!is.na(match(colnames(temp), c("processing_aids_not_otherwise_specified",
                                              "no_specific_technical_function",
                                              "surfactant_(surface_active_agent)",
                                              "propellants,_non-motive_(blowing_agents)"))))
  colnames(temp)[ind] <- c("processing_aids", "no_specific_function", "surfactant", "propellants,_non-motive")
  
  temp <- as.data.frame(apply(temp, 2, as.numeric))
  row.names(temp) <- prodCatUses[[i]][,2]
  tempAnno <- as.data.frame(prodCatUses[[i]][,1:4])
  
  # The columns I want to use for annotations need to be ordered factors. Subset to the product
  # category so the brand labels don't get mixed up
  tempAnno$BrandName <- as.factor(as.character(tempAnno$BrandName))
  tempAnno$Type <- as.factor(as.character(tempAnno$Type))
  
  palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
  brand_col <- palettes$`Tableau 20`$value[1:length(unique(tempAnno$BrandName))]
  names(brand_col) <- levels(tempAnno$BrandName)
  
  #type_col <- brewer.pal(length(unique(tempAnno$Type)), "Dark2")
  #palettes <- ggthemes_data[["wsj"]][["palettes"]]
  #type_col <- palettes$`colors6`$value[1:(length(unique(tempAnno$Type))+1)]
  #type_col <- type_col[-3]  # The 3rd color is too similar to one in the brand color palette
  type_col <- rcartocolor::carto_pal(n = (1 + length(unique(tempAnno$Type))), name = "Antique")
  type_col <- type_col[-2]
  names(type_col) <- levels(tempAnno$Type)
  
  # Minimum number of elements for the palette is 3, so it adds a 3rd color. Remove this.
  if(length(unique(tempAnno$Type)) < 3){
    type_col <- type_col[1:length(unique(tempAnno$Type))]
  }
  
  # To visualize the colors that are pulled
  #if (test){
  #  plot(NULL, xlim =c(0, length(brand_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
  #  rect(0:(length(brand_col)-1), 0, 1:length(brand_col), 1, col = brand_col)
  #  plot(NULL, xlim =c(0, length(type_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
  #  rect(0:(length(type_col)-1), 0, 1:length(type_col), 1, col = type_col)
  #}
  
  column_ha <- rowAnnotation(SubCategory = tempAnno$Type, Brand = tempAnno$BrandName,   
                                 col = list("SubCategory" = type_col, "Brand" = brand_col))
  temp[temp == 0] <- NA
  col_fun = colorRamp2(c(1, max(temp, na.rm = TRUE)), c("darkblue", "yellow"))
  
  # Sort uses by most chemicals
  useCounts <- unlist(apply(temp, 2, function(x) sum(x, na.rm = TRUE)))
  ind0 <- useCounts == 0
  temp <- temp[,!ind0]
  temp <- temp[,order(useCounts[!ind0], decreasing = TRUE)]
  
  # For count legend
  mySeq <- round(seq.int(from = 1, to = max(temp, na.rm = TRUE), length.out = 4))
  
  # Make plot
  if (prodGroups[i] == "Fabric Upholstery"){
    ht <- Heatmap(temp, col = col_fun, 
                  heatmap_legend_param = list(title = "Chemical Count", at = mySeq, labels = as.character(mySeq)), 
                  na_col = "white", row_title = "Samples", 
                  column_title = paste("Reported Functional Uses in ", prodGroups[i], " Products", sep = ""),
                  cluster_rows = TRUE, cluster_columns = FALSE, show_row_names = TRUE, show_column_names = TRUE,
                  column_names_rot = 90, rect_gp = gpar(col = "white", lwd = 1.4, cex = 1.1),
                  column_names_gp = grid::gpar(fontsize = 9), row_names_gp = grid::gpar(fontsize = 9))
  } else {
    ht <- Heatmap(temp, col = col_fun, 
                  heatmap_legend_param = list(title = "Chemical Count", at = mySeq, labels = as.character(mySeq)), 
                  na_col = "white", row_title = "Samples", left_annotation = column_ha,
                  column_title = paste("Reported Functional Uses in ", prodGroups[i], " Products", sep = ""),
                  cluster_rows = TRUE, cluster_columns = FALSE, show_row_names = TRUE, show_column_names = TRUE,
                  column_names_rot = 90, rect_gp = gpar(col = "white", lwd = 1.4, cex = 1.1),
                  column_names_gp = grid::gpar(fontsize = 9), row_names_gp = grid::gpar(fontsize = 9))
  }
  pdf(file = paste(myPath, "plots", paste("prodCatHeatmap_ReportedUses_", prodGroups[i], 
                                          "_withDupReps_v2.pdf", sep = ""), sep = "/"), width = 10, height = 7.5)
    draw(ht)
  dev.off()
  
  # Save data for each figure 
  write.table(cbind("Category" = rep(prodGroups[i], dim(temp)[1]), prodCatUses[[i]][,-1]), 
                    file = paste(myPath, "results", paste("prodCatHeatmap_ReportedUses_", prodGroups[i], 
                                                      "_withDupReps_v2_data.txt", sep = ""), sep = "/"), 
              sep = "\t", row.names = FALSE)
}

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## ClassyFire

Use the treeCompareR package written by Paul Kruse to annotate my
chemicals via the ClassyFire API and then make a series fo tree
diagrams.

```{r classyfire}
devtools::install_git(url = 'https://bitbucket.epa.gov/scm/~pkruse/treecomparer.git', 
                       ref = "merge_kr_rcpp_kruse", git = "external")

# Read in my dashboard file
HPssa <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", sep = "/"), sheet = 2)
# Check for rows that didn't have a match
as.data.frame(table(HPssa$FOUND_BY))
todrop <- c("Searched by Synonym: Found 0 results", 
            "Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
curatedHPssa <- HPssa[!HPssa$FOUND_BY %in% todrop,]
colnames(curatedHPssa)[1:20]
curatedHPssa <- curatedHPssa[,c(3:7)]


###############################
# Using ClassyFire batch search
CFresult <- read.csv(file = "C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsSSA/houseProdSSA_chems_ClassyFire_batchquery_2023-12-07.csv")
# Remove any chemicals that couldn't be classified
CFresult <- CFresult[!CFresult$ClassyFy.Status == "Failed",]
# Match with curatedHPssa object to add chemical name, DTXSID, and CAS
ind <- match(CFresult$InChIKey, curatedHPssa$INCHIKEY)
CFresult <- cbind("DTXSID" = curatedHPssa$DTXSID[ind], "PREFERRED_NAME" = curatedHPssa$PREFERRED_NAME[ind], 
                  "CASRN" = curatedHPssa$CASRN[ind], CFresult)
CFresult$ClassyFy.Status <- NULL
# Save object for manuscript supplemental data
write.table(CFresult, file = paste(myPath, "results", "ClassyFireAnnotation_allChems_batchAPI.txt", sep = "/"), 
              sep = "\t", row.names = FALSE)
##############################


# Classify my chemicals
curatedHPssa<- data.table(curatedHPssa)
myClassified <- classify_inchikeys(curatedHPssa$INCHIKEY, tax_level_labels = chemont_tax_levels, wait_min = 0.5)
# Run again for chemicals that didn't work from this first step
#myClassified <- classify_by_smiles(myClassified)

# Examine classifications
head(myClassified)
as.data.frame(table(myClassified$report))

# Set up the chemOnt tree
tax_nodes <- jsonlite::read_json('http://classyfire.wishartlab.com/tax_nodes.json')
length(tax_nodes)
tax_nodes[[1]]
str(tax_nodes[[1]])
# Organize nodes and ontology info
tax_nodes[[1]]$parent_chemont_id <- NA
chemont_taxnodes <- data.frame('Name' = sapply(tax_nodes, function(t) {t[[1]]}),
                               'ID' = sapply(tax_nodes, function(t) {t[[2]]}),
                               'Parent_ID' = sapply(tax_nodes, function(t) {t[[3]]}))
head(chemont_taxnodes)
# Build the ontology
chemont_taxonomy <- generate_taxonomy_tree(tax_nodes = chemont_taxnodes)
str(chemont_taxonomy)
# Finalize tree and test view
chemont_tree <- chemont_taxonomy
ggtree(chemont_tree) + layout_circular()

# Remove NAs and convert my data to wide form
myData <- myClassified[!is.na(myClassified$level),]
myData <- pivot_wider(myData[,c(1:3,5:6)], names_from = "level", values_from = "name")
myData <- myData[,c(1:9,11,10)]
myData <- cbind(myData, "level9" = NA, "level10" = NA, "level11" = NA)

# add Chemical names and product type to this data
ind <- match(myData$identifier, HPssa$INCHIKEY)
myData <- cbind("Chemical" = HPssa$INPUT[ind], myData)

# Look at how our SSA chemicals span the full ontology
pdf(file = paste(myPath, "plots", "chemsInFullTree_AllChems.pdf", sep = "/"))
display_subtree(data_1 = myData, name_1 = 'HouseProdSSA')
dev.off()

# Visualize the tree spanned by just our chemicals
pdf(file = paste(myPath, "plots", "AllMyChems_subtree.pdf", sep = "/"))
prune_and_display_subtree(prune_to = myData, prune_name = "All Chemicals")
dev.off()
# Make this subtree a tree object we can plot subtrees on
myFullTree <- prune_tree(tree = chemont_tree, prune_to = myData)
# Check it is correct by plotting
ggtree(myFullTree) + layout_circular()
#prune_and_display_subtree(myData, show_tips = FALSE)

# Now do for each product group individually.  Load needed data
# Need to go to the clustering section , which is where 
load(paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))
myProds <- unique(allProdTypesMat$prodType)
for (i in 1:length(myProds)){
  # Samples of type i
  prodSamps <- allProdTypesMat$prodType == myProds[i]
  # Chems measured in samples of type i
  prodChems <- row.names(allProdTypesMat$binary)[which(unlist(apply(allProdTypesMat$binary[indP, prodSamps], 
                                                                    1, sum)) > 0)]
  # Now reduce full tree to tree for product type i. Note that not all chemicals had dashboard entries, 
  # so a couple of chemicals from each product type will be missing
  ind <- match(prodChems, myData$Chemical)
  temp <- myData[ind,]
  temp <- temp[!is.na(temp$Chemical),]
  
  # Plot subtree
  pdf(file = paste(myPath, "plots", paste("AllMyChems_subtree_with", myProds[i], "Chems.pdf", sep = ""), sep = "/"))
  print(display_subtree(base_tree = myFullTree, base_name = "All Product Chemicals", data_1 = temp, 
                  name_1 = paste(myProds[i], "Chems", sep = " ")))
  dev.off()
}

# Can visualize a numerical value overlaid on this tree.  Maybe start with just the
# number of samples each chemical occurs in. So I need to add a column to the object
# myClassified that has the sample count (just sum rows of chemXsamp_binary_full.RData).
myClassified_terminal <- add_terminal_label(myClassified)
circ_tree_boxplot(myClassified_terminal, col = 'Sample Count')

# Look at the number of unique labels for each taxonomic level
label_bars(myClassified_terminal)

# If I want to compare tress from 2 product types, I can subset myClassified and
# then 
data_list <- list(myClassified_terminal_1, myClassified_terminal_2)
names(data_list) <- c('Clothing', 'Fabric')
label_bars(data_list)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


# Within-product Category Similarity

## By Chemical Occurrence

```{r prodSimOccur}
# Get curated table of group levels and brands
prodOnt <- as.data.frame(read_xlsx(path = paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", 
                                                sep = "/")))
# Remove blanks
prodOnt <- prodOnt[!prodOnt$Group3 == "blank",]
# Change NA brand to "unknown"
prodOnt$`Anon Brand` <- as.character(prodOnt$`Anon Brand`)
indNA <- prodOnt$`Anon Brand` == "NA"
prodOnt$`Anon Brand`[indNA] <- "unknown"
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

distances <- list()
plot <- TRUE
for (i in 1:length(prodList)){
  if (names(prodList)[i] == "Fabric Upholstery"){
    # Doesn't have sub groups for product or brand names 
    # Get the anonymized sample names using master table
    ind <- match(colnames(prodList[[i]]$binary), prodOnt$MySysID)
    
    distances[[i]] <- as.matrix(dist(t(prodList[[i]]$binary), method = "binary"))
    colnames(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
    row.names(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
  
    # Build annotation for chemical count in each sample
    right_ha <- rowAnnotation("Chemical Count" = anno_barplot(unlist(apply(prodList[[i]]$binary, 
                                                                           2, function(x) sum(x!=0)))),
                                                                           annotation_name_rot = 90)
    
    # Set colors and range
    col_fun <- colorRamp2(c(0, 0.5, 1), c("blue", "white", "red"))
    
    a <- Heatmap(distances[[i]], name = "Distance", col = col_fun, right_annotation = right_ha, 
                 column_names_gp = grid::gpar(fontsize = 8), show_row_names = FALSE,
                 column_title = paste(names(prodList)[i], "Products", sep = " "))
    if (plot){
      pdf(file = paste(myPath, "plots/singleProdCatSimilarityHeatmaps", 
                       paste("withinProdSimilarityHeatmap_", names(prodList)[i], 
                             "_anonSampBrand_v2.pdf", sep = ""), sep = "/"))
      print(a)
      dev.off()
    }
    
  } else {
  
    # Get brand, product sub-category, and curated sample names using master table
    ind <- match(colnames(prodList[[i]]$binary), prodOnt$MySysID)
    
    distances[[i]] <- as.matrix(dist(t(prodList[[i]]$binary), method = "binary"))
    colnames(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
    row.names(distances[[i]]) <- prodOnt$`Anon Sample 2`[ind]
    
    # The columns I want to use for annotations need to be ordered factors. Subset to the product
    # category so the brand labels don't get mixed up
    temp <- prodOnt[ind,]
    temp$`Anon Brand` <- as.factor(as.character(temp$`Anon Brand`))
    temp$Group3 <- as.factor(temp$Group3)
    
    # Build annotations for these
    #library(RColorBrewer)
    palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
    brand_col <- palettes$`Tableau 20`$value[1:length(unique(temp$`Anon Brand`))]
    names(brand_col) <- levels(temp$`Anon Brand`)
    #type_col <- brewer.pal(length(unique(temp$Group3)), "Dark2")
    #names(type_col) <- levels(temp$Group3)
    type_col <- rcartocolor::carto_pal(n = (1 + length(unique(temp$Group3))), name = "Antique")
    type_col <- type_col[-2]
    names(type_col) <- levels(temp$Group3)
    
    # Minimum number of elements for the palette is 3, so it adds a 3rd color. Remove this.
    if(length(unique(temp$Group3)) < 3){
      type_col <- type_col[1:length(unique(temp$Group3))]
    }
    
    # To visualize the colors that are pulled
    #if (test){
    #  plot(NULL, xlim =c(0, length(brand_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
    #  rect(0:(length(brand_col)-1), 0, 1:length(brand_col), 1, col = brand_col)
    #  plot(NULL, xlim =c(0, length(type_col)), ylim =c(0,1), xlab = "", ylab = "", xaxt = "n", yaxt = "n")
    #  rect(0:(length(type_col)-1), 0, 1:length(type_col), 1, col = type_col)
    #}
    
    column_ha <- HeatmapAnnotation(SubCategory = temp$Group3, Brand = temp$`Anon Brand`,   
                                   col = list("SubCategory" = type_col, "Brand" = brand_col))
    
    # Build annotation for chemical count in each sample
    right_ha <- rowAnnotation("Chemical Count" = anno_barplot(unlist(apply(prodList[[i]]$binary, 
                                                                           2, function(x) sum(x!=0)))),
                                                                           annotation_name_rot = 90)
    # Set colors and range
    col_fun <- colorRamp2(c(0, 0.5, 1), c("blue", "white", "red"))
    
    # Our categories either have ~20 samples or ~40 samples. 
    # Use 2 different font sized for the sample names in the figures.
    if(names(prodList)[i] %in% c("Cotton Clothing", "Silicone Kitchen Tools")){
      myFontSize <- 9.5
    } else {
      myFontSize <- 7.7
    }
    
    a <- Heatmap(distances[[i]], name = "Distance", col = col_fun, top_annotation = column_ha, 
                 right_annotation = right_ha, 
                 column_names_gp = grid::gpar(fontsize = myFontSize), show_row_names = FALSE,
                 column_title = paste(names(prodList)[i], "Products", sep = " "))
    if (plot){
      pdf(file = paste(myPath, "plots/singleProdCatSimilarityHeatmaps", 
                       paste("withinProdSimilarityHeatmap_", names(prodList)[i], 
                             "_anonSampBrand_v2.pdf", sep = ""), sep = "/"))
        print(a)
      dev.off()
    }
  }
}


# Examine within-product category sample variability
names(distances) <- prodGroups
simTable <- c()
for (i in 1:length(prodGroups)){
  # First find where our dups and reps are
  indDups <- grep("dup", colnames(distances[[i]]))
  indReps <- grep("rep", colnames(distances[[i]]))
  # All samples without the diagonal
  indTri <- upper.tri(distances[[i]])
  avgTot <-  mean(distances[[i]][indTri])
  sdTot <- sd(distances[[i]][indTri])
  # Non dups and reps
  temp <- distances[[i]][-c(indDups, indReps), -c(indDups, indReps)]
  indTri <- upper.tri(temp)
  avgRed <-  mean(temp[indTri])
  sdRed <- sd(temp[indTri])
  # Dups
  tempDup <- c()
  tempDupCount <- c()
  for (j in 1:length(indDups)){
    indreg <- which(colnames(distances[[i]]) == gsub("_dup", "", colnames(distances[[i]])[indDups[j]]))
    tempDup <- c(tempDup, distances[[i]][indDups[j], indreg])
    tempDupCount <- c(tempDupCount, sum(abs(prodList[[i]]$binary[,indreg] - prodList[[i]]$binary[,indDups[j]])))
  }
  avgDup <- mean(tempDup)
  sdDup <- sd(tempDup)
  avgDupCount <- mean(tempDupCount)
  sdDupCount <- sd(tempDupCount)
  # Reps
  tempRep <- c()
  tempRepCount <- c()
  for (j in 1:length(indReps)){
    indreg <- colnames(distances[[i]]) == gsub("_rep", "", colnames(distances[[i]])[indReps[j]])
    tempRep <- c(tempRep, distances[[i]][indReps[j], indreg])
    tempRepCount <- c(tempRepCount, sum(abs(prodList[[i]]$binary[,indreg] - prodList[[i]]$binary[,indReps[j]])))
  }
  avgRep <- mean(tempRep)
  sdRep <- sd(tempRep)
  avgRepCount <- mean(tempRepCount)
  sdRepCount <- sd(tempRepCount)
  # Build up data frame
  simTable <- rbind(simTable, c(avgTot, sdTot, avgRed, sdRed, length(indDups), avgDup, sdDup, length(indReps), avgRep, sdRep, avgDupCount, sdDupCount, avgRepCount, sdRepCount))
}
simTable <- data.frame(simTable)
colnames(simTable) <- c("avgTot", "sdTot", "avgRed", "sdRed", "NumDups", "avgDup", "sdDup", "NumReps", "avgRep", "sdRep",
                        "avgDupCount", "sdDupCount", "avgRepCount", "sdRepCount")
simTable <- cbind("ProductCategory" = prodGroups, simTable)
#write.table(simTable, file = paste(myPath, "results", "similarityMeansForSampBySampHeatmaps.txt", sep = "/"), 
 #           quote = FALSE, sep = "\t", row.names = FALSE)



# Get a binary vector for each product category
prodCatVects <- c()
for (i in 1:length(prodGroups)){
  temp <- unlist(apply(prodList[[i]]$binary, 1, max))
  prodCatVects <- rbind(prodCatVects, temp)
}
row.names(prodCatVects) <- prodGroups
# Get the distances
catDistances <- as.matrix(dist(prodCatVects, method = "binary"))
# Fill in the diagonal
diag(catDistances) <- simTable$avgTot

# Make the plot
# Set colors and range
col_fun <- colorRamp2(c(0.4, 0.7, 1), c("blue", "white", "red"))

a <- Heatmap(catDistances, name = "Distance", col = col_fun, 
             rect_gp = gpar(col = "white", lwd = 2),
             cell_fun = function(j, i, x, y, width, height, fill){
               grid.text(sprintf("%.3f", catDistances[i, j]), x, y, gp = gpar(fontsize = 10))
             },
             column_names_gp = grid::gpar(fontsize = 11), show_row_names = FALSE,
             column_title = "Product Category Similarity by Chemical Occurrence")

pdf(file = paste(myPath, "plots", "allProdCatSimilarityHeatmap_1vect.pdf", sep = "/"))
  print(a)
dev.off()

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## By Chemical Concentration

```{r prodSimConc}
# Load functional uses.  Object name is preds
load(paste(myPath, "/results/predAndKnownFuncUse_chemsAcrossAllSamps_probs.RData", sep = ""))

# Load our list of product group matrices
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Get curated table of group levels and brands
prodOnt <- as.data.frame(read_xlsx(path = paste(myPath, "data", "masterSampleTable_withLevelsAndBrands_v2.xlsx", 
                                                sep = "/")))
# Remove blanks
prodOnt <- prodOnt[!prodOnt$Group3 == "blank",]

funcUse <- FALSE
concTable <- c()
allDup <- c()
allRep <- c()
for (i in 1:length(prodList)){
  temp <- prodList[[i]]$conc
  
  # Remove chemicals not in any of the samples
  indRem <- unlist(apply(temp, 1, function(x) sum(is.na(x)) == dim(temp)[2])) 
  temp <- temp[!indRem,]  
  
  # Perform clustering of rows
  set.seed(788)
  temp2 <- temp
  temp2[is.na(temp2)] <- 0
  temp2[is.nan(temp2)] <- 0
  temp2 <- scale(temp2)
  dist_mat <- dist(temp2, method = 'euclidean')
  hclust_avg <- hclust(dist_mat, method = 'complete')
  temp <- temp[hclust_avg$order,]
  
  
  # If I want to add functional uses
  if (funcUse){
    # Add functional uses
    preds$chemical_id <- NULL
    ind <- match(row.names(temp), row.names(preds))
    preds <- preds[ind,]
    # Step through each row and get a vector of indices where the 1st element represents the use with the highest probability
    # and the last the lowest probability.  Will have the same size as preds
    rnkOrder <- t(apply(preds, 1, function(x) order(x, decreasing = TRUE)))
    # Use this matrix to make a ranked probability and use name matrix
    probOrder <- as.data.frame(matrix(data = NA, nrow = dim(preds)[1], ncol = dim(preds)[2], 
                                      dimnames = list(row.names(preds), paste("Use", 1:dim(preds)[2], sep = ""))))
    useOrder <- probOrder
    # Step through each row and pull the column names from preds based on the sorted vector
    # Do the same, but pull the probabilities as we want both pieces of information
    for (j in 1:dim(preds)[1]){
      useOrder[j,] <- colnames(preds)[rnkOrder[j,]]
      probOrder[j,] <- preds[j,rnkOrder[j,]]
      # For those with a valid predicted use below our assignment threshold, change to 
      # NA so those are not printed in the annotation area
      if (!is.na(probOrder[j,1])){
        ind0 <- as.numeric(probOrder[j,]) < 0.8
        useOrder[j,ind0] <- NA
        probOrder[j,ind0] <- NA
      }
    }
    indNA <- is.na(probOrder)
    useOrder[indNA] <- NA
    # To keep the figure size reasonable, just use the top 3 uses
    useOrder <- useOrder[,1:3]
    probOrder <- probOrder[,1:3]
    
    # I need to turn useOrder into a matrix with integers or single letters but keep the relationship
    myUses <- unique(as.vector(as.matrix(useOrder)))
    usePCH <- probOrder
    for (j in 1:dim(usePCH)[2]){
      ind <- match(useOrder[,j], myUses)
      usePCH[,j] <- ind
    }
    # NA use will be assigned a number if it is in myUses. Don't want a symbol for NA in plot annotation.
    indNA <- which(is.na(myUses))
    indNA2 <- usePCH == indNA
    usePCH[indNA2] <- NA
    # Since indNA is NA, need to reduce any indices with a value above this
    usePCH <- apply(usePCH, 2, function(x) ifelse(x > indNA, x-1, x))
    myUses <- myUses[-indNA]
    
    # Want the top use closest to the heatmap
    usePCH <- rev(as.data.frame(usePCH))
    probOrder <- rev(probOrder)
    
    # Use letters instead of symbols for the uses
    newUses <- LETTERS[1:length(myUses)]
    for (j in 1:dim(usePCH)[2]){
      ind <- match(usePCH[,j], 1:length(myUses))
      usePCH[,j] <- newUses[ind]
    }
    
    # Set up annotation
    left_ha <- rowAnnotation("Top Functional Uses" = anno_simple(as.matrix(probOrder), 
                              col = colorRamp2(c(0,1), c("white", "darkred")), na_col = "grey", 
                              which = "row", pch = as.matrix(usePCH), pt_gp = gpar(col = "white"), 
                              pt_size = unit(1, "snpc")*0.475))
    lgd_prob <- Legend(title = "Confidence of Use", col_fun = colorRamp2(c(0,1), c("white", "darkred")), 
                       at = c(0, 1), labels = c("0.8", "1"))
    lgd_pch <- Legend(title = "Top Functional Uses", pch = LETTERS[1:length(newUses)], type = "points", labels = myUses)
  }
  
  
  # Use anonymized sample names from prodOnt
  # Get brand, product sub-category, and curated sample names using master table
  ind <- match(colnames(temp), prodOnt$MySysID)
  colnames(temp) <- prodOnt$`Anon Sample 2`[ind]
  
  # Put in ug/g rather than ng/g
  temp <- temp/1000
  column_ha <- HeatmapAnnotation(Total_Conc_Sample = unlist(apply(temp, 2, function(x) sum(x, na.rm = TRUE))), 
                                 Chems_in_Sample = anno_barplot(unlist(apply(temp, 2, function(x) sum(!is.na(x))))))
  row_ha <- rowAnnotation(Total_Conc_Chem = unlist(apply(temp, 1, function(x) sum(x, na.rm = TRUE))),
                          annotation_name_rot = 90,
                          Samples_with_Chem = anno_barplot(unlist(apply(temp, 1, function(x) sum(!is.na(x))))))
  
  # Our categories either have ~20 samples or ~40 samples. 
  # Use 2 different font sized for the sample names in the figures.
  if(names(prodList)[i] %in% c("Cotton Clothing", "Silicone Kitchen Tools")){
    myFontSize <- 12.2
  } else {
    myFontSize <- 10.8
  }
  
  # Make plot
  #ht <- Heatmap(temp, name = "Concentration (ug/g)", top_annotation = column_ha, right_annotation = row_ha, 
  #              row_title = "Chemicals", #left_annotation = left_ha, 
  #              column_title = paste(prodGroups[i], " Samples", sep = ""), 
  #              cluster_rows = FALSE, cluster_columns = FALSE, show_row_names = FALSE, column_names_rot = 90, 
  #              column_names_gp = gpar(fontsize = myFontSize), column_names_max_height = unit(4, "cm"))
  #pdf(file = paste(myPath, "plots/singleProdCatConcHeatmaps", 
  #                 paste("prodSpecificHeatmap_conc_", prodGroups[i], "_newUseAnno_v3.pdf", sep = ""),
  #                 sep = "/"), width = 11, height = 13)
  #  draw(ht)
    #draw(ht, annotation_legend_list = list(lgd_prob, lgd_pch))
  #dev.off()
  
  
  # Find the largest difference in estimated concentration for a chemical between dups and reps
  # First find where our dups and reps are
  indDups <- grep("dup", colnames(temp))
  indReps <- grep("rep", colnames(temp))
  # Dups
  tempDup <- c()
  tempDup2 <- c()
  for (j in 1:length(indDups)){
    indreg <- which(colnames(temp) == gsub("_dup", "", colnames(temp)[indDups[j]]))
    # Differences
    Cdiff <- abs(temp[,indDups[j]] - temp[,indreg])
    # Maximum difference
    #tempDup <- c(tempDup, max(Cdiff, na.rm = TRUE))
    # Maximum fold change
    tempDup <- c(tempDup, max(Cdiff/temp[,indreg], na.rm = TRUE))
    # Keep track of each chemical in each sample pair
    tempDup2 <- cbind(tempDup2, Cdiff/temp[,indreg])
    colnames(tempDup2)[j] <- colnames(temp)[indDups[j]]
  }
  allDup[[i]] <- tempDup2 
  avgDup <- mean(tempDup)
  sdDup <- sd(tempDup)
  # Reps
  tempRep <- c()
  tempRep2 <- c()
  for (j in 1:length(indReps)){
    indreg <- colnames(temp) == gsub("_rep", "", colnames(temp)[indReps[j]])
    # Differences
    Cdiff <- abs(temp[,indReps[j]] - temp[,indreg])
    # Maximum difference
    #tempRep <- c(tempRep, max(Cdiff, na.rm = TRUE))
    # Maximum fold change
    tempRep <- c(tempRep, max(Cdiff/temp[,indreg], na.rm = TRUE))
    # Keep track of each chemical in each sample pair
    tempRep2 <- cbind(tempRep2, Cdiff/temp[,indreg])
    colnames(tempRep2)[j] <- colnames(temp)[indReps[j]]
  }
  allRep[[i]] <- tempRep2
  avgRep <- mean(tempRep)
  sdRep <- sd(tempRep)
  # Build up data frame
  concTable <- rbind(concTable, c(avgDup, sdDup, avgRep, sdRep))
  
}

concTable <- as.data.frame(concTable)
colnames(concTable) <- c("avgDup", "sdDup", "avgRep", "sdRep")
concTable <- cbind("ProductCategory" = prodGroups, concTable)

rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


# Simple Signature Identification

This is a simple first-pass way of finding a chemical signature for each
product type. Use the concentration matrix to get an idea of the
fraction of mass each chemical makes up.

```{r simpleSig}
# Load prodList
load(paste(myPath, "data", "prodList_all5cats_BinaryConcGroupNames.RData", sep = "/"))

# Get mean and 95% CI for the concentration of each chemical.  Write a function for 95% CI.
conf_int <- function(vector, interval = 0.95){
  vec_sd <- sd(vector, na.rm = TRUE)
  vec_mean <- mean(vector, na.rm = TRUE)
  result <- c(vec_mean, vec_mean - 1.96*vec_sd, vec_mean + 1.96*vec_sd)
  return(result)
}

signatures <- vector(mode = "list", length = length(prodList))
for (i in 1:length(prodList)){
  rowcounts <- unlist(apply(prodList[[i]]$conc, 1, function(x) sum(!is.na(x)))) 
  prevChems <- which(rowcounts/dim(prodList[[i]]$conc)[2] >= 0.8)
  signatures[[i]] <- prodList[[i]]$conc[prevChems,]
  # Some entries are NaN.  Change to NA.
  signatures[[i]][is.nan(signatures[[i]])] <- NA
  signatures[[i]] <- cbind(signatures[[i]], "Median_conc" = apply(signatures[[i]], 1, function(x) 
                                                             quantile(x, probs = 0.5, na.rm = TRUE)))
  
  # Convert from ng/g to ug/g
  signatures[[i]] <- signatures[[i]]/1000
}
names(signatures) <- prodGroups
# Save this object for comparison with external data
save(signatures, file = paste(myPath, "results", "prodCatSignatures_gte0.8sampOccurrence_all.RData", sep = "/"))


# Make a Facet Plot 
# Build the data frame 
df <- c()
for (i in 1:length(prodList)){
  ind <- dim(signatures[[i]])
  temp <- data.frame("Category" = rep(names(prodList)[i], ind[1]), "Chemical" = row.names(signatures[[i]]), 
              signatures[[i]], row.names = NULL)
  temp <- pivot_longer(temp, cols = grep("X", colnames(temp)), cols_vary = "fastest")
  colnames(temp)[4:5] <- c("Sample", "Conc")
  df <- rbind(df, temp)
}

# Remove NA rows (samples for which signature chems are not present)
df <- df[!is.na(df$Conc),]

# Facet from largest category signature to smallest
srtOrder <- unlist(lapply(signatures, function(x) dim(x)[1]))
srtOrder <- order(srtOrder, decreasing = TRUE)
df$Category <- factor(df$Category, levels = names(prodList)[srtOrder], ordered = TRUE)
g <- ggplot(df, aes(x = reorder_within(Chemical, -Median_conc, Category), y = Conc, fill = Category)) +
  geom_boxplot() +
  scale_y_log10() +
  scale_x_reordered() +
  facet_grid(~Category, scales = "free_x", space = "free", 
             labeller = labeller(Category = label_wrap_gen(5))) +
  theme_bw() +
  ylab("log10(Conc in ug/g)") +
  ggtitle("Chemical Signatures of Product Categories") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  theme(axis.title.x = element_blank()) +
  theme(text =element_text(size = 13)) +
  theme(legend.text = element_text(size = 10))
pdf(file = paste(myPath, "plots", "mostPrevChemsPerProduct_boxplotConc_v2.pdf", sep = "/"), width = 12, height = 7)
  print(g)
dev.off()

# For supplement, want to get the IQR for each category-chemical pair. Step through the signatures object.
sigChemsConc <- c()
for (i in 1:length(signatures)){
  iqrs <- t(apply(signatures[[i]], 1, function(x) quantile(x, probs = seq(0, 1, 0.25), na.rm = TRUE)))
  # Round the values
  iqrs <- round(iqrs, digits = 4)
  # Rename columns
  colnames(iqrs) <- c("Min_conc", "25%_quantile_conc", "Median_conc", "75%_quantile_conc", "Max_conc")
  # Want to concatenate across all categories. Since some chemicals are signature chems for multiple 
  # categories, we can't use them as row names (duplicates not allowed). So make it a column.
  iqrs <- cbind("Category" = rep(names(signatures)[i], dim(iqrs)[1]), "Chemical" = row.names(iqrs), iqrs)
  row.names(iqrs) <- NULL
  sigChemsConc <- rbind(sigChemsConc, iqrs)
}
sigChemsConc <- as.data.frame(sigChemsConc)

# Go to next section to finish filling out the supplemental table (sigChemsConc) 
```


## Characterize Signature Chemicals

To add more context to our results and signatures, bring in various forms of chemical
data, including EPA's ChemExpo Database for product composition, availability of ToxVal
data, EPA's QC level, activity in ToxCast assays, and predicted oral rat LD50s.

```{r annotateSigChems}
### Pull the ORAL RAT LD50 TEST estimates for the signature chemicals
# Bring in the dashboard result for the chemicals and remove those without a dashboard entry
myChems <- as.data.frame(read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", 
                                         sep = "/"), sheet = 2))
indTox <- which(colnames(myChems) %in% c("ORAL_RAT_LD50_MOL/KG_TEST_PRED",
                                       "BIODEGRADATION_HALF_LIFE_DAYS_DAYS_OPERA_PRED",
                                       "OCTANOL_AIR_PARTITION_COEFF_LOGKOA_OPERA_PRED",
                                       "OCTANOL_WATER_PARTITION_LOGP_OPERA_PRED"))
myChems <- myChems[,c(1:5,indTox)]
# Drop chemicals that didn't have a match
todrop <- c("Searched by Synonym: Found 0 results", 
            "Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
myChems <- myChems[!myChems$FOUND_BY %in% todrop,]

# Combine with sigChemsConc object from the last section/code block
# Prep first
myChems$FOUND_BY <- NULL
colnames(myChems)[1] <- "Chemical"
sigChemsAll <- base::merge(sigChemsConc, myChems, by = "Chemical", all.x = TRUE, sort = FALSE)
sigChemsAll <- sigChemsAll[,c(2,8:10,3:7,11:14)]

# Add data from EPA's Comptox Chemicals Dashboard
# Create a file of unique DTXSIDs to write a file and then use that file in the CCD batch search
sigCCD <- unique(sigChemsAll$DTXSID)
#write.csv(sigCCD, file = "C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsSSA/signatureChemDTXSIDs_2023-11-08.txt",
#          quote = FALSE, row.names = FALSE, col.names = FALSE)
# Read in file
CCDmetadata <- read_xlsx(path = paste(myPath, "data", "signaturechems_CurationMetaData_CCD.xlsx", sep = "/"), 
                         sheet = 2, na = "")
CCDmetadata <- CCDmetadata[,!colnames(CCDmetadata) %in% c("INPUT", "FOUND_BY", "PREFERRED_NAME", "CASRN")]
# Combine with sigChemsAll object
sigChemsFinal <- base::merge(sigChemsAll, CCDmetadata, by = "DTXSID", all.x = TRUE, sort = FALSE)
# Clean up
sigChemsFinal <- sigChemsFinal[,c(2,1,3:18)]
sigChemsFinal$TOXVAL_DATA[is.na(sigChemsFinal$TOXVAL_DATA)] <- "N" 
sigChemsFinal$CPDAT_COUNT[is.na(sigChemsFinal$CPDAT_COUNT)] <- 0
sigChemsFinal$`TOXCAST_NUMBER_OF_ASSAYS/TOTAL`[is.na(sigChemsFinal$`TOXCAST_NUMBER_OF_ASSAYS/TOTAL`)] <- 0
sigChemsFinal$TOXCAST_PERCENT_ACTIVE[is.na(sigChemsFinal$TOXCAST_PERCENT_ACTIVE)] <- 0
# Group by category
sigChemsFinal <- sigChemsFinal[order(match(sigChemsFinal$Category, prodGroups)),]

# Make a plot
sigChemsFinal$Category <- factor(sigChemsFinal$Category, levels = names(prodList)[srtOrder], ordered = TRUE)
sigChemsFinal$`ORAL_RAT_LD50_MOL/KG_TEST_PRED` <- as.numeric(sigChemsFinal$`ORAL_RAT_LD50_MOL/KG_TEST_PRED`)
sigChemsFinal$CPDAT_COUNT <- as.numeric(sigChemsFinal$CPDAT_COUNT)

sigChemsFinal$CPDat_Product_Count <- cut(sigChemsFinal$CPDAT_COUNT, breaks = c(0.5,10,100,1000,max(sigChemsFinal$CPDAT_COUNT)),
                                         labels = c("1-10", "11-100", "101-1000", ">1000"))
levels(sigChemsFinal$CPDat_Product_Count) <- c(levels(sigChemsFinal$CPDat_Product_Count), "0")
sigChemsFinal$CPDat_Product_Count[is.na(sigChemsFinal$CPDat_Product_Count)] <- 0
sigChemsFinal$CPDat_Product_Count <- factor(sigChemsFinal$CPDat_Product_Count, 
                                            levels = c("0", "1-10", "11-100", "101-1000", ">1000"), ordered = TRUE)

sigChemsFinal$Median_conc <- as.numeric(sigChemsFinal$Median_conc)
colnames(sigChemsFinal)[3] <- "Chemical"
g <- ggplot(sigChemsFinal, aes(x = reorder_within(Chemical, -Median_conc, Category), 
                           y = sigChemsFinal$`ORAL_RAT_LD50_MOL/KG_TEST_PRED`, fill = CPDat_Product_Count)) +
  geom_bar(stat = "identity", width = 0.8) +
  scale_x_reordered() +
  scale_fill_manual(values = rev(colorspace::heat_hcl(5))) + 
  facet_grid(~Category, scales = "free_x", space = "free",
             labeller = labeller(Category = label_wrap_gen(5))) +
  theme_bw() +
  #guides(fill = guide_legend(title = "Reported in ChemExpo")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylab("Predicted Oral Rat LD50 (mol/kg)") +
  #ggtitle("Chemical Signatures of Product Categories") +
  theme(axis.title.x = element_blank()) +
  theme(text =element_text(size = 13)) +
  theme(legend.text = element_text(size = 10))
pdf(file = paste(myPath, "plots", "prodCatSignatures_withChemExpoAndLD50_v2.pdf", sep = "/"), width = 12, height = 6.7)
  print(g)
dev.off()


# Save data for figure ##
write.table(sigChemsFinal, file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"), sep = "\t", row.names = FALSE)

# What ClassyFire annotations 
sigchems <- read.delim(file = paste(myPath, "results", "signatureChemsCuratedData.txt", sep = "/"))
classyfire <- read.delim(file = paste(myPath, "results/ClassyFireAnnotation_allChems_batchAPI.txt", sep = "/"))
ind <- match(sigchems$DTXSID, classyfire$DTXSID)
sigchems <- cbind(sigchems, classyfire[ind,c("Kingdom", "Superclass", "Class")])
for (i in 1:length(prodGroups)){
  ind <- sigchems$Category == prodGroups[i]
  print(as.data.frame(table(sigchems$Superclass[ind])))
}

# Check overlap with TSCA Active list
tsca <- read_xlsx(path = "C:/Users/ZSTANFIE/OneDrive - Environmental Protection Agency (EPA)/zstanfield/HhldProdsSSA/ChemList_TSCA_ACTIVE_NCTI_0222-2024-03-19.xlsx")

# Check to make sure all chemicals are unique
length(unique(tsca$DTXSID))

# Overlap with unique signature chemicals
sigind <- which(sigchems_unique$DTXSID %in% tsca$DTXSID)
sigchems_unique$Chemical[-sigind]

myChems <- as.data.frame(read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", 
                                         sep = "/"), sheet = 2))
myChems <- myChems[!is.na(myChems$DTXSID),]
myChems <- myChems[!duplicated(myChems$DTXSID),]
allind <- which(myChems$DTXSID %in% tsca$DTXSID)



rm(list=setdiff(ls(), c("myPath", "prodGroups")))
```


## Signatures at Different Category Levels

Do for multiple different levels, not just the above 5 categories. Any
different set of groupings can be used, so some manual input is needed
at the start of this section

```{r levelSigs}
load(paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))
refTable <- as.data.frame(read_xlsx(paste(myPath, "data", "masterSampleTable_withLevelsAndBrands.xlsx", sep = "/")))

# Reduce sample list to those in matrix
ind <- match(colnames(allProdTypesMat$binary), refTable$`System ID`)
refTable_2 <- refTable[ind,]
colnames(refTable_2)[1:3] <- c("Lvl1", "Lvl2", "Lvl3")

# List of groups to look at
myGroups <- list(c("Clothing", "Fabric"), "Cotton Clothing", "Fabric Upholstery", "baby_onesie", 
                 "shorts_or_pants", "baby_socks", "GERBER", "JOHNSON'S", c("Shampoo", "Baby Soap"), 
                 "Shampoo", "Baby Soap", "baby_wash", "natural", "traditional", 
                 "Silicone Kitchen Tools", "spatula", "cup")
names(myGroups) <- c("Lvl1", "Lvl2", "Lvl2", "Lvl3", "Lvl3", "Lvl3", "Brand", "Brand", "Lvl2", "Lvl2", 
                     "Lvl2", "Lvl3", "Lvl3", "Lvl3", "Lvl2", "Lvl3", "Lvl3")

topSignats <- list()
topConcs <- list()
sampleCount <- c()
for (i in 1:length(myGroups)){
  indS <- which(refTable_2[,colnames(refTable_2) %in% names(myGroups)[i]] %in% myGroups[[i]])
  sampleCount <- c(sampleCount, length(indS))
  rowcounts <- unlist(apply(allProdTypesMat$binary[,indS], 1, function(x) sum(x != 0))) 
  # Get median conc. in ug/g across samples
  rowMeans <- unlist(apply(allProdTypesMat$conc[,indS], 1, function(x) median(x/1000, na.rm = TRUE)))  
  prevChems <- which(rowcounts/length(indS) >= 0.8)
  topSignats[[i]] <- row.names(allProdTypesMat$binary)[prevChems]
  topConcs[[i]] <- rowMeans[prevChems]
  names(topSignats)[i] <- paste(names(myGroups)[i], ": ", paste(myGroups[[i]], collapse = " + "), sep = "")
  names(topConcs)[i] <- paste(names(myGroups)[i], ": ", paste(myGroups[[i]], collapse = " + "), sep = "")
  names(sampleCount)[i] <- paste(names(myGroups)[i], ": ", paste(myGroups[[i]], collapse = " + "), sep = "")
}

# Now build a heatmap for these signatures
# Rows are chemicals occurring in at least 1 signature and columns are the sample groups
# Want to pull the concentration values to get a median concentration
# Also want functional use for chemicals and sample count for each group of samples
sigChems <- unique(unlist(topSignats))
mydf <- as.data.frame(matrix(data = NA, nrow = length(sigChems), ncol = length(topSignats), 
                             dimnames = list(sigChems, names(topSignats))))
for (i in 1:length(topSignats)){
  ind <- match(topSignats[[i]], sigChems)
  mydf[ind, names(topSignats)[i]] <- topConcs[[i]]
}

# Build annotations for these
# Start with functional use
load(paste(myPath, "results", "predFuncUse_chemsAcrossAllSamps_prob.RData", sep = "/"))
preds$chemical_id <- NULL
preds <- as.matrix(preds)
ind <- match(row.names(mydf), row.names(preds))
useInd <- unlist(apply(preds[ind,], 1, function(x) ifelse(sum(is.na(x)) == length(x) | 
                                                          sum(x) == 0, NA, which(x == max(x)))))
uses <- colnames(preds)[useInd]
uses <- as.factor(uses)

palettes <- ggthemes_data[["tableau"]][["color-palettes"]][["regular"]]
use_col <- palettes$`Tableau 20`$value[1:length(levels(uses))]
names(use_col) <- levels(uses)
left_ha <- rowAnnotation("Functional Use" = uses, col = list("Functional Use" = use_col),
                               annotation_name_gp = grid::gpar(fontsize = 8))

column_ha <- HeatmapAnnotation("Sample Count" = anno_barplot(unlist(apply(mydf, 2, function(x) sum(!is.na(x))))),
                               annotation_name_gp = grid::gpar(fontsize = 8))

# Build annotation for chemical count in each sample
right_ha <- rowAnnotation("Chemical Count" = anno_barplot(unlist(apply(mydf, 1, function(x) sum(!is.na(x))))),
                          annotation_name_rot = 90, annotation_name_gp = grid::gpar(fontsize = 8))

a <- Heatmap(as.matrix(mydf), name = "Median Conc. (ug/g)", top_annotation = column_ha, right_annotation = right_ha, 
             column_names_gp = grid::gpar(fontsize = 7), show_row_names = TRUE, cluster_rows = FALSE, 
             cluster_columns = FALSE, column_title = "Chemical Signatures at Different Product Levels", 
             column_split = c(1,1,1,2,2,2,3,3,4,4,4,5,5,5,6,6,6),
             row_names_side = "left", row_names_gp = grid::gpar(fontsize = 6.25), left_annotation = left_ha)
pdf(file = paste(myPath, "plots", "ChemSignatureHeatmap_withConc.pdf", sep = "/"))
  print(a)
dev.off()

```


## Classify External Data

Do a simple classification of the data from Phillips et. al. 2017 using
the signatures in our data.

```{r simpleClassif}
# Load my data's signatures
load(file = paste(myPath, "results", "prodCatSignatures_gte0.8sampOccurrence_all.RData", sep = "/"))

#Bring in the dashboard result for my chemicals and remove those without a dashboard entry
myChems <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", sep = "/"), sheet = 2)
myChems <- myChems[,1:5]
# Drop chemicals that didn't have a match
todrop <- c("Searched by Synonym: Found 0 results", 
            "Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
myChems <- myChems[!myChems$FOUND_BY %in% todrop,]

# Just need the chemical names if I am doing occurrence only
sigList <- list()
for (i in 1:length(signatures)){
  minconc <- apply(signatures[[i]][,-dim(signatures[[i]])[2]], 1, function(x) min(x, na.rm = TRUE))
  maxconc <- apply(signatures[[i]][,-dim(signatures[[i]])[2]], 1, function(x) max(x, na.rm = TRUE))
  sigList[[i]] <- cbind("Mean" = signatures[[i]][,dim(signatures[[i]])[2]], "Min" = minconc, "Max" = maxconc)
  
  # Add columns with identifiers to help use match with the other study
  ind <- match(names(minconc), myChems$INPUT)
  sigList[[i]] <- cbind(as.data.frame(sigList[[i]]), "CAS" = myChems$CASRN[ind])
}
names(sigList) <- names(prodList)

sets <- lapply(sigList, row.names)

# Look at overlaps
for (i in 1:(length(sets)-1)){
  for (j in (i+1):length(sets)){
    print(paste("Intersection between ", names(sets)[i], " and ", names(sets)[j], sep = ""))
    print(length(intersect(sets[[i]], sets[[j]])))
  }
}

# Drop chemicals that occur in more than one category
uniqSigList <- sigList
for (i in 1:length(sets)){
  ind <- setdiff(sets[[i]], unlist(sets[-i]))
  uniqSigList[[i]] <- sigList[[i]][ind,]
}
lapply(uniqSigList, dim)  

# From Phillips et al 2017 supplemental data, 20 product types (5 samples each)
occurMat <- as.data.frame(read_xlsx(path = paste(myPath, "data", "KPhillips_SSofConsumerProds_SuppTables.xlsx", 
                                                 sep = "/"), sheet = 3))

# Remove any NAs in the CAS column
occurMat <- occurMat[!is.na(occurMat$casrn),]  # Down from 6010 rows to 5982

# Turn this long-form table into an occurrence matrix of sample X chemical
extChems <- unique(occurMat$casrn)  # 1594
extSamps <- unique(occurMat$anonymized_product)
# Allocate space
extDF <- as.data.frame(matrix(data = NA, nrow = length(extSamps), ncol = length(extChems), 
                              dimnames = list(extSamps, extChems)))
for (i in 1:length(extSamps)){
  indS <- which(occurMat$anonymized_product == extSamps[i])
  indC <- match(occurMat$casrn[indS], extChems)
  indDup <- duplicated(indC)  # There are cases when a chemical is reported twice for a sample
  indS <- indS[!indDup]       # This causes issues when populating the matrix, so drop the duplicate
  indC <- indC[!indDup]
  extDF[i,indC] <- occurMat$concentration_microgram_per_gram[indS] 
}
# Replace NAs with zeros
extDF[is.na(extDF)] <- 0

# Build final DF for classification.  Just have the signature chemicals in the final DF
myCols <- sapply(names(uniqSigList), function(x) paste(x, c("Count", "Total", "Fraction"), sep = "_"))
classDF <- as.data.frame(matrix(data = NA, nrow = dim(extDF)[1], ncol = 3*length(uniqSigList),
                                dimnames = list(row.names(extDF), myCols)))
for (j in 1:dim(extDF)[1]){
  place <- 0
  for (i in 1:length(uniqSigList)){
    counts <- length(intersect(colnames(extDF)[which(extDF[j,] != 0)], uniqSigList[[i]][,4]))
    total <- dim(uniqSigList[[i]])[1]
    fraction <- counts/total
    classDF[j, (place + 1):(place + 3)] <- c(counts, total, fraction)
    place <- place + 3
  }
}

# Make the classification call
callCol <- c()
fraction_cols <- grep("Fraction", colnames(classDF))
for (i in 1:dim(classDF)[1]){
  ind <- names(uniqSigList[which(classDF[i, fraction_cols] == max(classDF[i, fraction_cols]))])
  if (length(ind) > 1){
    ind <- paste(ind, collapse = "_and_")
  }
  callCol <- c(callCol, ind)
}
classDF <- cbind("Classfication" = callCol, classDF)


# Get simple signatures for this external data
extDF <- t(extDF)
catNames <- substr(colnames(extDF), 1, nchar(colnames(extDF))-2)
extCats <- unique(catNames)
extSignatures <- vector(mode = "list", length = length(extCats))
for (i in 1:length(extCats)){
  indCat <- catNames == extCats[i]
  rowcounts <- unlist(apply(extDF[,indCat], 1, function(x) sum(x > 0))) 
  prevChems <- which(rowcounts/dim(extDF[,indCat])[2] >= 0.8)
  extSignatures[[i]] <- extDF[prevChems,indCat]
  # Some entries are NaN.  Change to NA.
  extSignatures[[i]][is.nan(extSignatures[[i]])] <- NA
  extSignatures[[i]] <- cbind(extSignatures[[i]], "Mean" = apply(extSignatures[[i]], 1, function(x) mean(x, na.rm = TRUE)))
}
names(extSignatures) <- extCats
# Save this object for comparison with external data
save(extSignatures, file = paste(myPath, "results", "prodCatSignatures_Phillips2018_gte0.8sampOccurrence_all.RData", sep = "/"))


# Look at signature overlap
# Use the CAS column in sigList to check against the row names in extSignatures
ssdf <- as.data.frame(matrix(data = NA, nrow = 5, ncol = 20, dimnames = list(prodGroups, extCats)))
for (i in 1:length(prodGroups)){
  for (j in 1:length(extCats)){
    ssdf[i,j] <- length(intersect(sigList[[i]][,4], row.names(extSignatures[[j]])))
  }
}
ssdf <- t(ssdf)

# Build annotation for the signanture size of both our data and the external data
right_ha <- rowAnnotation("Signature Size" = anno_barplot(unlist(lapply(extSignatures, 
                                                                       function(x) dim(x)[1]))),
                                                                       annotation_name_rot = 90)

column_ha <- HeatmapAnnotation("Signature Size" = anno_barplot(unlist(lapply(sigList, 
                                                                       function(x) dim(x)[1]))))

# Set colors and range
col_fun <- colorRamp2(c(0, max(ssdf)/2, max(ssdf)), c("blue", "white", "red"))

a <- Heatmap(ssdf, name = "Shared Chemicals", col = col_fun, right_annotation = right_ha,
             top_annotation = column_ha, rect_gp = gpar(col = "white", lwd = 2),
             cell_fun = function(j, i, x, y, width, height, fill){
               grid.text(sprintf("%i", ssdf[i, j]), x, y, gp = gpar(fontsize = 10))},
             column_names_gp = grid::gpar(fontsize = 10), show_row_names = TRUE,
             column_title = "Product Categories: This Study",
             row_names_side = "right", row_names_gp = grid::gpar(fontsize = 10),
             column_title_side = "bottom", row_title = "Product Categories: Phillips et al 2018",
             row_title_side = "right")
pdf(file = paste(myPath, "plots", "prodCatSignatureOverlap_Phillips2018_Heatmap.pdf", sep = "/"))
  print(a)
dev.off()

```


# Make Upset plot

```{r upset}
# Aggregate by product
prods <- unique(allSamps$Product)
upset_list <- vector("list", length(prods))
for (i in 1:length(prods)){
  upset_list[[i]] <- which(unlist(apply(chemXsamp_binary_red[,allSamps$Product == prods[i]], 1, sum))  > 0)
}
names(upset_list) <- prods

# Chemical counts per product group
lengths(upset_list)

pdf(file = paste(myPath, "plots", "ProductGroup_chemOccurrence_upsetPlot.pdf", sep = "/"), width = 8, height = 6)
upset(fromList(upset_list), order.by = "freq", point.size = 3, line.size = 1.5, 
      mainbar.y.label = "Chemical Intersections", sets.x.label = "Product Type", 
      text.scale = c(1.5, 1.3, 1.3, 1.1, 1.4, 1.2))
dev.off()

# Save the data for this plot
# Might have to somehow convert this to a data frame
#write.table(upset_list, file = paste(myPath, "results", "Figure_#_data.txt", sep = "/"), sep = "\t")

```


# Clustering of Chemicals by Occurrence

Want to identify ubiquitous chemicals, chemicals specific to certain
subsets of samples, and chemicals with similar signatures.

```{r occur_clust, echo=FALSE}
load(file = paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))

# Drop chemicals that are ubiquitous (in most samples) and scarce (in very few samples)
chemSums <- unlist(apply(chemXsamp_binary_red2, 1, sum))
hist(chemSums)
# Remove those in 0 samples
chemXsamp_binary_red2 <- chemXsamp_binary_red2[chemSums > 0,]
# Remove those in only 1 sample
chemSums <- unlist(apply(chemXsamp_binary_red2, 1, sum))
chemXsamp_binary_red2 <- chemXsamp_binary_red2[chemSums > 1,]

# Create Distance Matrix
ID_temp <- vegdist(as.matrix(chemXsamp_binary_red2), method = "jaccard")

# Visualize the silhouette width and weighted sum of squares for different number of clusters using the divisive clustering
fviz_nbclust(chemXsamp_binary_red2, diss = ID_temp, method = "wss", FUN = hcut, hc_func = "diana", k.max = 100)
fviz_nbclust(chemXsamp_binary_red2, diss = ID_temp, method = "silhouette", FUN = hcut, hc_func = "diana", k.max = 100)

# Looks like 6 is the optimal cluster #
clustered <- diana(ID_temp, diss = TRUE)
cluster_assignments <- cutree(clustered, k = 13)
# Add assignments to the sample data
table(cluster_assignments)
# Drop clusters with less than 5 chemicals
ind <- which(cluster_assignments %in% c(5,8,9,11,13))
chemXsamp_binary_red2 <- chemXsamp_binary_red2[-ind,]
cluster_assignments <- cluster_assignments[-ind]

# Try a different clustering approach
n_clusters <- 20
wss <- numeric(n_clusters)
for (i in 1:n_clusters){
  km.out <- kmeans(scale(chemXsamp_binary_red2), centers = i, nstart = 20)
  wss[i] <- km.out$tot.withinss
}
wss_df <- data.frame(clusters = 1:n_clusters, wss = wss)
ggplot(wss_df, aes(x = clusters, y = wss, group = 1)) +
  geom_point(size = 4) +
  geom_line() +
  xlab("Number of clusters") +
  geom_hline(yintercept = wss, linetype = "dashed")
# 6 clusters looks best
k <- 6
set.seed(123)
km.out <- kmeans(scale(chemXsamp_binary_red2), centers = k, nstart = 20)
cluster_assignments <- factor(km.out$cluster)
as.data.frame(table(cluster_assignments))

# Make the plot
temp <- chemXsamp_binary_red2
temp <- temp[order(cluster_assignments),]
temp[temp == 0] <- NA

mycols <- brewer.pal(5, "Set1")
names(mycols) <- unique(prodOrd)
                     
column_ha <- HeatmapAnnotation(Chems_in_Sample = anno_barplot(unlist(apply(temp, 2, function(x) sum(x!=0)))),
                               col = list(ProductType = mycols))
row_ha <- rowAnnotation(Samples_with_Chem = anno_barplot(unlist(apply(temp, 1, function(x) sum(x!=0)))),
                        annotation_name_rot = 90)
#left_ha <- rowAnnotation(Functional_Use = uses, col = list(FuncUse = cols), annotation_name_rot = 90)

pdf(file = paste(myPath, "plots", "occurrenceHeatmap_allCombined_clustered6_kmeans.pdf", sep = "/"), 
    width = 9, height = 11)
Heatmap(temp, name = "Occurrence", col = c("grey", "gold"), top_annotation = column_ha, right_annotation = row_ha,
        #left_annotation = left_ha,
        row_title = "Chemicals", column_title = "Product Samples", cluster_rows = FALSE, na_col = "grey",
        cluster_columns = FALSE, show_row_names = FALSE, column_names_rot = 90, column_names_gp = gpar(fontsize = 6), 
        column_names_max_height = unit(4, "cm"), row_split = cluster_assignments, column_split = prodOrd)
dev.off()

```


# Clustering Chemicals by Abundance

See how chemicals occur across samples from different categories and how their 
abundances range from sample to sample 

```{r abund_clust}






```


# Build Model to Predict Product Type

Want to build a sparse machine learning model based on chemical
occurrence. Use all samples with all chemicals to predict the product
type and identify the most influential chemicals for each class.

```{r sparsemodel}
load(paste(myPath, "data", "allProdTypesMat_combDilDupRep.RData", sep = "/"))

# Bring in the dashboard result for my chemicals and remove those without a dashboard entry
myChems <- read_xlsx(paste(myPath, "data/houseProdSSA_chems_CCDquery_byName_full.xlsx", sep = "/"), sheet = 2)
myChems <- myChems[,1:5]
# Drop chemicals that didn't have a match
todrop <- c("Searched by Synonym: Found 0 results", 
            "Integrated Source Name - WARNING: Synonym mapped to two or more chemicals",
            "Synonym - WARNING: Synonym mapped to two or more chemicals")
myChems <- myChems[!myChems$FOUND_BY %in% todrop,]

# Need the final chemical X sample occurrence matrix, after combining repeats and duplicates
featMat <- allProdTypesMat$binary
# Match to reduced set
featMat <- featMat[row.names(featMat) %in% myChems$INPUT,]
# Drop chemicals occurring in only 1 training sample
oneSamp <- unlist(apply(featMat, 1, sum))
featMat <- featMat[!oneSamp == 1,]

labels <- allProdTypesMat$prodType
set.seed(112)
featMat <- t(featMat)
data <- as.data.frame(featMat)
data <- cbind("Type" = as.factor(labels), data)
cv_3 <- trainControl(method = "cv", number = 3)
def_elnet <- train(Type ~ ., data = data, method = "rf", trControl = cv_3)
varImp(def_elnet, useModel = TRUE, scale = FALSE)

# Compare to a null model
ind <- sample.int(dim(data)[1], dim(data)[1], replace = FALSE)
data_yrand <- data
data_yrand$Type <- data_yrand$Type[ind]
def_elnet_yrand <- train(Type ~ ., data = data_yrand, method = "rf", trControl = cv_3)


##### Now predict the product type of an external set of samples
# From Phillips et al 2017 supplemental data, 20 product types (5 samples each)
occurMat <- as.data.frame(read_xlsx(path = paste(myPath, "data", "KPhillips_SSofConsumerProds_SuppTables.xlsx", 
                                                 sep = "/"), sheet = 3))

# Examine data
length(unique(occurMat$chemical_name))  # 1602
as.data.frame(table(occurMat$product_type))  # 3: article, food, and formulation
as.data.frame(table(occurMat$product_category))  # 20 product categories for 100 total samples
as.data.frame(table(occurMat$hit_flag))

# Check to see if I can use the chemical names or if I need to do DTXSID or CAS instead
length(intersect(myChems$INPUT, unique(occurMat$chemical_name)))  # 0
length(intersect(myChems$DTXSID, unique(occurMat$dtxsid)))  # 222
length(intersect(myChems$CASRN, unique(occurMat$casrn)))  # 222

# Remove any NAs in the CAS column
occurMat <- occurMat[!is.na(occurMat$casrn),]  # Down from 6010 rows to 5982

# Turn this long-form table into an occurrence matrix of sample X chemical
extChems <- unique(occurMat$casrn)  # 1594
extSamps <- unique(occurMat$anonymized_product)
# Allocate space
extDF <- as.data.frame(matrix(data = NA, nrow = length(extSamps), ncol = length(extChems), 
                              dimnames = list(extSamps, extChems)))
for (i in 1:length(extSamps)){
  indS <- occurMat$casrn[occurMat$anonymized_product == extSamps[i]]
  extDF[i,unique(indS)] <- 1
}
# Replace NAs with zeros
extDF[is.na(extDF)] <- 0

# Build final DF for classification
finalDF <- as.data.frame(matrix(data = NA, nrow = dim(extDF)[1], ncol = dim(featMat)[2], 
                              dimnames = list(row.names(extDF), colnames(featMat))))
for (i in 1:dim(finalDF)[2]){
  # Get the index for this chemical so I can pull CAS of our final feature chemicals
  ind1 <- which(myChems$INPUT == colnames(finalDF)[i])  
  if (length(ind1) == 0){  # If there is no match, it is one of the 63 chemicals in my data without a dashboard entry
    finalDF[,i] <- 0    # meaning we can't say anything about occurrence
  } else {     # otherwise we want to match the CAS of our chemical to the external set
    ind2 <- which(extChems == myChems$CASRN[ind1])
    if (length(ind2) == 0){  # If there is no match, the chemical occurred in my data but not the external data
      finalDF[,i] <- 0    # meaning this chemical isn't present in the samples
    } else {
      # If we do find a match, use the external occurrence matrix to fill in the binary column
      finalDF[,i] <- extDF[,ind2]  
    }
  }  
}

# Get a sample - product category reference table
refSamp <- occurMat[,colnames(occurMat) %in% c("anonymized_product", "product_category", "product_type")]
refSamp <- refSamp[!duplicated(refSamp[,1:2]),]

# Use the model to make predictions
predicted <- predict(def_elnet, newdata = finalDF)

# Save the model that gave these predictions
rf_model_3cv <- def_elnet
varImp(rf_model_3cv, useModel = TRUE)
save(rf_model_3cv, file = paste(myPath, "results", "ProdTypeClassifModel_RandForest_3cv_dashChemsAllSamps_binary.RData", sep = "/"))

# Fill out reference table
refSamp$predicted <- predicted
true_names <- read.csv(file = paste(myPath, "data", "anonymized_product_dictionary.csv", sep = "/"), header = TRUE)
# Not in the same order, so have to match up. Drop spaces, points, and go to lowercase
vecRef <- gsub(" ", "", tolower(refSamp$anonymized_product))
vecTrue <- gsub("\\.", "", gsub(" ", "", tolower(true_names$anonymous)))
ind <- match(vecRef, vecTrue)

refSamp <- cbind("product_name" = true_names$product_name[ind], refSamp)
#save(refSamp, file = paste(myPath, "results", "PilotStudyPreds_RandForest_3cv_dashChemsAllSamps_binary.RData", 
#                            sep = "/"))

### AD Assessment
# Need a train and predicted matrix with labels
train <- as.data.frame(featMat)
trainlabels <- as.factor(labels)
train$train_class <- as.numeric(trainlabels)
train <- cbind("DTXSID" = row.names(train), train)

test <- finalDF
test$pred_class <- as.numeric(predicted)
test <- cbind("DTXSID" = row.names(test), test)

source(paste(myPath, "R/assessAD.R", sep = "/"))
indomain_DTXSIDs <- DomainOfApplicability(training=train, predicted=test)

refSamp$InDomain <- "No"
refSamp$InDomain[indomain_DTXSIDs] <- "Yes"

```
